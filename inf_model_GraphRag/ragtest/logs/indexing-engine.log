16:23:07,470 graphrag.cli.index INFO Logging enabled at E:\_MyCollegeLife\_3rd_2\inf_model_GraphRag\ragtest\logs\indexing-engine.log
16:23:09,264 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:23:10,231 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
16:23:10,235 graphrag.cli.index INFO Starting pipeline run. dry_run=False
16:23:10,235 graphrag.cli.index INFO Using default configuration: {
    "root_dir": "E:\\_MyCollegeLife\\_3rd_2\\inf_model_GraphRag\\ragtest",
    "models": {
        "default_chat_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "openai_chat",
            "model": "deepseek/deepseek-v3",
            "encoding_model": "cl100k_base",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0,
            "request_timeout": 180.0,
            "api_base": "https://api.ppinfra.com/v3/openai",
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "retry_strategy": "native",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 10,
            "responses": null,
            "async_mode": "threaded"
        },
        "default_embedding_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "openai_embedding",
            "model": "baai/bge-m3",
            "encoding_model": "cl100k_base",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0,
            "request_timeout": 180.0,
            "api_base": "https://api.ppinfra.com/v3/openai",
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "retry_strategy": "native",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 10,
            "responses": null,
            "async_mode": "threaded"
        }
    },
    "reporting": {
        "type": "file",
        "base_dir": "E:\\_MyCollegeLife\\_3rd_2\\inf_model_GraphRag\\ragtest\\logs",
        "storage_account_blob_url": null
    },
    "output": {
        "type": "file",
        "base_dir": "E:\\_MyCollegeLife\\_3rd_2\\inf_model_GraphRag\\ragtest\\output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "outputs": null,
    "update_index_output": {
        "type": "file",
        "base_dir": "E:\\_MyCollegeLife\\_3rd_2\\inf_model_GraphRag\\ragtest\\update_output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "input": {
        "type": "file",
        "file_type": "text",
        "base_dir": "input",
        "storage_account_blob_url": null,
        "encoding": "utf-8",
        "file_pattern": ".*\\.(txt|md)$",
        "file_filter": null,
        "text_column": "text",
        "title_column": null,
        "metadata": null
    },
    "embed_graph": {
        "enabled": false,
        "dimensions": 1536,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "use_lcc": true
    },
    "embed_text": {
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "target": "required",
        "names": [],
        "strategy": null,
        "model_id": "default_embedding_model",
        "vector_store_id": "default_vector_store"
    },
    "chunks": {
        "size": 1200,
        "overlap": 100,
        "group_by_columns": [
            "id"
        ],
        "strategy": "tokens",
        "encoding_model": "cl100k_base",
        "prepend_metadata": false,
        "chunk_size_includes_metadata": false
    },
    "snapshots": {
        "embeddings": false,
        "graphml": false
    },
    "extract_graph": {
        "prompt": "prompts/extract_graph.txt",
        "entity_types": [
            "organization",
            "person",
            "geo",
            "event"
        ],
        "max_gleanings": 1,
        "strategy": null,
        "encoding_model": null,
        "model_id": "default_chat_model"
    },
    "extract_graph_nlp": {
        "normalize_edge_weights": true,
        "text_analyzer": {
            "extractor_type": "regex_english",
            "model_name": "en_core_web_md",
            "max_word_length": 15,
            "word_delimiter": " ",
            "include_named_entities": true,
            "exclude_nouns": null,
            "exclude_entity_tags": [
                "DATE"
            ],
            "exclude_pos_tags": [
                "DET",
                "PRON",
                "INTJ",
                "X"
            ],
            "noun_phrase_tags": [
                "PROPN",
                "NOUNS"
            ],
            "noun_phrase_grammars": {
                "PROPN,PROPN": "PROPN",
                "NOUN,NOUN": "NOUNS",
                "NOUNS,NOUN": "NOUNS",
                "ADJ,ADJ": "ADJ",
                "ADJ,NOUN": "NOUNS"
            }
        },
        "concurrent_requests": 25
    },
    "summarize_descriptions": {
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "strategy": null,
        "model_id": "default_chat_model"
    },
    "community_reports": {
        "graph_prompt": "prompts/community_report_graph.txt",
        "text_prompt": "prompts/community_report_text.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null,
        "model_id": "default_chat_model"
    },
    "extract_claims": {
        "enabled": false,
        "prompt": "prompts/extract_claims.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 1,
        "strategy": null,
        "encoding_model": null,
        "model_id": "default_chat_model"
    },
    "prune_graph": {
        "min_node_freq": 2,
        "max_node_freq_std": null,
        "min_node_degree": 1,
        "max_node_degree_std": null,
        "min_edge_weight_pct": 40,
        "remove_ego_nodes": false,
        "lcc_only": false
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "use_lcc": true,
        "seed": 3735928559
    },
    "umap": {
        "enabled": false
    },
    "local_search": {
        "prompt": "prompts/local_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "text_unit_prop": 0.5,
        "community_prop": 0.15,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "global_search": {
        "map_prompt": "prompts/global_search_map_system_prompt.txt",
        "reduce_prompt": "prompts/global_search_reduce_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "knowledge_prompt": "prompts/global_search_knowledge_system_prompt.txt",
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_tokens": 1000,
        "reduce_max_tokens": 2000,
        "concurrency": 32,
        "dynamic_search_llm": "gpt-4o-mini",
        "dynamic_search_threshold": 1,
        "dynamic_search_keep_parent": false,
        "dynamic_search_num_repeats": 1,
        "dynamic_search_use_summary": false,
        "dynamic_search_concurrent_coroutines": 16,
        "dynamic_search_max_level": 2
    },
    "drift_search": {
        "prompt": "prompts/drift_search_system_prompt.txt",
        "reduce_prompt": "prompts/drift_search_reduce_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "reduce_max_tokens": 2000,
        "reduce_temperature": 0,
        "concurrency": 32,
        "drift_k_followups": 20,
        "primer_folds": 5,
        "primer_llm_max_tokens": 12000,
        "n_depth": 3,
        "local_search_text_unit_prop": 0.9,
        "local_search_community_prop": 0.1,
        "local_search_top_k_mapped_entities": 10,
        "local_search_top_k_relationships": 10,
        "local_search_max_data_tokens": 12000,
        "local_search_temperature": 0,
        "local_search_top_p": 1,
        "local_search_n": 1,
        "local_search_llm_max_gen_tokens": 4096
    },
    "basic_search": {
        "prompt": "prompts/basic_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "text_unit_prop": 0.5,
        "conversation_history_max_turns": 5,
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "vector_store": {
        "default_vector_store": {
            "type": "lancedb",
            "db_uri": "E:\\_MyCollegeLife\\_3rd_2\\inf_model_GraphRag\\ragtest\\output\\lancedb",
            "url": null,
            "audience": null,
            "container_name": "==== REDACTED ====",
            "database_name": null,
            "overwrite": true
        }
    },
    "workflows": null
}
16:23:10,245 graphrag.storage.file_pipeline_storage INFO Creating file storage at E:\_MyCollegeLife\_3rd_2\inf_model_GraphRag\ragtest\output
16:23:10,246 graphrag.index.input.factory INFO loading input from root_dir=input
16:23:10,246 graphrag.index.input.factory INFO using file storage for input
16:23:10,248 graphrag.storage.file_pipeline_storage INFO search E:\_MyCollegeLife\_3rd_2\inf_model_GraphRag\ragtest\input for files matching .*\.(txt|md)$
16:23:10,259 graphrag.index.input.util INFO Found 1 InputFileType.text files, loading 1
16:23:10,259 graphrag.index.input.util INFO Total number of unfiltered InputFileType.text rows: 1
16:23:10,262 graphrag.index.run.run_pipeline INFO Final # of rows loaded: 1
16:23:10,284 graphrag.utils.storage INFO reading table from storage: documents.parquet
16:23:10,677 graphrag.utils.storage INFO reading table from storage: documents.parquet
16:23:10,687 graphrag.utils.storage INFO reading table from storage: text_units.parquet
16:23:10,747 graphrag.utils.storage INFO reading table from storage: text_units.parquet
16:23:12,466 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:23:13,277 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:23:20,712 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:23:21,988 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:23:23,635 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:23:24,481 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:23:24,851 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:23:29,747 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:23:31,812 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:23:32,286 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:23:32,675 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:23:33,265 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:23:33,462 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:23:35,811 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:23:36,659 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:23:36,967 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:23:37,794 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:23:39,4 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:23:41,541 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:23:42,379 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:23:43,704 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:23:44,7 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:23:44,810 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:23:45,532 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:23:46,457 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:23:46,668 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:23:47,447 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:23:48,629 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:23:48,700 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:23:49,814 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:23:50,21 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:23:50,560 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:23:50,888 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:23:50,937 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:23:52,925 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:23:53,824 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:23:54,641 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:23:55,397 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:23:57,218 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:23:58,19 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:23:58,150 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:23:58,931 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:23:58,947 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:23:59,56 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:23:59,893 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:23:59,923 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:24:01,560 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:24:02,336 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:24:04,318 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:24:05,299 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:24:05,552 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:24:06,154 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:24:06,364 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:24:07,72 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:24:07,613 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:24:07,710 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:24:08,12 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:24:09,672 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:24:10,699 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:24:10,766 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:24:11,226 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:24:11,279 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:24:12,244 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:24:12,280 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:24:12,328 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:24:13,59 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:24:15,652 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:24:16,179 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:24:16,219 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:24:16,370 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:24:16,495 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:24:16,566 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:24:17,73 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:24:17,169 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:24:17,581 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:24:18,314 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:24:18,367 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:24:19,779 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:24:20,421 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:24:20,676 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:24:20,902 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:24:21,647 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:24:21,774 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:24:23,5 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:24:23,767 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:24:24,686 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:24:24,815 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:24:24,817 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:24:25,605 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:24:25,744 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:24:27,517 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:24:27,619 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:24:27,644 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:24:27,814 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:24:28,432 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:24:28,585 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:24:28,605 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:24:28,716 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:24:29,761 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:24:30,539 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:24:30,935 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:24:31,744 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:24:32,146 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:24:32,563 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:24:34,463 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:24:35,275 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:24:35,340 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:24:36,156 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:24:37,669 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:24:37,897 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:24:38,392 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:24:38,818 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:24:39,141 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:24:39,650 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:24:42,392 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:24:42,449 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:24:42,600 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:24:43,132 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:24:43,389 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:24:43,432 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:24:43,533 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:24:44,356 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:24:45,371 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:24:46,347 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:24:46,851 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:24:47,86 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:24:47,678 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:24:48,173 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:24:48,420 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:24:48,627 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:24:48,873 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:24:48,944 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:24:49,19 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:24:49,439 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:24:49,860 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:24:53,159 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:24:53,534 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:24:53,549 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:24:54,51 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:24:54,494 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:24:56,148 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:24:56,659 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:24:57,157 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:24:57,169 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:24:57,390 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:24:57,670 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:24:57,723 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:24:58,601 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:25:00,320 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:25:00,411 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:25:00,695 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:25:00,836 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:25:01,35 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:25:01,859 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:25:01,939 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:25:02,49 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:25:02,958 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:25:03,898 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:25:07,89 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:25:08,503 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:25:09,481 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:25:09,496 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:25:10,187 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:25:10,292 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:25:10,883 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:25:11,135 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:25:13,244 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:25:13,692 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:25:14,92 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:25:14,218 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:25:15,128 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:25:15,715 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:25:16,45 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:25:16,429 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:25:16,787 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:25:17,88 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:25:17,273 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:25:17,899 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:25:18,632 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:25:20,477 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:25:20,689 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:25:20,983 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:25:21,293 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:25:21,348 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:25:21,664 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:25:21,892 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:25:22,140 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:25:22,224 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:25:22,761 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:25:23,422 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:25:24,669 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:25:24,978 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:25:25,73 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:25:25,154 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:25:25,426 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:25:25,856 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:25:25,961 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:25:26,340 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:25:27,268 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:25:28,634 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:25:29,650 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:25:30,901 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:25:31,271 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:25:31,422 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:25:31,960 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:25:32,346 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:25:32,848 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:25:33,18 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:25:33,649 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:25:35,661 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:25:35,728 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:25:35,730 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:25:36,704 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:25:37,77 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:25:39,319 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:25:40,114 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:25:41,491 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:25:42,105 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:25:42,732 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:25:43,544 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:25:46,385 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:25:46,841 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:25:47,61 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:25:47,294 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:25:47,688 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:25:48,122 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:25:48,502 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:25:49,30 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:25:49,122 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:25:49,973 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:25:51,58 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:25:52,502 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:25:52,802 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:25:53,661 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:25:53,714 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:25:57,207 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:25:59,206 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:25:59,482 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:25:59,529 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:26:00,606 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:26:00,660 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:26:01,383 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:26:03,871 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:26:04,332 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:26:04,783 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:26:07,457 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:26:07,605 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:26:10,61 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:26:10,237 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:26:11,250 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:26:12,137 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:26:12,375 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:26:13,263 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:26:14,936 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:26:15,187 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:26:15,723 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:26:15,825 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:26:16,60 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:26:16,174 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:26:16,488 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:26:17,233 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:26:18,458 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:26:19,572 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:26:19,617 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:26:19,716 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:26:19,982 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:26:20,327 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:26:20,346 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:26:21,596 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:26:22,718 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:26:23,466 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:26:23,535 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:26:23,560 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:26:24,479 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:26:26,77 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:26:26,470 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:26:26,962 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:26:27,365 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:26:28,110 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:26:28,603 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:26:29,269 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:26:29,449 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:26:29,661 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:26:30,764 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:26:32,610 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:26:32,612 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:26:34,640 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:26:35,482 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:26:36,2 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:26:36,595 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:26:37,389 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:26:38,196 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:26:43,864 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:26:43,904 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:26:44,173 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:26:44,677 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:26:47,154 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:26:47,949 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:26:48,212 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:26:48,412 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:26:48,823 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:26:49,240 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:26:49,528 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:26:51,60 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:26:52,198 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:26:53,107 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:26:53,452 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:26:53,971 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:26:54,98 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:26:54,285 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:26:56,371 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:26:57,302 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:26:58,205 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:26:59,462 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:27:00,259 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:27:00,583 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:27:00,757 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:27:01,539 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:27:04,976 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:27:05,203 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:27:05,918 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:27:06,197 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:27:07,97 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:27:07,478 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:27:08,433 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:27:09,383 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:27:09,563 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:27:10,114 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:27:10,598 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:27:10,786 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:27:11,68 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:27:13,420 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:27:14,321 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:27:14,876 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:27:15,717 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:27:16,428 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:27:17,341 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:27:18,930 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:27:19,206 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:27:19,788 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:27:20,60 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:27:20,139 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:27:20,737 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:27:20,939 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:27:23,352 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:27:24,83 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:27:24,419 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:27:24,982 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:27:25,15 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:27:26,743 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:27:28,782 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:27:29,545 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:27:30,402 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:27:31,216 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:27:32,355 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:27:35,289 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:27:36,320 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:27:39,112 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:27:40,397 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:27:41,593 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:27:41,882 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:27:42,115 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:27:42,927 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:27:44,9 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:27:44,728 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:27:44,838 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:27:45,975 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:27:46,830 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:27:47,444 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:27:47,486 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:27:47,565 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:27:48,727 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:27:51,50 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:27:51,628 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:27:52,0 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:27:52,916 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:27:52,927 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:27:53,690 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:27:53,826 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:27:54,530 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:27:57,109 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:27:57,143 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:27:57,776 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:27:57,928 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:27:58,62 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:27:58,78 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:27:58,448 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:27:58,627 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:27:58,786 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:27:59,347 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:27:59,853 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:28:00,916 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:28:01,109 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:28:01,851 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:28:02,714 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:28:03,97 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:28:03,624 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:28:03,790 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:28:03,927 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:28:04,8 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:28:04,453 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:28:04,804 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:28:08,195 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:28:09,177 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:28:10,423 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:28:11,338 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:28:12,727 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:28:13,76 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:28:13,705 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:28:13,976 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:28:14,50 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:28:14,326 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:28:15,191 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:28:17,897 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:28:18,793 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:28:18,801 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:28:19,374 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:28:20,561 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:28:21,50 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:28:21,209 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:28:21,420 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:28:21,559 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:28:22,210 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:28:22,227 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:28:22,818 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:28:23,309 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:28:24,67 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:28:25,60 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:28:25,214 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:28:25,327 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:28:25,921 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:28:26,285 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:28:26,337 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:28:27,990 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:28:28,994 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:28:29,14 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:28:29,863 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:28:30,122 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:28:31,29 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:28:31,412 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:28:31,657 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:28:32,486 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:28:33,85 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:28:34,135 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:28:36,39 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:28:36,50 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:28:36,223 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:28:36,905 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:28:37,25 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:28:37,634 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:28:38,534 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:28:38,599 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:28:39,412 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:28:39,509 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:28:40,109 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:28:40,388 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:28:40,880 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:28:41,25 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:28:41,621 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:28:42,916 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:28:43,34 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:28:43,738 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:28:44,58 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:28:47,409 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:28:47,689 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:28:48,312 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:28:48,423 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:28:48,565 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:28:49,248 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:28:49,380 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:28:51,148 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:28:51,220 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:28:51,929 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:28:52,77 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:28:55,589 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:28:55,611 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:28:55,966 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:28:56,457 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:28:56,917 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:28:57,758 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:28:59,23 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:28:59,78 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:28:59,946 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:29:00,37 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:29:00,218 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:29:00,629 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:29:01,248 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:29:01,729 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:29:02,132 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:29:02,716 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:29:03,248 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:29:03,683 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:29:04,77 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:29:04,256 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:29:04,950 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:29:05,70 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:29:06,859 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:29:06,909 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:29:06,972 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:29:07,682 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:29:07,810 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:29:07,838 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:29:08,162 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:29:08,405 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:29:08,717 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:29:09,164 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:29:11,248 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:29:12,209 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:29:12,254 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:29:13,230 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:29:14,895 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:29:15,170 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:29:15,729 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:29:16,94 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:29:16,947 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:29:17,844 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:29:18,268 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:29:19,113 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:29:19,154 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:29:19,671 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:29:20,128 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:29:20,349 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:29:20,447 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:29:21,67 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:29:21,226 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:29:22,17 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:29:22,897 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:29:23,604 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:29:23,754 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:29:24,596 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:29:27,889 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:29:29,88 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:29:30,475 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:29:30,583 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:29:31,787 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:29:31,944 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:29:32,162 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:29:32,214 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:29:32,259 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:29:32,848 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:29:33,96 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:29:33,268 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:29:33,346 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:29:33,605 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:29:34,86 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:29:34,654 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:29:34,888 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:29:35,839 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:29:35,931 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:29:35,996 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:29:36,785 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:29:37,247 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:29:37,408 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:29:37,540 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:29:37,800 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:29:38,271 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:29:38,669 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:29:38,740 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:29:39,426 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:29:40,368 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:29:40,425 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:29:40,519 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:29:41,195 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:29:41,433 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:29:43,999 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:29:44,637 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:29:44,836 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:29:45,148 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:29:45,754 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:29:45,769 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:29:46,384 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:29:46,667 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:29:46,731 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:29:46,797 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:29:47,172 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:29:47,988 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:29:49,655 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:29:50,48 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:29:50,739 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:29:51,241 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:29:51,256 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:29:51,549 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:29:52,550 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:29:53,695 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:29:53,819 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:29:54,550 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:29:54,839 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:29:54,924 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:29:57,582 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:29:58,880 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:29:59,678 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:30:02,460 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:30:03,93 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:30:03,510 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:30:03,518 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:30:04,368 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:30:04,547 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:30:05,618 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:30:06,354 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:30:07,137 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:30:07,264 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:30:07,903 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:30:09,466 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:30:10,224 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:30:11,124 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:30:11,991 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:30:13,724 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:30:14,29 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:30:14,416 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:30:14,492 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:30:14,804 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:30:14,896 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:30:15,214 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:30:15,818 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:30:16,635 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:30:16,636 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:30:17,790 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:30:18,32 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:30:18,470 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:30:20,864 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:30:20,970 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:30:21,745 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:30:21,798 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:30:26,461 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:30:28,364 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:30:29,367 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:30:29,794 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:30:30,791 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:30:31,910 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:30:34,902 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:30:36,111 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:30:38,909 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:30:39,402 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:30:39,680 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:30:39,834 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:30:39,860 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:30:40,552 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:30:40,567 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:30:40,769 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:30:41,376 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:30:41,522 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:30:42,578 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:30:43,147 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:30:43,495 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:30:44,339 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:30:44,744 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:30:44,873 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:30:49,40 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:30:49,378 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:30:50,237 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:30:50,756 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:30:51,125 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:30:52,3 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:30:52,102 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:30:56,403 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:30:57,56 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:30:57,197 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:30:57,406 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:30:57,926 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:30:58,672 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:31:00,381 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:31:00,700 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:31:01,560 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:31:03,199 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:31:03,295 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:31:04,110 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:31:06,981 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:31:07,539 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:31:07,805 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:31:07,844 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:31:08,257 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:31:08,356 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:31:08,435 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:31:09,0 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:31:09,293 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:31:09,861 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:31:11,600 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:31:12,213 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:31:12,473 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:31:15,369 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:31:16,168 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:31:16,641 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:31:16,914 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:31:18,246 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:31:18,258 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:31:19,855 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:31:20,842 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:31:21,747 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:31:22,345 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:31:24,26 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:31:27,323 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:31:27,588 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:31:27,937 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:31:28,301 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:31:28,799 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:31:30,120 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:31:30,881 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:31:34,725 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:31:35,908 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:31:36,530 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:31:36,726 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:31:37,831 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:31:40,212 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:31:41,642 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:31:42,125 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:31:43,106 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:31:43,537 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:31:44,592 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:31:45,461 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:31:49,148 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:31:50,133 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:31:50,518 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:31:51,25 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:31:51,199 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:31:51,400 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:31:52,129 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:31:52,217 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:31:52,973 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:31:53,88 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:31:53,834 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:31:54,132 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:31:54,234 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:31:54,852 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:31:54,963 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:31:55,105 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:31:55,745 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:31:55,976 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:31:55,979 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:31:56,710 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:31:56,848 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:31:56,877 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:31:56,913 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:31:56,984 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:31:57,643 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:31:57,850 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:31:58,26 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:31:58,207 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:31:58,893 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:31:59,992 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:32:00,725 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:32:00,834 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:32:01,403 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:32:01,424 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:32:01,793 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:32:02,216 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:32:02,217 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:32:03,346 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:32:04,533 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:32:04,906 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:32:05,673 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:32:07,6 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:32:07,864 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:32:08,198 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:32:08,231 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:32:08,831 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:32:09,29 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:32:09,758 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:32:12,633 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:32:12,823 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:32:13,597 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:32:15,211 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:32:15,915 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:32:16,42 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:32:17,653 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:32:17,987 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:32:18,554 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:32:19,970 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:32:20,71 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:32:21,54 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:32:22,346 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:32:22,475 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:32:23,170 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:32:25,645 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:32:26,25 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:32:27,327 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:32:28,171 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:32:29,256 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:32:29,400 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:32:30,68 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:32:30,420 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:32:31,625 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:32:31,652 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:32:31,897 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:32:32,479 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:32:32,942 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:32:33,14 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:32:33,508 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:32:33,759 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:32:33,925 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:32:34,356 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:32:34,653 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:32:36,474 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:32:37,4 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:32:37,295 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:32:37,351 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:32:37,433 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:32:37,471 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:32:37,848 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:32:38,340 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:32:38,453 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:32:39,244 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:32:40,323 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:32:40,852 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:32:41,297 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:32:41,659 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:32:42,477 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:32:42,569 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:32:42,673 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:32:43,548 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:32:44,385 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:32:44,420 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:32:45,254 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:32:45,307 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:32:46,994 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:32:48,360 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:32:48,517 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:32:48,972 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:32:51,855 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:32:55,202 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:32:55,628 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:32:56,62 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:32:56,548 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:32:57,578 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:32:57,996 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:33:00,56 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:33:00,188 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:33:01,398 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:33:02,610 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:33:03,521 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:33:04,884 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:33:04,924 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:33:05,850 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:33:06,198 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:33:07,519 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:33:07,901 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:33:08,396 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:33:08,432 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:33:09,388 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:33:11,779 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:33:12,685 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:33:13,722 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:33:14,931 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:33:15,62 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:33:19,197 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:33:19,912 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:33:20,842 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:33:21,134 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:33:21,914 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:33:21,938 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:33:22,523 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:33:25,117 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:33:25,230 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:33:25,362 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:33:28,169 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:33:31,211 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:33:32,675 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:33:33,461 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:33:33,948 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:33:34,746 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:33:34,802 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:33:38,765 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:33:39,934 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:33:41,112 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:33:42,316 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:33:43,341 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:33:43,493 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:33:44,335 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:33:44,511 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:33:46,396 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:33:47,308 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:33:47,757 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:33:47,987 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:33:48,544 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:33:49,624 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:33:49,683 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:33:50,387 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:33:50,570 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:33:50,607 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:33:51,438 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:33:51,628 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:33:52,185 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:33:52,532 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:33:52,626 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:33:53,130 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:33:53,946 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:33:53,973 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:33:54,750 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:33:54,851 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:33:55,718 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:33:55,892 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:33:56,692 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:33:56,772 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:33:57,471 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:33:57,514 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:33:57,664 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:33:58,355 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:33:58,712 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:33:59,693 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:34:00,556 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:34:00,633 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:34:01,481 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:34:01,561 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:34:02,428 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:34:02,545 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:34:03,471 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:34:03,920 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:34:04,563 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:34:04,931 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:34:05,160 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:34:05,215 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:34:05,282 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:34:05,819 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:34:06,154 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:34:06,707 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:34:06,811 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:34:07,308 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:34:08,358 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:34:08,402 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:34:08,687 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:34:08,880 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:34:09,174 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:34:09,633 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:34:09,726 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:34:10,543 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:34:10,749 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:34:11,355 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:34:12,52 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:34:12,67 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:34:12,195 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:34:12,276 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:34:12,320 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:34:13,90 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:34:16,979 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:34:17,413 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:34:17,868 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:34:18,512 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:34:20,949 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:34:21,817 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:34:22,464 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:34:22,468 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:34:22,480 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:34:23,340 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:34:24,31 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:34:24,223 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:34:25,101 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:34:25,167 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:34:25,470 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:34:25,591 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:34:25,790 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:34:29,542 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:34:29,749 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:34:30,944 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:34:31,12 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:34:34,707 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:34:37,780 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:34:41,247 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:34:46,270 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:34:55,788 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:35:01,416 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:35:02,83 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:35:03,548 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:35:31,558 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:35:32,90 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:35:41,130 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:35:45,755 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:35:46,145 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:35:51,650 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:35:51,743 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:35:59,136 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:36:08,547 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:36:13,250 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:36:23,45 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:36:31,431 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:36:32,414 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:36:42,621 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:36:52,842 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:36:53,26 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:36:53,710 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:36:58,757 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:37:03,15 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:37:07,403 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:37:15,618 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:37:22,403 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:37:28,429 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:37:34,62 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:37:37,385 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:37:43,539 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:37:49,628 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:37:54,147 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:37:57,50 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:38:00,523 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:38:02,376 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:38:10,738 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:38:11,436 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:38:11,921 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:38:21,130 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:38:38,168 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:38:39,81 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:38:40,754 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:38:41,74 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:38:44,471 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:38:44,560 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:38:57,508 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:38:59,314 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:39:01,305 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:39:03,323 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:39:07,188 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:39:09,602 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:39:10,445 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:39:12,449 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:39:16,240 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:39:17,746 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:39:18,853 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:39:21,621 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:39:23,990 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:39:25,734 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:39:29,990 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:39:35,230 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:39:35,704 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:39:37,306 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:39:40,516 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:39:45,777 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:39:45,907 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:39:50,681 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:40:05,616 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:40:08,518 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:40:08,845 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:40:11,63 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:40:15,706 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:40:18,228 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:40:25,35 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:40:27,997 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:40:31,975 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:40:35,178 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:40:38,997 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:40:39,432 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:40:45,327 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:40:45,806 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:40:45,823 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:40:47,242 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:40:54,862 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:40:57,565 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:40:58,792 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:40:59,352 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:41:00,217 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:41:05,521 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:41:06,453 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:41:20,719 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:41:21,170 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:41:29,405 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:41:39,805 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:42:05,794 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:42:08,63 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:42:10,969 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:42:15,578 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:42:15,946 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:42:16,569 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:42:17,468 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:42:17,607 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:42:17,839 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:42:18,71 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:42:19,614 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:42:21,130 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:42:21,771 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:42:22,85 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:42:22,120 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:42:22,183 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:42:22,788 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:42:22,790 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:42:23,601 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:42:24,526 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:42:25,85 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:42:25,728 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:42:26,484 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:42:26,593 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:42:26,676 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:42:27,568 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:42:27,813 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:42:28,163 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:42:28,641 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:42:29,919 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:42:31,227 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:42:32,333 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:42:32,414 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:42:32,656 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:42:32,697 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:42:32,886 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:42:32,927 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:42:33,663 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:42:35,653 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:42:35,968 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:42:36,927 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:42:37,437 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:42:37,978 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:42:38,54 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:42:38,314 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:42:38,619 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:42:39,580 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:42:40,18 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:42:40,227 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:42:41,767 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:42:42,531 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:42:42,846 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:42:43,168 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:42:43,667 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:42:44,539 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:42:45,939 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:42:46,342 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:42:46,996 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:42:47,570 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:42:48,308 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:42:48,527 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:42:49,270 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:42:50,325 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:42:50,738 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:42:51,653 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:42:51,742 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:42:52,473 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:42:52,555 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:42:53,11 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:42:53,92 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:42:53,181 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:42:53,700 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:42:53,733 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:42:55,200 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:42:55,916 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:42:56,253 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:42:57,745 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:42:58,157 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:42:58,313 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:42:58,334 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:42:58,427 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:42:59,515 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:43:00,18 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:43:00,444 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:43:01,272 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:43:01,700 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:43:02,506 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:43:03,296 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:43:04,152 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:43:04,521 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:43:05,407 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:43:05,449 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:43:05,596 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:43:06,479 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:43:06,585 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:43:07,65 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:43:07,761 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:43:09,863 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:43:10,176 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:43:10,206 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:43:10,363 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:43:10,838 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:43:11,24 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:43:11,48 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:43:11,78 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:43:11,564 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:43:11,936 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:43:13,249 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:43:13,960 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:43:14,280 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:43:14,580 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:43:15,402 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:43:16,147 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:43:16,201 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:43:16,345 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:43:16,480 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:43:17,162 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:43:17,179 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:43:17,203 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:43:17,938 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:43:18,283 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:43:19,774 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:43:20,139 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:43:20,206 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:43:20,552 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:43:21,636 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:43:21,699 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:43:22,299 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:43:22,726 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:43:24,271 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:43:24,272 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:43:24,404 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:43:25,361 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:43:25,690 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:43:26,887 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:43:27,363 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:43:27,672 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:43:27,716 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:43:28,318 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:43:29,157 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:43:29,244 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:43:29,615 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:43:29,784 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:43:30,310 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:43:30,491 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:43:31,645 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:43:31,935 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:43:33,85 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:43:33,398 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:43:33,993 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:43:34,95 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:43:34,158 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:43:34,918 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:43:35,253 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:43:35,775 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:43:36,245 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:43:36,723 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:43:37,887 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:43:38,139 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:43:39,440 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:43:39,468 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:43:39,746 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:43:39,758 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:43:40,29 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:43:42,194 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:43:42,324 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:43:43,189 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:43:43,288 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:43:43,962 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:43:44,279 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:43:44,652 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:43:45,233 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:43:45,353 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:43:46,219 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:43:47,350 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:43:47,635 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:43:47,754 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:43:48,451 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:43:48,605 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:43:49,40 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:43:49,544 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:43:49,653 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:43:51,172 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:43:51,655 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:43:51,955 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:43:52,220 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:43:52,447 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:43:52,490 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:43:52,951 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:43:54,273 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:43:54,378 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:43:55,867 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:43:56,292 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:43:56,338 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:43:56,658 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:43:56,930 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:43:57,307 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:43:57,332 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:43:57,461 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:43:57,646 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:43:58,221 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:44:01,89 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:44:01,187 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:44:01,767 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:44:02,194 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:44:02,693 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:44:03,249 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:44:03,698 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:44:03,815 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:44:03,941 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:44:04,35 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:44:04,532 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:44:05,22 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:44:07,157 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:44:07,190 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:44:07,540 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:44:07,541 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:44:07,693 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:44:07,961 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:44:08,119 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:44:09,195 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:44:09,794 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:44:10,567 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:44:11,135 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:44:11,157 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:44:11,193 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:44:11,476 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:44:12,475 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:44:12,951 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:44:13,674 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:44:15,254 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:44:15,380 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:44:16,47 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:44:16,201 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:44:16,940 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:44:16,997 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:44:17,458 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:44:17,654 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:44:17,840 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:44:18,386 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:44:19,160 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:44:19,569 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:44:21,36 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:44:21,85 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:44:22,127 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:44:22,274 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:44:22,314 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:44:22,730 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:44:22,967 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:44:23,307 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:44:23,536 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:44:24,627 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:44:25,257 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:44:25,555 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:44:25,867 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:44:26,394 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:44:27,22 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:44:27,666 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:44:28,74 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:44:28,278 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:44:28,286 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:44:29,793 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:44:30,184 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:44:30,478 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:44:30,874 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:44:30,968 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:44:31,177 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:44:31,596 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:44:31,774 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:44:32,325 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:44:32,519 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:44:32,884 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:44:34,235 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:44:34,753 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:44:34,922 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:44:35,540 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:44:35,884 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:44:36,163 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:44:37,286 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:44:38,685 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:44:38,993 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:44:39,101 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:44:39,179 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:44:39,535 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:44:39,950 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:44:41,125 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:44:41,740 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:44:42,164 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:44:43,291 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:44:43,420 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:44:43,644 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:44:44,672 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:44:44,790 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:44:45,196 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:44:45,335 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:44:46,355 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:44:47,56 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:44:47,421 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:44:47,484 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:44:47,768 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:44:47,830 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:44:48,18 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:44:48,141 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:44:48,525 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:44:49,226 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:44:49,504 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:44:50,263 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:44:51,176 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:44:52,123 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:44:52,371 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:44:52,925 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:44:53,780 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:44:53,942 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:44:54,263 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:44:55,563 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:44:55,760 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:44:56,907 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:44:56,981 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:44:57,312 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:44:58,279 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:44:58,607 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:44:58,670 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:44:59,993 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:45:00,419 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:45:01,55 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:45:01,943 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:45:02,306 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:45:02,959 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:45:03,454 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:45:03,787 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:45:03,896 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:45:03,946 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:45:04,89 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:45:04,200 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:45:05,317 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:45:05,354 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:45:06,691 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:45:07,522 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:45:07,640 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:45:08,169 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:45:08,276 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:45:08,624 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:45:08,813 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:45:09,943 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:45:10,21 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:45:11,581 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:45:11,766 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:45:11,906 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:45:12,85 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:45:14,949 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:45:15,61 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:45:15,178 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:45:15,220 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:45:15,665 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:45:15,700 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:45:17,399 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:45:17,596 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:45:17,973 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:45:18,195 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:45:18,517 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:45:18,626 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:45:18,626 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:45:18,888 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:45:19,38 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:45:19,641 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:45:20,658 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:45:21,243 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:45:21,598 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:45:21,724 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:45:22,313 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:45:22,423 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:45:22,944 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:45:23,682 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:45:23,847 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:45:24,41 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:45:24,911 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:45:24,986 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:45:25,558 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:45:26,468 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:45:26,472 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:45:26,839 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:45:27,696 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:45:28,814 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:45:29,161 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:45:29,170 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:45:29,257 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:45:29,606 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:45:29,632 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:45:30,757 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:45:31,888 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:45:32,383 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:45:32,646 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:45:32,805 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:45:32,813 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:45:32,851 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:45:33,248 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:45:33,260 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:45:33,572 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:45:35,37 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:45:35,502 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:45:35,648 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:45:35,778 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:45:36,261 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:45:36,628 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:45:36,720 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:45:37,663 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:45:37,928 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:45:37,983 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:45:38,690 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:45:39,148 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:45:39,428 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:45:40,229 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:45:40,629 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:45:40,837 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:45:41,426 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:45:41,665 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:45:41,711 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:45:41,897 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:45:45,494 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:45:45,821 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:45:46,233 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:45:46,558 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:45:46,704 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:45:46,843 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:45:46,916 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:45:46,945 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:45:47,107 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:45:47,311 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:45:49,687 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:45:50,206 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:45:50,353 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:45:50,380 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:45:50,430 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:45:51,220 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:45:51,458 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:45:51,654 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:45:53,108 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:45:54,370 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:45:54,397 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:45:54,722 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:45:54,913 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:45:55,319 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:45:55,563 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:45:55,738 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:45:55,868 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:45:56,323 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:45:57,616 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:45:57,715 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:45:57,770 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:45:59,35 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:45:59,279 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:45:59,307 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:45:59,919 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:46:00,220 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:46:00,956 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:46:00,991 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:46:00,998 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:46:01,848 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:46:01,888 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:46:02,141 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:46:02,771 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:46:03,390 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:46:04,767 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:46:04,904 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:46:05,332 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:46:05,341 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:46:05,344 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:46:06,387 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:46:06,615 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:46:06,671 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:46:07,169 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:46:07,627 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:46:08,11 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:46:08,137 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:46:08,840 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:46:09,85 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:46:09,248 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:46:09,328 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:46:10,139 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:46:10,364 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:46:10,597 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:46:10,641 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:46:11,773 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:46:12,72 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:46:12,863 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:46:13,143 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:46:13,550 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:46:13,586 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:46:13,731 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:46:14,480 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:46:14,546 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:46:15,95 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:46:15,483 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:46:16,169 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:46:17,28 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:46:17,87 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:46:18,179 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:46:18,316 graphrag.utils.storage INFO reading table from storage: entities.parquet
16:46:18,332 graphrag.utils.storage INFO reading table from storage: relationships.parquet
16:46:18,512 graphrag.utils.storage INFO reading table from storage: entities.parquet
16:46:18,522 graphrag.utils.storage INFO reading table from storage: relationships.parquet
16:46:18,719 graphrag.utils.storage INFO reading table from storage: text_units.parquet
16:46:18,733 graphrag.utils.storage INFO reading table from storage: entities.parquet
16:46:18,742 graphrag.utils.storage INFO reading table from storage: relationships.parquet
16:46:18,879 graphrag.utils.storage INFO reading table from storage: relationships.parquet
16:46:18,888 graphrag.utils.storage INFO reading table from storage: entities.parquet
16:46:18,896 graphrag.utils.storage INFO reading table from storage: communities.parquet
16:46:18,934 graphrag.index.operations.summarize_communities.graph_context.context_builder INFO Number of nodes at level=2 => 173
16:46:19,230 graphrag.index.operations.summarize_communities.graph_context.context_builder INFO Number of nodes at level=1 => 653
16:46:20,348 graphrag.index.operations.summarize_communities.graph_context.context_builder INFO Number of nodes at level=0 => 659
16:46:40,790 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:46:42,552 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:46:42,952 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:46:45,234 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:46:45,363 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:46:45,606 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:46:46,174 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:46:48,28 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:46:50,376 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:46:59,872 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:47:00,142 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:47:01,285 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:47:02,576 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:47:03,432 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:47:04,954 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:47:07,943 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:47:11,678 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:47:14,372 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:47:15,852 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:47:18,143 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:47:18,258 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:47:24,799 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:47:27,468 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:47:32,837 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:47:33,386 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:47:33,683 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:47:34,276 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:47:34,826 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:47:36,399 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:47:36,456 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:47:36,469 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:47:44,916 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:47:50,941 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:47:50,950 graphrag.index.operations.summarize_communities.community_reports_extractor ERROR error generating community report
Traceback (most recent call last):
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\services\json.py", line 126, in _parse_json_string
    return json.loads(value) if value else None
           ^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\__init__.py", line 346, in loads
    return _default_decoder.decode(s)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\services\json.py", line 96, in invoke_json
    return await self.try_receive_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\services\json.py", line 114, in try_receive_json
    raw_json = self._parse_json_string(json_string)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\services\json.py", line 129, in _parse_json_string
    raise FailedToGenerateValidJsonError(msg) from err
fnllm.base.services.errors.FailedToGenerateValidJsonError: JSON response is not a valid JSON, response=```json
{
    "title": "Information Theory Community: X, Uniform Coin, and Entropy",
    "summary": "The community is centered around the random variable X, which is generated using a uniform coin and mapped to outcomes via a tree. The entropy function H is applied to X, and STOP is used in its encoding. The relationships between these entities are fundamental to understanding information theory, communication systems, and statistical dependencies.",
    "rating": 8.5,
    "rating_explanation": "The impact severity rating is high due to the foundational role of these entities in information theory and communication systems.",
    "findings": [
        {
            "summary": "Central role of random variable X",
            "explanation": "Random variable X is the central entity in this community, playing a key role in information theory and communication systems. X is used to represent input signals or transmitted codewords, and its relationship with Y (the output signal) is crucial for understanding noise effects and statistical dependencies. The joint typicality of X and Y is used to calculate mutual information and conditional entropy, which are fundamental metrics in these fields. [Data: Entities (102), Relationships (109, 243, 244, 260, 532)]"
        },
        {
            "summary": "Uniform coin as a generator of X",
            "explanation": "The uniform coin is used to generate sequences of bits that are then used to create the random variable X. This process ensures that X has specific probability density functions, which are essential for modeling and analysis in information theory. The uniform coin's role in generating X highlights its importance in the community. [Data: Entities (238), Relationships (243)]"
        },
        {
            "summary": "Tree mapping bits to X",
            "explanation": "A tree is used to map sequences of bits generated by the uniform coin to the random variable X. This mapping ensures that the algorithm meets specific properties, such as non-singularity and efficiency in encoding. The tree's role in this process underscores its significance in the community. [Data: Entities (239), Relationships (244)]"
        },
        {
            "summary": "STOP character in encoding X",
            "explanation": "The STOP character is used in the encoding of the random variable X, particularly in non-singular binary codes. This character indicates the end of a codeword, ensuring that the encoding process is efficient and unambiguous. The use of STOP in encoding X highlights its importance in the community. [Data: Entities (250), Relationships (260)]"
        },
        {
            "summary": "Entropy function H applied to X",
            "explanation": "The entropy function H is applied to the binary source X, representing the uncertainty or information content of X. Entropy is a fundamental concept in information theory, used to measure the efficiency of data compression and the capacity of communication channels. The application of H to X underscores its critical role in the community. [Data: Entities (467), Relationships (532)]"
        }
    ]
}
```.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\services\json.py", line 77, in invoke
    return await this.invoke_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\services\json.py", line 100, in invoke_json
    raise FailedToGenerateValidJsonError from error
fnllm.base.services.errors.FailedToGenerateValidJsonError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\graphrag\index\operations\summarize_communities\community_reports_extractor.py", line 80, in __call__
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\graphrag\language_model\providers\fnllm\models.py", line 81, in achat
    response = await self.model(prompt, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\openai\llm\openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\openai\services\openai_tools_parsing.py", line 130, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\base_llm.py", line 148, in __call__
    await self._events.on_error(
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\graphrag\language_model\providers\fnllm\events.py", line 26, in on_error
    self._on_error(error, traceback, arguments)
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\graphrag\language_model\providers\fnllm\utils.py", line 45, in on_error
    callbacks.error("Error Invoking LLM", error, stack, details)
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\graphrag\callbacks\workflow_callbacks_manager.py", line 64, in error
    callback.error(message, cause, stack, details)
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\graphrag\callbacks\file_workflow_callbacks.py", line 37, in error
    json.dumps(
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\__init__.py", line 238, in dumps
    **kw).encode(obj)
          ^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 202, in encode
    chunks = list(chunks)
             ^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 432, in _iterencode
    yield from _iterencode_dict(o, _current_indent_level)
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 406, in _iterencode_dict
    yield from chunks
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 406, in _iterencode_dict
    yield from chunks
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 406, in _iterencode_dict
    yield from chunks
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 439, in _iterencode
    o = _default(o)
        ^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 180, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
TypeError: Object of type ModelMetaclass is not JSON serializable
16:47:50,963 graphrag.callbacks.file_workflow_callbacks INFO Community Report Extraction Error details=None
16:47:50,963 graphrag.index.operations.summarize_communities.strategies WARNING No report found for community: 127.0
16:47:51,709 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:47:53,871 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:47:55,164 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:47:57,220 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:47:57,270 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:47:58,974 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:47:59,56 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:48:06,349 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:48:06,916 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:48:08,165 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:48:08,595 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:48:11,359 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:48:15,822 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:48:17,94 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:48:17,98 graphrag.index.operations.summarize_communities.community_reports_extractor ERROR error generating community report
Traceback (most recent call last):
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\services\json.py", line 126, in _parse_json_string
    return json.loads(value) if value else None
           ^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\__init__.py", line 346, in loads
    return _default_decoder.decode(s)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\services\json.py", line 96, in invoke_json
    return await self.try_receive_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\services\json.py", line 114, in try_receive_json
    raw_json = self._parse_json_string(json_string)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\services\json.py", line 129, in _parse_json_string
    raise FailedToGenerateValidJsonError(msg) from err
fnllm.base.services.errors.FailedToGenerateValidJsonError: JSON response is not a valid JSON, response=```json
{
    "title": "Communication Channel and Decoder Community",
    "summary": "This community centers around communication channels and decoders, with key entities including the DECODER, Binary Erasure Channel (BEC), and Binary Erasure Multiple Access Channel. These entities are interconnected through relationships that highlight their roles in data transmission and decoding processes, emphasizing their importance in communication systems.",
    "rating": 7.5,
    "rating_explanation": "The impact severity rating is high due to the critical role these entities play in ensuring reliable communication and data transmission.",
    "findings": [
        {
            "summary": "DECODER's pivotal role in communication systems",
            "explanation": "The DECODER is a crucial component within communication systems, responsible for processing and interpreting received messages. Its primary function is to map received sequences back to the original messages, ensuring accurate and reliable communication. This makes the DECODER an essential element in both communication and broadcast channel systems. [Data: Entities (386)]"
        },
        {
            "summary": "Binary Erasure Channel (BEC) as a fundamental model",
            "explanation": "The Binary Erasure Channel (BEC) is a fundamental communication channel model used in information theory. It is characterized by binary inputs and ternary outputs, where each transmitted bit is either received correctly or erased. The channel's capacity, given by \( C = 1 - \alpha \), represents the maximum rate of reliable communication. This model is particularly useful for analyzing the capacity region in multiple access communication systems. [Data: Entities (324)]"
        },
        {
            "summary": "Binary Erasure Multiple Access Channel's generalization",
            "explanation": "The Binary Erasure Multiple Access Channel is a generalization of the Binary Erasure Channel, where multiple users can transmit simultaneously. This channel is used to study the capacity region for multiple access communication systems, making it a valuable tool for understanding complex communication scenarios. [Data: Entities (730), Relationships (850)]"
        },
        {
            "summary": "Relationship between Binary Symmetric Channel and DECODER",
            "explanation": "The DECODER is used to decode messages received from the Binary Symmetric Channel. This relationship underscores the DECODER's role in ensuring accurate data interpretation in various communication channel models. [Data: Relationships (421)]"
        },
        {
            "summary": "Binary Erasure Channel as a specific example of a symmetric channel",
            "explanation": "The Binary Erasure Channel is a specific example of a symmetric channel. This relationship highlights the BEC's place within the broader category of symmetric channels, which are essential for understanding different types of communication channels. [Data: Relationships (341)]"
        }
    ]
}
```.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\services\json.py", line 77, in invoke
    return await this.invoke_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\services\json.py", line 100, in invoke_json
    raise FailedToGenerateValidJsonError from error
fnllm.base.services.errors.FailedToGenerateValidJsonError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\graphrag\index\operations\summarize_communities\community_reports_extractor.py", line 80, in __call__
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\graphrag\language_model\providers\fnllm\models.py", line 81, in achat
    response = await self.model(prompt, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\openai\llm\openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\openai\services\openai_tools_parsing.py", line 130, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\base_llm.py", line 148, in __call__
    await self._events.on_error(
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\graphrag\language_model\providers\fnllm\events.py", line 26, in on_error
    self._on_error(error, traceback, arguments)
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\graphrag\language_model\providers\fnllm\utils.py", line 45, in on_error
    callbacks.error("Error Invoking LLM", error, stack, details)
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\graphrag\callbacks\workflow_callbacks_manager.py", line 64, in error
    callback.error(message, cause, stack, details)
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\graphrag\callbacks\file_workflow_callbacks.py", line 37, in error
    json.dumps(
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\__init__.py", line 238, in dumps
    **kw).encode(obj)
          ^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 202, in encode
    chunks = list(chunks)
             ^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 432, in _iterencode
    yield from _iterencode_dict(o, _current_indent_level)
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 406, in _iterencode_dict
    yield from chunks
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 406, in _iterencode_dict
    yield from chunks
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 406, in _iterencode_dict
    yield from chunks
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 439, in _iterencode
    o = _default(o)
        ^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 180, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
TypeError: Object of type ModelMetaclass is not JSON serializable
16:48:17,105 graphrag.callbacks.file_workflow_callbacks INFO Community Report Extraction Error details=None
16:48:17,105 graphrag.index.operations.summarize_communities.strategies WARNING No report found for community: 141.0
16:48:17,818 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:48:18,477 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:48:21,161 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:48:23,196 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:48:27,637 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:48:27,641 graphrag.index.operations.summarize_communities.community_reports_extractor ERROR error generating community report
Traceback (most recent call last):
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\services\json.py", line 126, in _parse_json_string
    return json.loads(value) if value else None
           ^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\__init__.py", line 346, in loads
    return _default_decoder.decode(s)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\services\json.py", line 96, in invoke_json
    return await self.try_receive_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\services\json.py", line 114, in try_receive_json
    raw_json = self._parse_json_string(json_string)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\services\json.py", line 129, in _parse_json_string
    raise FailedToGenerateValidJsonError(msg) from err
fnllm.base.services.errors.FailedToGenerateValidJsonError: JSON response is not a valid JSON, response=```json
{
    "title": "Investment Portfolio and Management Community",
    "summary": "This community centers around the Investment Portfolio, which is managed by a Portfolio Manager and includes strategies like the Growth Optimal Portfolio. The portfolio is composed of assets traded in the stock market, and its management is crucial for achieving financial goals.",
    "rating": 7.5,
    "rating_explanation": "The impact severity rating is high due to the significant financial implications and strategic importance of investment portfolios.",
    "findings": [
        {
            "summary": "Investment Portfolio as the core entity",
            "explanation": "The Investment Portfolio is the central entity in this community, serving as a collection of financial assets designed to achieve specific financial goals. It includes stocks, bonds, and cash, and is optimized using strategies like the log optimal investment strategy to maximize returns and manage risk. [Data: Entities (864), Relationships (1079, 1084)]"
        },
        {
            "summary": "Role of the Portfolio Manager",
            "explanation": "The Portfolio Manager is responsible for making investment decisions and managing the assets within the Investment Portfolio to achieve optimal returns. This role is crucial for the effective management and performance of the portfolio. [Data: Entities (883), Relationships (1067)]"
        },
        {
            "summary": "Growth Optimal Portfolio strategy",
            "explanation": "The Growth Optimal Portfolio is a type of investment strategy that maximizes the expected growth rate of wealth. This strategy is a key component of the Investment Portfolio, highlighting the importance of strategic approaches in wealth management. [Data: Entities (893), Relationships (1084)]"
        },
        {
            "summary": "Connection to the Stock Market",
            "explanation": "The Investment Portfolio is composed of assets traded in the stock market. This connection underscores the portfolio's reliance on market dynamics and the importance of market conditions in achieving financial goals. [Data: Relationships (1079)]"
        }
    ]
}
```.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\services\json.py", line 77, in invoke
    return await this.invoke_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\services\json.py", line 100, in invoke_json
    raise FailedToGenerateValidJsonError from error
fnllm.base.services.errors.FailedToGenerateValidJsonError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\graphrag\index\operations\summarize_communities\community_reports_extractor.py", line 80, in __call__
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\graphrag\language_model\providers\fnllm\models.py", line 81, in achat
    response = await self.model(prompt, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\openai\llm\openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\openai\services\openai_tools_parsing.py", line 130, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\base_llm.py", line 148, in __call__
    await self._events.on_error(
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\graphrag\language_model\providers\fnllm\events.py", line 26, in on_error
    self._on_error(error, traceback, arguments)
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\graphrag\language_model\providers\fnllm\utils.py", line 45, in on_error
    callbacks.error("Error Invoking LLM", error, stack, details)
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\graphrag\callbacks\workflow_callbacks_manager.py", line 64, in error
    callback.error(message, cause, stack, details)
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\graphrag\callbacks\file_workflow_callbacks.py", line 37, in error
    json.dumps(
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\__init__.py", line 238, in dumps
    **kw).encode(obj)
          ^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 202, in encode
    chunks = list(chunks)
             ^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 432, in _iterencode
    yield from _iterencode_dict(o, _current_indent_level)
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 406, in _iterencode_dict
    yield from chunks
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 406, in _iterencode_dict
    yield from chunks
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 406, in _iterencode_dict
    yield from chunks
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 439, in _iterencode
    o = _default(o)
        ^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 180, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
TypeError: Object of type ModelMetaclass is not JSON serializable
16:48:27,648 graphrag.callbacks.file_workflow_callbacks INFO Community Report Extraction Error details=None
16:48:27,648 graphrag.index.operations.summarize_communities.strategies WARNING No report found for community: 147.0
16:48:31,447 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:48:32,778 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:48:35,352 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:48:35,393 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:48:38,46 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:48:39,706 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:48:41,323 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:48:48,632 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:48:48,638 graphrag.index.operations.summarize_communities.community_reports_extractor ERROR error generating community report
Traceback (most recent call last):
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\services\json.py", line 126, in _parse_json_string
    return json.loads(value) if value else None
           ^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\__init__.py", line 346, in loads
    return _default_decoder.decode(s)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\services\json.py", line 96, in invoke_json
    return await self.try_receive_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\services\json.py", line 114, in try_receive_json
    raw_json = self._parse_json_string(json_string)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\services\json.py", line 129, in _parse_json_string
    raise FailedToGenerateValidJsonError(msg) from err
fnllm.base.services.errors.FailedToGenerateValidJsonError: JSON response is not a valid JSON, response=```json
{
    "title": "Shannon and Information Theory Community",
    "summary": "The community centers around Claude E. Shannon, a foundational figure in information theory, and his extensive contributions to the field. Shannon's work is deeply interconnected with other key entities such as Boltzmann, Hartley, Chung, and Feinstein, who have influenced or extended his theories. The community also includes significant theorems like the Shannon-Nyquist Sampling Theorem and Shannon's three fundamental theorems, which are cornerstones of information theory. Shannon's work during World War II in cryptography further highlights the historical and scientific impact of this community.",
    "rating": 9.5,
    "rating_explanation": "The impact severity rating is very high due to the foundational and far-reaching contributions of Shannon and associated entities in shaping modern information theory and related fields.",
    "findings": [
        {
            "summary": "Shannon's foundational role in information theory",
            "explanation": "Claude E. Shannon is widely recognized as a pioneer in information theory, with his 1948 paper introducing groundbreaking concepts such as entropy, mutual information, and channel capacity. His work laid the theoretical foundation for data compression, communication systems, and error-correcting codes, which remain central to modern technology. Shannon's contributions have had a profound and lasting impact on fields ranging from computer science to telecommunications. [Data: Entities (61), Relationships (44, 1819, 1820, 1821)]"
        },
        {
            "summary": "Influence of Boltzmann on Shannon's work",
            "explanation": "Ludwig Boltzmann's work on entropy in statistical mechanics significantly influenced Shannon's development of information theory. Boltzmann's equation \( S = k \ln W \) established a fundamental relationship between entropy and the number of microscopic states, which Shannon adapted to quantify information entropy. This connection highlights the interdisciplinary nature of Shannon's contributions and their roots in physics. [Data: Entities (136), Relationships (144)]"
        },
        {
            "summary": "Hartley's logarithmic measure and its impact on Shannon",
            "explanation": "Hartley introduced the logarithmic measure of information in the 1930s, which directly influenced Shannon's work on entropy and mutual information. Hartley's concept provided a mathematical framework for quantifying information, which Shannon expanded upon to develop his theories. This relationship underscores the collaborative and cumulative nature of scientific progress in information theory. [Data: Entities (137), Relationships (145)]"
        },
        {
            "summary": "Chung's extension of Shannon's AEP theorem",
            "explanation": "Chung extended the Asymptotic Equipartition Property (AEP) theorem, which was first discussed by Shannon, to countable alphabets. This extension broadened the applicability of Shannon's work and demonstrated the ongoing evolution of information theory. Chung's contributions highlight the collaborative nature of the field and the importance of building upon foundational work. [Data: Entities (164), Relationships (164)]"
        },
        {
            "summary": "Shannon's wartime cryptography and its influence",
            "explanation": "During World War II, Shannon's work in cryptography played a pivotal role in shaping his later contributions to information theory. His experiences in cryptographic research inspired his foundational work on secure communication and data encoding, which became central to information theory. This dual influence underscores the historical significance of Shannon's wartime efforts. [Data: Entities (290), Relationships (306)]"
        },
        {
            "summary": "Feinstein's rigorous proof of Shannon's channel capacity theorem",
            "explanation": "Feinstein provided the first rigorous proof of Shannon's channel capacity theorem using a complex 'cookie-cutting' method. This proof validated Shannon's theoretical work and solidified the theorem's importance in communication theory. Feinstein's contribution exemplifies the collaborative nature of scientific research and the importance of rigorous validation in advancing theoretical frameworks. [Data: Entities (391), Relationships (433)]"
        },
        {
            "summary": "Schalkwijk's coding schemes exceeding Shannon's bounds",
            "explanation": "Schalkwijk proposed coding schemes for two-way channels that exceeded Shannon's inner bounds, demonstrating the potential for advancements beyond Shannon's foundational work. This achievement highlights the dynamic and evolving nature of information theory, where researchers continue to push the boundaries of established theories. [Data: Entities (809), Relationships (968)]"
        },
        {
            "summary": "Shannon-Nyquist Sampling Theorem's significance",
            "explanation": "The Shannon-Nyquist Sampling Theorem, co-developed by Shannon, is crucial in signal processing as it establishes the conditions under which a signal can be perfectly reconstructed from its samples. This theorem is foundational in digital communication and has widespread applications in technology, including audio and video processing. [Data: Entities (1925), Relationships (1816)]"
        },
        {
            "summary": "Shannon's three fundamental theorems",
            "explanation": "Shannon's three fundamental theoremsthe source coding theorem, the channel coding theorem, and the rate distortion theoremare cornerstones of information theory. These theorems define the limits of data compression, reliable communication over noisy channels, and the trade-off between compression and distortion, respectively. Their impact spans numerous fields, including telecommunications, data storage, and machine learning. [Data: Entities (1926, 1927, 1928), Relationships (1819, 1820, 1821)]"
        }
    ]
}
```.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\services\json.py", line 77, in invoke
    return await this.invoke_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\services\json.py", line 100, in invoke_json
    raise FailedToGenerateValidJsonError from error
fnllm.base.services.errors.FailedToGenerateValidJsonError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\graphrag\index\operations\summarize_communities\community_reports_extractor.py", line 80, in __call__
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\graphrag\language_model\providers\fnllm\models.py", line 81, in achat
    response = await self.model(prompt, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\openai\llm\openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\openai\services\openai_tools_parsing.py", line 130, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\base_llm.py", line 148, in __call__
    await self._events.on_error(
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\graphrag\language_model\providers\fnllm\events.py", line 26, in on_error
    self._on_error(error, traceback, arguments)
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\graphrag\language_model\providers\fnllm\utils.py", line 45, in on_error
    callbacks.error("Error Invoking LLM", error, stack, details)
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\graphrag\callbacks\workflow_callbacks_manager.py", line 64, in error
    callback.error(message, cause, stack, details)
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\graphrag\callbacks\file_workflow_callbacks.py", line 37, in error
    json.dumps(
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\__init__.py", line 238, in dumps
    **kw).encode(obj)
          ^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 202, in encode
    chunks = list(chunks)
             ^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 432, in _iterencode
    yield from _iterencode_dict(o, _current_indent_level)
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 406, in _iterencode_dict
    yield from chunks
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 406, in _iterencode_dict
    yield from chunks
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 406, in _iterencode_dict
    yield from chunks
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 439, in _iterencode
    o = _default(o)
        ^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 180, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
TypeError: Object of type ModelMetaclass is not JSON serializable
16:48:48,645 graphrag.callbacks.file_workflow_callbacks INFO Community Report Extraction Error details=None
16:48:48,645 graphrag.index.operations.summarize_communities.strategies WARNING No report found for community: 133.0
16:48:49,242 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:48:50,53 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:48:54,290 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:48:55,259 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:49:00,73 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:49:00,903 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:49:00,955 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:49:05,818 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:49:09,207 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:49:09,211 graphrag.index.operations.summarize_communities.community_reports_extractor ERROR error generating community report
Traceback (most recent call last):
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\services\json.py", line 126, in _parse_json_string
    return json.loads(value) if value else None
           ^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\__init__.py", line 346, in loads
    return _default_decoder.decode(s)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\services\json.py", line 96, in invoke_json
    return await self.try_receive_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\services\json.py", line 114, in try_receive_json
    raw_json = self._parse_json_string(json_string)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\services\json.py", line 129, in _parse_json_string
    raise FailedToGenerateValidJsonError(msg) from err
fnllm.base.services.errors.FailedToGenerateValidJsonError: JSON response is not a valid JSON, response=```json
{
    "title": "Stock Market and Investment Strategies",
    "summary": "The community centers around the stock market, which is analyzed in the context of investment strategies, entropy rates, and the Asymptotic Equipartition Property (AEP). Key entities include the stock market, investment strategies, and researchers like Algoet and Cover, who contribute to the theoretical underpinnings of these concepts. The relationships highlight the application of strategies such as the constant rebalanced portfolio and the universal portfolio in the stock market.",
    "rating": 7.5,
    "rating_explanation": "The impact severity rating is high due to the significant influence of the stock market on economic activities and the application of advanced theoretical concepts in investment strategies.",
    "findings": [
        {
            "summary": "Stock market as the central entity",
            "explanation": "The stock market is the central entity in this community, serving as the platform for various investment strategies and economic activities. It is analyzed in relation to entropy rates and the Asymptotic Equipartition Property, which provide insights into wealth accumulation and risk management. The stock market's complexity and multifaceted nature make it a critical component of the community. [Data: Entities (840), Relationships (1019, 1036, 1039, 1041, 1054, +more)]"
        },
        {
            "summary": "Investment strategies in the stock market",
            "explanation": "Investment strategies are a key focus within the community, particularly those aimed at maximizing logarithmic returns in the stock market. Strategies such as the constant rebalanced portfolio and the universal portfolio are analyzed for their performance and efficiency. These strategies are crucial for understanding the dynamics of wealth growth and risk management in the stock market. [Data: Entities (857, 865, 867), Relationships (1036, 1054, 1055)]"
        },
        {
            "summary": "Role of the Asymptotic Equipartition Property",
            "explanation": "The Asymptotic Equipartition Property (AEP) is a fundamental concept in information theory that is applied to the stock market to analyze optimal investment strategies. The AEP helps in understanding the behavior of sequences of random variables and their implications for data compression and communication systems. Its application in the stock market highlights the intersection of information theory and financial analysis. [Data: Entities (77), Relationships (146, 1041)]"
        },
        {
            "summary": "Contributions of Algoet and Cover",
            "explanation": "Algoet and Cover are referenced for their proof related to the Asymptotic Equipartition Property in the context of the stock market. Their work contributes to the theoretical foundation of investment strategies and the application of information theory principles in financial analysis. Their research is significant in understanding the behavior of optimal investment strategies over time. [Data: Entities (861), Relationships (1041)]"
        },
        {
            "summary": "Stationary market analysis",
            "explanation": "A stationary market is a specific type of stock market process analyzed in the context of investment strategies. The analysis of stationary markets provides insights into the time-dependent nature of market processes and their implications for wealth accumulation and risk management. This analysis is crucial for understanding the dynamics of the stock market. [Data: Entities (859), Relationships (1039)]"
        },
        {
            "summary": "Researchers and their contributions",
            "explanation": "Several researchers, including Stone, C. J., Storer, J. A., and Tibshirani, R., are referenced in the context of the stock market. Their contributions likely pertain to the analysis of investment strategies, entropy rates, and the application of information theory principles in financial markets. Their work is significant in advancing the theoretical understanding of the stock market. [Data: Entities (1943, 1944, 1948), Relationships (1832, 1833, 1837)]"
        }
    ]
}
```.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\services\json.py", line 77, in invoke
    return await this.invoke_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\services\json.py", line 100, in invoke_json
    raise FailedToGenerateValidJsonError from error
fnllm.base.services.errors.FailedToGenerateValidJsonError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\graphrag\index\operations\summarize_communities\community_reports_extractor.py", line 80, in __call__
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\graphrag\language_model\providers\fnllm\models.py", line 81, in achat
    response = await self.model(prompt, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\openai\llm\openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\openai\services\openai_tools_parsing.py", line 130, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\base_llm.py", line 148, in __call__
    await self._events.on_error(
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\graphrag\language_model\providers\fnllm\events.py", line 26, in on_error
    self._on_error(error, traceback, arguments)
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\graphrag\language_model\providers\fnllm\utils.py", line 45, in on_error
    callbacks.error("Error Invoking LLM", error, stack, details)
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\graphrag\callbacks\workflow_callbacks_manager.py", line 64, in error
    callback.error(message, cause, stack, details)
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\graphrag\callbacks\file_workflow_callbacks.py", line 37, in error
    json.dumps(
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\__init__.py", line 238, in dumps
    **kw).encode(obj)
          ^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 202, in encode
    chunks = list(chunks)
             ^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 432, in _iterencode
    yield from _iterencode_dict(o, _current_indent_level)
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 406, in _iterencode_dict
    yield from chunks
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 406, in _iterencode_dict
    yield from chunks
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 406, in _iterencode_dict
    yield from chunks
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 439, in _iterencode
    o = _default(o)
        ^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 180, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
TypeError: Object of type ModelMetaclass is not JSON serializable
16:49:09,218 graphrag.callbacks.file_workflow_callbacks INFO Community Report Extraction Error details=None
16:49:09,218 graphrag.index.operations.summarize_communities.strategies WARNING No report found for community: 144.0
16:49:13,614 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:49:13,978 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:49:22,767 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:49:22,771 graphrag.index.operations.summarize_communities.community_reports_extractor ERROR error generating community report
Traceback (most recent call last):
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\services\json.py", line 126, in _parse_json_string
    return json.loads(value) if value else None
           ^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\__init__.py", line 346, in loads
    return _default_decoder.decode(s)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\decoder.py", line 353, in raw_decode
    obj, end = self.scan_once(s, idx)
               ^^^^^^^^^^^^^^^^^^^^^^
json.decoder.JSONDecodeError: Invalid \escape: line 9 column 62 (char 802)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\services\json.py", line 96, in invoke_json
    return await self.try_receive_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\services\json.py", line 114, in try_receive_json
    raw_json = self._parse_json_string(json_string)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\services\json.py", line 129, in _parse_json_string
    raise FailedToGenerateValidJsonError(msg) from err
fnllm.base.services.errors.FailedToGenerateValidJsonError: JSON response is not a valid JSON, response={
    "title": "Gaussian Channel and Associated Constraints",
    "summary": "The community centers around the Gaussian Channel, which is influenced by key constraints such as the Power Constraint and Noise Variance. These constraints are critical in determining the channel's capacity and operational efficiency. The Gaussian Channel Coding Theorem further establishes the theoretical limits of the channel under these constraints.",
    "rating": 7.5,
    "rating_explanation": "The impact severity rating is high due to the fundamental role of the Gaussian Channel in communication systems and the critical nature of its constraints.",
    "findings": [
        {
            "summary": "Power Constraint's role in the Gaussian Channel",
            "explanation": "The Power Constraint, denoted by \( P \), is a critical parameter that limits the maximum allowable power for signal transmission within the Gaussian Channel. This constraint ensures that the system adheres to predefined energy limitations, which is essential for maintaining the integrity and efficiency of communication systems. The relationship between the Power Constraint and the Gaussian Channel is fundamental in optimizing the channel's performance. [Data: Entities (421), Relationships (460)]"
        },
        {
            "summary": "Noise Variance as a key metric",
            "explanation": "The Noise Variance, denoted by \( N \), quantifies the variance of the noise present in the Gaussian Channel. This metric is essential for calculating the channel capacity and understanding the performance and limitations of communication systems operating under noisy conditions. The relationship between Noise Variance and the Gaussian Channel is crucial for analyzing the channel's behavior. [Data: Entities (422), Relationships (462)]"
        },
        {
            "summary": "Gaussian Channel Coding Theorem's significance",
            "explanation": "The Gaussian Channel Coding Theorem establishes the capacity of the Gaussian Channel under the Power Constraint. This theorem is fundamental in understanding the theoretical limits of the channel and its operational efficiency. The relationship between the Gaussian Channel Coding Theorem and the Gaussian Channel is key to comprehending the channel's capabilities. [Data: Entities (428), Relationships (477)]"
        }
    ]
}.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\services\json.py", line 77, in invoke
    return await this.invoke_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\services\json.py", line 100, in invoke_json
    raise FailedToGenerateValidJsonError from error
fnllm.base.services.errors.FailedToGenerateValidJsonError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\graphrag\index\operations\summarize_communities\community_reports_extractor.py", line 80, in __call__
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\graphrag\language_model\providers\fnllm\models.py", line 81, in achat
    response = await self.model(prompt, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\openai\llm\openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\openai\services\openai_tools_parsing.py", line 130, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\base_llm.py", line 148, in __call__
    await self._events.on_error(
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\graphrag\language_model\providers\fnllm\events.py", line 26, in on_error
    self._on_error(error, traceback, arguments)
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\graphrag\language_model\providers\fnllm\utils.py", line 45, in on_error
    callbacks.error("Error Invoking LLM", error, stack, details)
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\graphrag\callbacks\workflow_callbacks_manager.py", line 64, in error
    callback.error(message, cause, stack, details)
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\graphrag\callbacks\file_workflow_callbacks.py", line 37, in error
    json.dumps(
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\__init__.py", line 238, in dumps
    **kw).encode(obj)
          ^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 202, in encode
    chunks = list(chunks)
             ^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 432, in _iterencode
    yield from _iterencode_dict(o, _current_indent_level)
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 406, in _iterencode_dict
    yield from chunks
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 406, in _iterencode_dict
    yield from chunks
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 406, in _iterencode_dict
    yield from chunks
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 439, in _iterencode
    o = _default(o)
        ^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 180, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
TypeError: Object of type ModelMetaclass is not JSON serializable
16:49:22,777 graphrag.callbacks.file_workflow_callbacks INFO Community Report Extraction Error details=None
16:49:22,777 graphrag.index.operations.summarize_communities.strategies WARNING No report found for community: 160.0
16:49:27,431 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:49:45,46 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:49:47,401 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:49:50,20 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:49:51,38 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:49:52,585 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:49:53,859 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:49:54,604 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:49:55,431 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:50:02,115 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:50:05,25 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:50:07,637 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:50:11,917 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:50:12,105 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:50:14,684 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:50:17,599 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:50:18,570 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:50:20,44 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:50:21,432 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:50:21,885 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:50:31,701 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:50:34,70 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:50:36,901 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:50:36,907 graphrag.index.operations.summarize_communities.community_reports_extractor ERROR error generating community report
Traceback (most recent call last):
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\services\json.py", line 126, in _parse_json_string
    return json.loads(value) if value else None
           ^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\__init__.py", line 346, in loads
    return _default_decoder.decode(s)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\services\json.py", line 96, in invoke_json
    return await self.try_receive_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\services\json.py", line 114, in try_receive_json
    raw_json = self._parse_json_string(json_string)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\services\json.py", line 129, in _parse_json_string
    raise FailedToGenerateValidJsonError(msg) from err
fnllm.base.services.errors.FailedToGenerateValidJsonError: JSON response is not a valid JSON, response=```json
{
    "title": "Maximum Entropy Process and Related Mathematical Entities",
    "summary": "The community centers around the Maximum Entropy Process, which is analyzed in the context of Gaussian Random Processes and Laplace Transforms. These entities are interconnected through their applications in determining entropy rates and deriving maximum entropy densities.",
    "rating": 6.5,
    "rating_explanation": "The impact severity rating is moderately high due to the technical and mathematical significance of the entities involved.",
    "findings": [
        {
            "summary": "Maximum Entropy Process as the central entity",
            "explanation": "The Maximum Entropy Process is the central entity in this community, serving as a key concept in the analysis of entropy rates and densities. Its application in various mathematical contexts highlights its importance in the community. [Data: Entities (568), Relationships (662, 663, 664)]"
        },
        {
            "summary": "Gaussian Random Process's role in the community",
            "explanation": "The Gaussian Random Process is analyzed in the context of the Maximum Entropy Process, providing a specific case study for understanding entropy bounds. This relationship underscores the practical applications of the Maximum Entropy Process. [Data: Entities (566), Relationships (663)]"
        },
        {
            "summary": "Laplace Transform's application in the community",
            "explanation": "The Laplace Transform is used to derive the maximum entropy density in the Maximum Entropy Process. This mathematical tool is crucial for understanding the theoretical underpinnings of the process. [Data: Entities (567), Relationships (664)]"
        },
        {
            "summary": "Markov Chain's connection to the Maximum Entropy Process",
            "explanation": "The Maximum Entropy Process is applied to a Markov Chain to determine its entropy rate. This application demonstrates the process's utility in analyzing complex systems. [Data: Relationships (662)]"
        }
    ]
}
```.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\services\json.py", line 77, in invoke
    return await this.invoke_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\services\json.py", line 100, in invoke_json
    raise FailedToGenerateValidJsonError from error
fnllm.base.services.errors.FailedToGenerateValidJsonError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\graphrag\index\operations\summarize_communities\community_reports_extractor.py", line 80, in __call__
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\graphrag\language_model\providers\fnllm\models.py", line 81, in achat
    response = await self.model(prompt, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\openai\llm\openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\openai\services\openai_tools_parsing.py", line 130, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\base_llm.py", line 148, in __call__
    await self._events.on_error(
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\graphrag\language_model\providers\fnllm\events.py", line 26, in on_error
    self._on_error(error, traceback, arguments)
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\graphrag\language_model\providers\fnllm\utils.py", line 45, in on_error
    callbacks.error("Error Invoking LLM", error, stack, details)
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\graphrag\callbacks\workflow_callbacks_manager.py", line 64, in error
    callback.error(message, cause, stack, details)
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\graphrag\callbacks\file_workflow_callbacks.py", line 37, in error
    json.dumps(
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\__init__.py", line 238, in dumps
    **kw).encode(obj)
          ^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 202, in encode
    chunks = list(chunks)
             ^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 432, in _iterencode
    yield from _iterencode_dict(o, _current_indent_level)
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 406, in _iterencode_dict
    yield from chunks
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 406, in _iterencode_dict
    yield from chunks
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 406, in _iterencode_dict
    yield from chunks
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 439, in _iterencode
    o = _default(o)
        ^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 180, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
TypeError: Object of type ModelMetaclass is not JSON serializable
16:50:36,913 graphrag.callbacks.file_workflow_callbacks INFO Community Report Extraction Error details=None
16:50:36,913 graphrag.index.operations.summarize_communities.strategies WARNING No report found for community: 24.0
16:50:38,97 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:50:38,602 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:50:40,197 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:50:44,853 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:50:47,480 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:50:47,748 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:50:48,279 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:50:48,283 graphrag.index.operations.summarize_communities.community_reports_extractor ERROR error generating community report
Traceback (most recent call last):
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\services\json.py", line 126, in _parse_json_string
    return json.loads(value) if value else None
           ^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\__init__.py", line 346, in loads
    return _default_decoder.decode(s)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\services\json.py", line 96, in invoke_json
    return await self.try_receive_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\services\json.py", line 114, in try_receive_json
    raw_json = self._parse_json_string(json_string)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\services\json.py", line 129, in _parse_json_string
    raise FailedToGenerateValidJsonError(msg) from err
fnllm.base.services.errors.FailedToGenerateValidJsonError: JSON response is not a valid JSON, response=```json
{
    "title": "Q, P*, and D(P||Q) Community",
    "summary": "The community is centered around the entities Q, P*, and D(P||Q), which are interconnected through their roles in distribution comparison and divergence measurement. Q is the distribution being compared, P* is the closest type to Q in set E, and D(P||Q) is the divergence measure used to compare distributions.",
    "rating": 6.5,
    "rating_explanation": "The impact severity rating is moderately high due to the technical and analytical significance of the entities in distribution comparison and divergence measurement.",
    "findings": [
        {
            "summary": "Q as the central distribution",
            "explanation": "Q is the primary distribution in this community, serving as the reference point for comparison with other distributions. Its high degree of 9 indicates its central role in the community's dynamics. The relationships between Q and other entities, such as D(P||Q), highlight its importance in divergence measurement. [Data: Entities (530), Relationships (598)]"
        },
        {
            "summary": "P* as the closest type to Q",
            "explanation": "P* is the type in set E that is closest to Q, and its probability determines the probability of E. This entity plays a crucial role in understanding the relationship between Q and the set E. The relationships between P* and E, as well as P* and D(P||Q), underscore its significance in the community. [Data: Entities (529), Relationships (595, 597)]"
        },
        {
            "summary": "D(P||Q) as the divergence measure",
            "explanation": "D(P||Q) is the relative entropy or divergence measure used to compare distributions P and Q. This entity is essential for quantifying the difference between distributions, making it a key component in the community's analytical framework. The relationships between D(P||Q) and Q, as well as D(P||Q) and P*, highlight its role in the community. [Data: Entities (531), Relationships (598, 597)]"
        }
    ]
}
```.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\services\json.py", line 77, in invoke
    return await this.invoke_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\services\json.py", line 100, in invoke_json
    raise FailedToGenerateValidJsonError from error
fnllm.base.services.errors.FailedToGenerateValidJsonError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\graphrag\index\operations\summarize_communities\community_reports_extractor.py", line 80, in __call__
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\graphrag\language_model\providers\fnllm\models.py", line 81, in achat
    response = await self.model(prompt, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\openai\llm\openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\openai\services\openai_tools_parsing.py", line 130, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\base_llm.py", line 148, in __call__
    await self._events.on_error(
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\graphrag\language_model\providers\fnllm\events.py", line 26, in on_error
    self._on_error(error, traceback, arguments)
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\graphrag\language_model\providers\fnllm\utils.py", line 45, in on_error
    callbacks.error("Error Invoking LLM", error, stack, details)
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\graphrag\callbacks\workflow_callbacks_manager.py", line 64, in error
    callback.error(message, cause, stack, details)
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\graphrag\callbacks\file_workflow_callbacks.py", line 37, in error
    json.dumps(
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\__init__.py", line 238, in dumps
    **kw).encode(obj)
          ^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 202, in encode
    chunks = list(chunks)
             ^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 432, in _iterencode
    yield from _iterencode_dict(o, _current_indent_level)
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 406, in _iterencode_dict
    yield from chunks
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 406, in _iterencode_dict
    yield from chunks
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 406, in _iterencode_dict
    yield from chunks
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 439, in _iterencode
    o = _default(o)
        ^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 180, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
TypeError: Object of type ModelMetaclass is not JSON serializable
16:50:48,289 graphrag.callbacks.file_workflow_callbacks INFO Community Report Extraction Error details=None
16:50:48,289 graphrag.index.operations.summarize_communities.strategies WARNING No report found for community: 27.0
16:50:50,282 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:50:52,416 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:51:00,940 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:51:01,362 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:51:02,404 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:51:08,24 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:51:08,28 graphrag.index.operations.summarize_communities.community_reports_extractor ERROR error generating community report
Traceback (most recent call last):
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\services\json.py", line 126, in _parse_json_string
    return json.loads(value) if value else None
           ^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\__init__.py", line 346, in loads
    return _default_decoder.decode(s)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\services\json.py", line 96, in invoke_json
    return await self.try_receive_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\services\json.py", line 114, in try_receive_json
    raw_json = self._parse_json_string(json_string)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\services\json.py", line 129, in _parse_json_string
    raise FailedToGenerateValidJsonError(msg) from err
fnllm.base.services.errors.FailedToGenerateValidJsonError: JSON response is not a valid JSON, response=```json
{
    "title": "Mathematical Sets A and B",
    "summary": "The community revolves around the mathematical sets A and B, which are characterized by specific probabilistic properties. Set A is defined by a probability greater than \(1 - \epsilon_1\) and serves as the typical set in data compression, while set B has a probability greater than \(1 - \epsilon_2\) and also functions as an organization involved in mathematical proofs. The relationships between these sets and other entities like \(P_1\) and \(P_2\) highlight their significance in probabilistic frameworks and information theory.",
    "rating": 6.5,
    "rating_explanation": "The impact severity rating is moderately high due to the theoretical and practical significance of sets A and B in probabilistic frameworks and information theory.",
    "findings": [
        {
            "summary": "Set A's role in data compression",
            "explanation": "Set A is a crucial entity in this community, defined by a probability greater than \(1 - \epsilon_1\). It serves as the typical set in data compression, which is essential for the efficient encoding of data in information theory. This role underscores its importance in both theoretical and practical applications. [Data: Entities (157), Relationships (158)]"
        },
        {
            "summary": "Set B's dual nature",
            "explanation": "Set B operates both as a mathematical set and an organization involved in mathematical proofs. Its probability is greater than \(1 - \epsilon_2\), and it has a specified value range, highlighting its significance in probabilistic frameworks and its practical role in the proof process. This dual nature makes B a key entity in bridging abstract mathematical concepts with practical applications. [Data: Entities (158), Relationships (159)]"
        },
        {
            "summary": "Relationship between A and B",
            "explanation": "Sets A and B are related through their probabilistic properties, with both having probabilities greater than \(1 - \epsilon_1\) and \(1 - \epsilon_2\), respectively. This relationship emphasizes their shared significance in probabilistic frameworks and their complementary roles in theoretical and applied contexts. [Data: Relationships (159)]"
        },
        {
            "summary": "Comparison of \(P_1\) and \(P_2\)",
            "explanation": "The entities \(P_1\) and \(P_2\) are compared in terms of their variational distance and relative entropy. This comparison is crucial for understanding the probabilistic properties and relationships within the community, particularly in the context of information theory and data compression. [Data: Entities (532, 533), Relationships (599)]"
        },
        {
            "summary": "Set A's association with X1",
            "explanation": "Set A is associated with X1, which is part of the typical set used in a data compression example. This association highlights the practical applications of set A in information theory and its role in encoding data efficiently. [Data: Relationships (158)]"
        }
    ]
}
```.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\services\json.py", line 77, in invoke
    return await this.invoke_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\services\json.py", line 100, in invoke_json
    raise FailedToGenerateValidJsonError from error
fnllm.base.services.errors.FailedToGenerateValidJsonError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\graphrag\index\operations\summarize_communities\community_reports_extractor.py", line 80, in __call__
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\graphrag\language_model\providers\fnllm\models.py", line 81, in achat
    response = await self.model(prompt, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\openai\llm\openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\openai\services\openai_tools_parsing.py", line 130, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\base_llm.py", line 148, in __call__
    await self._events.on_error(
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\graphrag\language_model\providers\fnllm\events.py", line 26, in on_error
    self._on_error(error, traceback, arguments)
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\graphrag\language_model\providers\fnllm\utils.py", line 45, in on_error
    callbacks.error("Error Invoking LLM", error, stack, details)
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\graphrag\callbacks\workflow_callbacks_manager.py", line 64, in error
    callback.error(message, cause, stack, details)
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\graphrag\callbacks\file_workflow_callbacks.py", line 37, in error
    json.dumps(
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\__init__.py", line 238, in dumps
    **kw).encode(obj)
          ^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 202, in encode
    chunks = list(chunks)
             ^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 432, in _iterencode
    yield from _iterencode_dict(o, _current_indent_level)
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 406, in _iterencode_dict
    yield from chunks
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 406, in _iterencode_dict
    yield from chunks
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 406, in _iterencode_dict
    yield from chunks
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 439, in _iterencode
    o = _default(o)
        ^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 180, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
TypeError: Object of type ModelMetaclass is not JSON serializable
16:51:08,34 graphrag.callbacks.file_workflow_callbacks INFO Community Report Extraction Error details=None
16:51:08,34 graphrag.index.operations.summarize_communities.strategies WARNING No report found for community: 25.0
16:51:11,404 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:51:13,68 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:51:13,71 graphrag.index.operations.summarize_communities.community_reports_extractor ERROR error generating community report
Traceback (most recent call last):
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\services\json.py", line 126, in _parse_json_string
    return json.loads(value) if value else None
           ^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\__init__.py", line 346, in loads
    return _default_decoder.decode(s)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\services\json.py", line 96, in invoke_json
    return await self.try_receive_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\services\json.py", line 114, in try_receive_json
    raw_json = self._parse_json_string(json_string)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\services\json.py", line 129, in _parse_json_string
    raise FailedToGenerateValidJsonError(msg) from err
fnllm.base.services.errors.FailedToGenerateValidJsonError: JSON response is not a valid JSON, response=```json
{
    "title": "Entropy Rate and Stochastic Processes",
    "summary": "This community revolves around the concept of entropy rate, a fundamental metric in information theory, and its application to various stochastic processes such as random walks on chessboards, 3D mazes, and graphs. Key entities include Entropy Rate, Random Walk on a 3x3 Chessboard, 3D Maze, Maximum Entropy Graph, and Markov Chain Transitions, all interconnected through their analysis of entropy rates and stationary distributions.",
    "rating": 8.5,
    "rating_explanation": "The impact severity rating is high due to the centrality of entropy rate in information theory and its broad applications in stochastic processes and language models.",
    "findings": [
        {
            "summary": "Entropy Rate as a central concept",
            "explanation": "The Entropy Rate is the cornerstone of this community, serving as a measure of uncertainty or randomness in stochastic processes. It is applied across various contexts, including random walks, Markov chains, and language models, making it a critical metric for understanding information content and system complexity. [Data: Entities (197), Relationships (198, 199, 200, 201)]"
        },
        {
            "summary": "Random Walk on a 3x3 Chessboard",
            "explanation": "The random walk of a king on a 3x3 chessboard is analyzed to determine its entropy rate. This analysis provides insights into the behavior of Markov chains and their entropy rates, offering a practical example of how entropy rate can be applied to discrete systems. [Data: Entities (194), Relationships (198)]"
        },
        {
            "summary": "3D Maze and Stationary Distribution",
            "explanation": "A bird's random walk in a 3x3x3 cubic maze is analyzed to determine its entropy rate and stationary distribution. This example highlights the application of entropy rate to more complex, multi-dimensional systems, providing a deeper understanding of stochastic processes. [Data: Entities (195), Relationships (199)]"
        },
        {
            "summary": "Maximum Entropy Graph Analysis",
            "explanation": "A random walk on a connected graph with 4 edges is analyzed to determine which graph has the highest and lowest entropy rates. This analysis is crucial for understanding how graph structure influences entropy rates and randomness in stochastic processes. [Data: Entities (196), Relationships (200)]"
        },
        {
            "summary": "Markov Chain Transitions and Entropy Rate",
            "explanation": "An irreducible Markov chain with a transition probability matrix and stationary distribution is described, with its entropy rate analyzed. This provides a foundational understanding of how entropy rate is applied to Markov chains, a key concept in stochastic processes. [Data: Entities (198), Relationships (201)]"
        },
        {
            "summary": "Shannon Guessing Game and English Language",
            "explanation": "The Shannon Guessing Game is used to estimate the entropy rate of the English language. This application of entropy rate to language models demonstrates its relevance in quantifying the predictability and complexity of sequences in natural language. [Data: Entities (298), Relationships (313)]"
        }
    ]
}
```.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\services\json.py", line 77, in invoke
    return await this.invoke_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\services\json.py", line 100, in invoke_json
    raise FailedToGenerateValidJsonError from error
fnllm.base.services.errors.FailedToGenerateValidJsonError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\graphrag\index\operations\summarize_communities\community_reports_extractor.py", line 80, in __call__
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\graphrag\language_model\providers\fnllm\models.py", line 81, in achat
    response = await self.model(prompt, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\openai\llm\openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\openai\services\openai_tools_parsing.py", line 130, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\base_llm.py", line 148, in __call__
    await self._events.on_error(
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\graphrag\language_model\providers\fnllm\events.py", line 26, in on_error
    self._on_error(error, traceback, arguments)
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\graphrag\language_model\providers\fnllm\utils.py", line 45, in on_error
    callbacks.error("Error Invoking LLM", error, stack, details)
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\graphrag\callbacks\workflow_callbacks_manager.py", line 64, in error
    callback.error(message, cause, stack, details)
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\graphrag\callbacks\file_workflow_callbacks.py", line 37, in error
    json.dumps(
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\__init__.py", line 238, in dumps
    **kw).encode(obj)
          ^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 202, in encode
    chunks = list(chunks)
             ^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 432, in _iterencode
    yield from _iterencode_dict(o, _current_indent_level)
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 406, in _iterencode_dict
    yield from chunks
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 406, in _iterencode_dict
    yield from chunks
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 406, in _iterencode_dict
    yield from chunks
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 439, in _iterencode
    o = _default(o)
        ^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 180, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
TypeError: Object of type ModelMetaclass is not JSON serializable
16:51:13,76 graphrag.callbacks.file_workflow_callbacks INFO Community Report Extraction Error details=None
16:51:13,76 graphrag.index.operations.summarize_communities.strategies WARNING No report found for community: 23.0
16:51:15,813 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:51:15,817 graphrag.index.operations.summarize_communities.community_reports_extractor ERROR error generating community report
Traceback (most recent call last):
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\services\json.py", line 126, in _parse_json_string
    return json.loads(value) if value else None
           ^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\__init__.py", line 346, in loads
    return _default_decoder.decode(s)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\services\json.py", line 96, in invoke_json
    return await self.try_receive_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\services\json.py", line 114, in try_receive_json
    raw_json = self._parse_json_string(json_string)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\services\json.py", line 129, in _parse_json_string
    raise FailedToGenerateValidJsonError(msg) from err
fnllm.base.services.errors.FailedToGenerateValidJsonError: JSON response is not a valid JSON, response=```json
{
    "title": "Random Variables and Entropy in Information Theory",
    "summary": "The community centers around a sequence of independent and identically distributed (i.i.d.) random variables, X1, X2, ..., XN, which are fundamental in mathematical analysis, probability theory, and information theory. These variables are interconnected through relationships involving joint entropy and conditional entropy, which are crucial for understanding data transmission, compression, and processing. The entities and their relationships form a cohesive framework for analyzing uncertainty and dependencies in data systems.",
    "rating": 7.5,
    "rating_explanation": "The impact severity rating is high due to the foundational role of these entities in critical fields such as information theory and data compression.",
    "findings": [
        {
            "summary": "X1 as a foundational random variable",
            "explanation": "X1 is a discrete random variable that serves as the starting point in the sequence X1, X2, ..., Xn. It is characterized as an independent and identically distributed (i.i.d.) random variable, which is essential for probabilistic analyses and information theory applications. X1's role in the sequence makes it a cornerstone for understanding joint entropy and conditional entropy, which are key measures in data compression and transmission. [Data: Entities (120), Relationships (611)]"
        },
        {
            "summary": "X2's role in entropy and mutual information",
            "explanation": "X2 is a discrete random variable that plays a significant role in mathematical analysis and information theory. It is part of the sequence X1, X2, ..., Xn and is frequently used in calculations related to entropy and mutual information. These calculations are fundamental for understanding data compression and transmission. X2's i.i.d. nature simplifies probabilistic analyses, making it a versatile and essential entity in theoretical and applied studies. [Data: Entities (116), Relationships (114)]"
        },
        {
            "summary": "XN as a key component in communication theory",
            "explanation": "XN is a discrete random variable that is part of the sequence X1, X2, ..., Xn. It is characterized as an i.i.d. random variable and is used in statistical analyses to compute joint entropy and conditional entropy. XN is also described as the sequence of input characters in a discrete memoryless channel, a model used in communication theory. This makes XN a critical entity for understanding data transmission and processing in communication systems. [Data: Entities (117), Relationships (117)]"
        },
        {
            "summary": "Joint entropy H(X1,X2,...,XN) as a measure of system uncertainty",
            "explanation": "H(X1,X2,...,Xn) represents the joint entropy of the random variables X1, X2, ..., Xn, which measures the total uncertainty of the system. This measure is crucial for understanding the relationships and dependencies between the variables in the context of data compression and transmission. The joint entropy is calculated using the conditional entropies H(Xi|Xi-1,...,X1), making it a key concept in information theory. [Data: Entities (118), Relationships (119)]"
        },
        {
            "summary": "Conditional entropy H(Xi|Xi-1,...,X1) as a measure of uncertainty",
            "explanation": "H(Xi|Xi-1,...,X1) represents the conditional entropy of Xi given Xi-1, ..., X1, which measures the uncertainty of Xi when Xi-1, ..., X1 are known. This measure is essential for understanding the dependencies between random variables in the sequence X1, X2, ..., Xn. Conditional entropy is used in the calculation of joint entropy, making it a fundamental concept in information theory and data compression. [Data: Entities (119), Relationships (119)]"
        }
    ]
}
```.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\services\json.py", line 77, in invoke
    return await this.invoke_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\services\json.py", line 100, in invoke_json
    raise FailedToGenerateValidJsonError from error
fnllm.base.services.errors.FailedToGenerateValidJsonError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\graphrag\index\operations\summarize_communities\community_reports_extractor.py", line 80, in __call__
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\graphrag\language_model\providers\fnllm\models.py", line 81, in achat
    response = await self.model(prompt, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\openai\llm\openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\openai\services\openai_tools_parsing.py", line 130, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\base_llm.py", line 148, in __call__
    await self._events.on_error(
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\graphrag\language_model\providers\fnllm\events.py", line 26, in on_error
    self._on_error(error, traceback, arguments)
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\graphrag\language_model\providers\fnllm\utils.py", line 45, in on_error
    callbacks.error("Error Invoking LLM", error, stack, details)
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\graphrag\callbacks\workflow_callbacks_manager.py", line 64, in error
    callback.error(message, cause, stack, details)
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\graphrag\callbacks\file_workflow_callbacks.py", line 37, in error
    json.dumps(
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\__init__.py", line 238, in dumps
    **kw).encode(obj)
          ^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 202, in encode
    chunks = list(chunks)
             ^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 432, in _iterencode
    yield from _iterencode_dict(o, _current_indent_level)
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 406, in _iterencode_dict
    yield from chunks
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 406, in _iterencode_dict
    yield from chunks
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 406, in _iterencode_dict
    yield from chunks
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 439, in _iterencode
    o = _default(o)
        ^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 180, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
TypeError: Object of type ModelMetaclass is not JSON serializable
16:51:15,823 graphrag.callbacks.file_workflow_callbacks INFO Community Report Extraction Error details=None
16:51:15,823 graphrag.index.operations.summarize_communities.strategies WARNING No report found for community: 26.0
16:51:16,22 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:51:18,331 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:51:23,721 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:51:23,725 graphrag.index.operations.summarize_communities.community_reports_extractor ERROR error generating community report
Traceback (most recent call last):
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\services\json.py", line 126, in _parse_json_string
    return json.loads(value) if value else None
           ^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\__init__.py", line 346, in loads
    return _default_decoder.decode(s)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\services\json.py", line 96, in invoke_json
    return await self.try_receive_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\services\json.py", line 114, in try_receive_json
    raw_json = self._parse_json_string(json_string)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\services\json.py", line 129, in _parse_json_string
    raise FailedToGenerateValidJsonError(msg) from err
fnllm.base.services.errors.FailedToGenerateValidJsonError: JSON response is not a valid JSON, response=```json
{
    "title": "Gaussian Relay and Interference Channel Entities",
    "summary": "The community is centered around the Gaussian relay and interference channel models, with key entities including Y1, Y2, U, and various transmitters and receivers. These entities are interconnected through signal transmission, decoding, and noise representation, highlighting their roles in ensuring accurate communication within the channel frameworks.",
    "rating": 7.5,
    "rating_explanation": "The impact severity rating is high due to the critical roles of entities in ensuring accurate signal processing and communication within the Gaussian channel models.",
    "findings": [
        {
            "summary": "Y1 as a critical relay receiver",
            "explanation": "Y1 is a pivotal entity in the Gaussian relay channel model, functioning as a relay receiver. It processes signals by subtracting the codeword of Y2 and seeks the closest codeword in the first codebook, ensuring accurate decoding. This role underscores Y1's importance in maintaining the integrity of the communication process. [Data: Entities (705), Relationships (825, 899)]"
        },
        {
            "summary": "Y2's dual role in signal processing and decoding",
            "explanation": "Y2 serves as both a signal processor and a decoder in the Gaussian relay channel model. It processes signals received by Receiver 2 and identifies the closest codeword in the second codebook, ensuring accurate message retrieval. This dual functionality highlights Y2's critical role in the communication framework. [Data: Entities (706), Relationships (827)]"
        },
        {
            "summary": "U's significance in clustering and mathematical frameworks",
            "explanation": "U is a clustering center used in encoding and decoding processes, playing a vital role in data transformation and analysis. Additionally, U is associated with an organization involved in mathematical proofs, operating within a defined value range. This dual functionality emphasizes U's importance in computational and mathematical accuracy. [Data: Entities (758), Relationships (899)]"
        },
        {
            "summary": "Transmitter 2 and Receiver 2 interaction",
            "explanation": "Transmitter 2 sends information to Receiver 2 in the Gaussian interference channel scenario. This interaction is crucial for the accurate transmission and reception of messages, highlighting the importance of these entities in the communication process. [Data: Entities (709, 711), Relationships (830)]"
        },
        {
            "summary": "Noise representation by Z1 and Z2",
            "explanation": "Z1 and Z2 are independent random variables representing noise in the Gaussian interference channel scenario. They affect the signals received by Receiver 1 and Receiver 2, respectively, underscoring the challenges in maintaining signal integrity in noisy environments. [Data: Entities (712, 713), Relationships (833, 835)]"
        }
    ]
}
```.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\services\json.py", line 77, in invoke
    return await this.invoke_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\services\json.py", line 100, in invoke_json
    raise FailedToGenerateValidJsonError from error
fnllm.base.services.errors.FailedToGenerateValidJsonError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\graphrag\index\operations\summarize_communities\community_reports_extractor.py", line 80, in __call__
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\graphrag\language_model\providers\fnllm\models.py", line 81, in achat
    response = await self.model(prompt, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\openai\llm\openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\openai\services\openai_tools_parsing.py", line 130, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\base_llm.py", line 148, in __call__
    await self._events.on_error(
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\graphrag\language_model\providers\fnllm\events.py", line 26, in on_error
    self._on_error(error, traceback, arguments)
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\graphrag\language_model\providers\fnllm\utils.py", line 45, in on_error
    callbacks.error("Error Invoking LLM", error, stack, details)
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\graphrag\callbacks\workflow_callbacks_manager.py", line 64, in error
    callback.error(message, cause, stack, details)
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\graphrag\callbacks\file_workflow_callbacks.py", line 37, in error
    json.dumps(
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\__init__.py", line 238, in dumps
    **kw).encode(obj)
          ^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 202, in encode
    chunks = list(chunks)
             ^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 432, in _iterencode
    yield from _iterencode_dict(o, _current_indent_level)
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 406, in _iterencode_dict
    yield from chunks
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 406, in _iterencode_dict
    yield from chunks
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 406, in _iterencode_dict
    yield from chunks
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 439, in _iterencode
    o = _default(o)
        ^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 180, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
TypeError: Object of type ModelMetaclass is not JSON serializable
16:51:23,731 graphrag.callbacks.file_workflow_callbacks INFO Community Report Extraction Error details=None
16:51:23,731 graphrag.index.operations.summarize_communities.strategies WARNING No report found for community: 34.0
16:51:23,851 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:51:25,128 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:51:28,38 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:51:29,709 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:51:31,689 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:51:39,225 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:51:40,826 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:51:46,204 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:51:46,208 graphrag.index.operations.summarize_communities.community_reports_extractor ERROR error generating community report
Traceback (most recent call last):
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\services\json.py", line 126, in _parse_json_string
    return json.loads(value) if value else None
           ^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\__init__.py", line 346, in loads
    return _default_decoder.decode(s)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\services\json.py", line 96, in invoke_json
    return await self.try_receive_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\services\json.py", line 114, in try_receive_json
    raw_json = self._parse_json_string(json_string)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\services\json.py", line 129, in _parse_json_string
    raise FailedToGenerateValidJsonError(msg) from err
fnllm.base.services.errors.FailedToGenerateValidJsonError: JSON response is not a valid JSON, response=```json
{
    "title": "Information Theory Community: Shannon, Wolfowitz, and Key Theorems",
    "summary": "This community revolves around foundational principles in information theory, with key entities including Shannon, Wolfowitz, the Channel Capacity Theorem, and the Channel Coding Theorem. These entities are interconnected through their contributions to understanding the limits and capabilities of communication systems, particularly in the context of reliable data transmission over noisy channels.",
    "rating": 8.5,
    "rating_explanation": "The impact severity rating is high due to the foundational nature of the theorems and their significant influence on the field of information theory and communication systems.",
    "findings": [
        {
            "summary": "Shannon's foundational role in information theory",
            "explanation": "Shannon is a central figure in this community, having introduced the Channel Capacity Theorem and the concept of random code selection. His seminal work in 1948 laid the groundwork for understanding the limits of data transmission over communication channels, making him a pivotal entity in the field of information theory. [Data: Relationships (351, 352)]"
        },
        {
            "summary": "Wolfowitz's contributions to channel capacity",
            "explanation": "Wolfowitz is another key entity, recognized for his rigorous proof of the Channel Capacity Theorem and his contributions to the method of types. His work has been instrumental in advancing the theoretical foundations of information theory, particularly in understanding the conditions for reliable communication. [Data: Entities (394), Relationships (638)]"
        },
        {
            "summary": "Channel Capacity Theorem as a cornerstone",
            "explanation": "The Channel Capacity Theorem is a fundamental principle in information theory, establishing the conditions under which information can be reliably transmitted through a communication channel. This theorem serves as a cornerstone in understanding the limits and capabilities of communication systems. [Data: Entities (331), Relationships (351)]"
        },
        {
            "summary": "Channel Coding Theorem's role in reliable communication",
            "explanation": "The Channel Coding Theorem defines the maximum rate, known as the channel capacity, at which information can be transmitted through a noisy channel with arbitrarily low error probability. This theorem is a key result in information theory, providing a theoretical foundation for the design and analysis of communication systems. [Data: Entities (332), Relationships (354)]"
        },
        {
            "summary": "Jointly Typical Decoding in achieving reliable transmission",
            "explanation": "Jointly Typical Decoding is a method used to decode messages by checking if the received sequence and the transmitted codeword are jointly typical, ensuring low error probability. This method is crucial in achieving the rates described in the Channel Coding Theorem. [Data: Entities (336), Relationships (357)]"
        }
    ]
}
```.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\services\json.py", line 77, in invoke
    return await this.invoke_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\services\json.py", line 100, in invoke_json
    raise FailedToGenerateValidJsonError from error
fnllm.base.services.errors.FailedToGenerateValidJsonError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\graphrag\index\operations\summarize_communities\community_reports_extractor.py", line 80, in __call__
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\graphrag\language_model\providers\fnllm\models.py", line 81, in achat
    response = await self.model(prompt, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\openai\llm\openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\openai\services\openai_tools_parsing.py", line 130, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\base_llm.py", line 148, in __call__
    await self._events.on_error(
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\graphrag\language_model\providers\fnllm\events.py", line 26, in on_error
    self._on_error(error, traceback, arguments)
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\graphrag\language_model\providers\fnllm\utils.py", line 45, in on_error
    callbacks.error("Error Invoking LLM", error, stack, details)
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\graphrag\callbacks\workflow_callbacks_manager.py", line 64, in error
    callback.error(message, cause, stack, details)
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\graphrag\callbacks\file_workflow_callbacks.py", line 37, in error
    json.dumps(
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\__init__.py", line 238, in dumps
    **kw).encode(obj)
          ^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 202, in encode
    chunks = list(chunks)
             ^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 432, in _iterencode
    yield from _iterencode_dict(o, _current_indent_level)
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 406, in _iterencode_dict
    yield from chunks
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 406, in _iterencode_dict
    yield from chunks
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 406, in _iterencode_dict
    yield from chunks
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 439, in _iterencode
    o = _default(o)
        ^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 180, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
TypeError: Object of type ModelMetaclass is not JSON serializable
16:51:46,213 graphrag.callbacks.file_workflow_callbacks INFO Community Report Extraction Error details=None
16:51:46,213 graphrag.index.operations.summarize_communities.strategies WARNING No report found for community: 35.0
16:51:48,633 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:51:49,332 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:51:51,973 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:51:54,225 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:51:54,884 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:52:01,254 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:52:02,587 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:52:07,537 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:52:07,883 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:52:14,256 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:52:14,700 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:52:15,153 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:52:15,157 graphrag.index.operations.summarize_communities.community_reports_extractor ERROR error generating community report
Traceback (most recent call last):
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\services\json.py", line 126, in _parse_json_string
    return json.loads(value) if value else None
           ^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\__init__.py", line 346, in loads
    return _default_decoder.decode(s)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\services\json.py", line 96, in invoke_json
    return await self.try_receive_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\services\json.py", line 114, in try_receive_json
    raw_json = self._parse_json_string(json_string)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\services\json.py", line 129, in _parse_json_string
    raise FailedToGenerateValidJsonError(msg) from err
fnllm.base.services.errors.FailedToGenerateValidJsonError: JSON response is not a valid JSON, response=```json
{
    "title": "Physical Degraded Relay Channel and Encoding Techniques",
    "summary": "The community centers around the Physical Degraded Relay Channel, a key concept in information theory, and its associated encoding techniques such as Block Markov Encoding, Random Coding, Slepian-Wolf Partition, and Cooperative Multiple Access Channel Coding. These techniques are foundational in proving the achievability of the relay channel and are interconnected through various relationships, highlighting their importance in advancing communication systems.",
    "rating": 7.5,
    "rating_explanation": "The impact severity rating is high due to the foundational role of these entities in advancing information theory and communication systems.",
    "findings": [
        {
            "summary": "Physical Degraded Relay Channel as the central entity",
            "explanation": "The Physical Degraded Relay Channel is the central entity in this community, serving as the focal point for various encoding techniques. These techniques are used to prove the achievability of the relay channel, making it a critical concept in information theory. The channel's role in advancing communication systems underscores its importance in the community. [Data: Entities (770), Relationships (924, 920, 921, 922)]"
        },
        {
            "summary": "Block Markov Encoding's critical role",
            "explanation": "Block Markov Encoding is a key technique used in the proof of achievability for the Physical Degraded Relay Channel. Its prominence in academic literature and its foundational role in demonstrating theoretical limits of communication systems highlight its significance. The relationship between Block Markov Encoding and the Physical Degraded Relay Channel is crucial in understanding the community's dynamics. [Data: Entities (775), Relationships (924, 1691)]"
        },
        {
            "summary": "Random Coding's application in the relay channel",
            "explanation": "Random Coding is another essential technique used in the proof of achievability for the Physical Degraded Relay Channel. Its application in this context underscores its importance in advancing the understanding of information transfer and optimization in complex network structures. The relationship between Random Coding and the Physical Degraded Relay Channel is a key aspect of the community. [Data: Entities (772), Relationships (920)]"
        },
        {
            "summary": "Slepian-Wolf Partition's contribution",
            "explanation": "The Slepian-Wolf Partition is a technique used in the proof of achievability for the Physical Degraded Relay Channel. Its role in this proof highlights its importance in the community, particularly in the context of information theory and communication systems. The relationship between the Slepian-Wolf Partition and the Physical Degraded Relay Channel is a significant aspect of the community's structure. [Data: Entities (771), Relationships (921)]"
        },
        {
            "summary": "Cooperative Multiple Access Channel Coding's significance",
            "explanation": "Cooperative Multiple Access Channel Coding is a technique used in the proof of achievability for the Physical Degraded Relay Channel. Its application in this context underscores its importance in advancing the understanding of information transfer and optimization in complex network structures. The relationship between Cooperative Multiple Access Channel Coding and the Physical Degraded Relay Channel is a key aspect of the community. [Data: Entities (773), Relationships (922)]"
        },
        {
            "summary": "Block Code's connection to Block Markov Encoding",
            "explanation": "Block Code is a type of error-correcting code used in digital communications and is connected to Block Markov Encoding. This relationship highlights the interconnectedness of various encoding techniques within the community and their collective role in advancing communication systems. The relationship between Block Code and Block Markov Encoding is a significant aspect of the community's structure. [Data: Entities (1537), Relationships (1691)]"
        },
        {
            "summary": "Binning's role in Block Code design",
            "explanation": "Binning is a technique used in data analysis and information theory and plays a role in the design of Block Codes. This relationship underscores the importance of Binning in the community, particularly in the context of error-correcting codes and digital communications. The relationship between Binning and Block Code is a key aspect of the community's structure. [Data: Entities (1534), Relationships (1690)]"
        },
        {
            "summary": "Bose's contributions to coding theory",
            "explanation": "Bose, R. C. is a mathematician known for contributions to coding theory, including block codes. His work is referenced in the context of Block Code, highlighting his significance in the community. The relationship between Bose and Block Code underscores the importance of historical contributions to the field of information theory. [Data: Entities (1541), Relationships (1694)]"
        },
        {
            "summary": "Blahut-Arimoto Algorithm's application",
            "explanation": "The Blahut-Arimoto Algorithm is a method used in information theory for computing channel capacity and rate-distortion functions. Its application in the context of the Binary Rate Distortion Function highlights its importance in the community. The relationship between the Blahut-Arimoto Algorithm and the Binary Rate Distortion Function is a key aspect of the community's structure. [Data: Entities (1524), Relationships (1685)]"
        },
        {
            "summary": "Blahut's association with the Blahut-Arimoto Algorithm",
            "explanation": "Blahut, R.E. is associated with the Blahut-Arimoto Algorithm, a method used in information theory for computing channel capacity and rate-distortion functions. This relationship highlights the importance of individual contributions to the field of information theory and their impact on the community. The relationship between Blahut and the Blahut-Arimoto Algorithm is a significant aspect of the community's structure. [Data: Entities (1522), Relationships (1693)]"
        }
    ]
}
```.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\services\json.py", line 77, in invoke
    return await this.invoke_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\services\json.py", line 100, in invoke_json
    raise FailedToGenerateValidJsonError from error
fnllm.base.services.errors.FailedToGenerateValidJsonError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\graphrag\index\operations\summarize_communities\community_reports_extractor.py", line 80, in __call__
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\graphrag\language_model\providers\fnllm\models.py", line 81, in achat
    response = await self.model(prompt, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\openai\llm\openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\openai\services\openai_tools_parsing.py", line 130, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\base_llm.py", line 148, in __call__
    await self._events.on_error(
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\graphrag\language_model\providers\fnllm\events.py", line 26, in on_error
    self._on_error(error, traceback, arguments)
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\graphrag\language_model\providers\fnllm\utils.py", line 45, in on_error
    callbacks.error("Error Invoking LLM", error, stack, details)
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\graphrag\callbacks\workflow_callbacks_manager.py", line 64, in error
    callback.error(message, cause, stack, details)
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\graphrag\callbacks\file_workflow_callbacks.py", line 37, in error
    json.dumps(
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\__init__.py", line 238, in dumps
    **kw).encode(obj)
          ^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 202, in encode
    chunks = list(chunks)
             ^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 432, in _iterencode
    yield from _iterencode_dict(o, _current_indent_level)
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 406, in _iterencode_dict
    yield from chunks
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 406, in _iterencode_dict
    yield from chunks
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 406, in _iterencode_dict
    yield from chunks
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 439, in _iterencode
    o = _default(o)
        ^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 180, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
TypeError: Object of type ModelMetaclass is not JSON serializable
16:52:15,164 graphrag.callbacks.file_workflow_callbacks INFO Community Report Extraction Error details=None
16:52:15,164 graphrag.index.operations.summarize_communities.strategies WARNING No report found for community: 31.0
16:52:18,244 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:52:22,249 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:52:22,417 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:52:30,352 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:52:33,303 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:52:36,465 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:52:37,785 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:52:41,166 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:52:41,275 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:52:45,449 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:52:45,716 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:52:46,381 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:52:46,385 graphrag.index.operations.summarize_communities.community_reports_extractor ERROR error generating community report
Traceback (most recent call last):
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\services\json.py", line 126, in _parse_json_string
    return json.loads(value) if value else None
           ^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\__init__.py", line 346, in loads
    return _default_decoder.decode(s)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\services\json.py", line 96, in invoke_json
    return await self.try_receive_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\services\json.py", line 114, in try_receive_json
    raw_json = self._parse_json_string(json_string)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\services\json.py", line 129, in _parse_json_string
    raise FailedToGenerateValidJsonError(msg) from err
fnllm.base.services.errors.FailedToGenerateValidJsonError: JSON response is not a valid JSON, response=```json
{
    "title": "Mathematical Community of Entropy and Inequalities",
    "summary": "This community revolves around key mathematicians and fundamental mathematical theorems, particularly in the fields of information theory and convex geometry. Central figures include BLACHMAN, STAM, DEMBO, and LIEB, who have made significant contributions to the entropy power inequality and the Brunn-Minkowski inequality. These theorems are interconnected through shared proof methods and conceptual frameworks, highlighting the collaborative and interdisciplinary nature of this mathematical community.",
    "rating": 8.5,
    "rating_explanation": "The impact severity rating is high due to the foundational nature of the theorems and the significant contributions of the mathematicians involved.",
    "findings": [
        {
            "summary": "BLACHMAN's pivotal role in the entropy power inequality",
            "explanation": "BLACHMAN is a central figure in this community, known for his contributions to the entropy power inequality. His collaboration with STAM led to the first formal proof of this theorem, which remains a cornerstone in information theory. This work underscores BLACHMAN's expertise and the collaborative nature of mathematical advancements. [Data: Entities (901), Relationships (1099, 1097)]"
        },
        {
            "summary": "STAM's foundational contributions to entropy theory",
            "explanation": "STAM is another key figure in the community, recognized for his work on the entropy power inequality. His collaboration with BLACHMAN was instrumental in establishing the first formal proof of this theorem, which has had a lasting impact on the field of information theory. [Data: Entities (900), Relationships (1097)]"
        },
        {
            "summary": "Interconnection between entropy power inequality and Brunn-Minkowski inequality",
            "explanation": "The entropy power inequality and the Brunn-Minkowski inequality are closely related, both conceptually and methodologically. They share a common proof method developed by DEMBO and LIEB, highlighting the deep connections between information theory and convex geometry. [Data: Entities (902, 898), Relationships (1100, 1101)]"
        },
        {
            "summary": "DEMBO and LIEB's unified proof method",
            "explanation": "DEMBO and LIEB collaborated to develop a unified proof method that addresses both the entropy power inequality and the Brunn-Minkowski inequality. This innovative approach demonstrates their ability to connect seemingly distinct mathematical concepts, contributing significantly to the field. [Data: Entities (903, 904), Relationships (1103)]"
        },
        {
            "summary": "Young's inequality as inspiration for proof methods",
            "explanation": "Young's inequality inspired the proof method used by DEMBO and LIEB for the Brunn-Minkowski inequality. This highlights the influence of earlier mathematical work on contemporary advancements in the field. [Data: Entities (906), Relationships (1102)]"
        },
        {
            "summary": "Fan's theorem in relation to entropy power inequality",
            "explanation": "Fan's theorem is related to the entropy power inequality through the study of information theory and matrix determinants. This connection underscores the interdisciplinary nature of the community's research. [Data: Entities (909), Relationships (1108)]"
        }
    ]
}
```.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\services\json.py", line 77, in invoke
    return await this.invoke_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\services\json.py", line 100, in invoke_json
    raise FailedToGenerateValidJsonError from error
fnllm.base.services.errors.FailedToGenerateValidJsonError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\graphrag\index\operations\summarize_communities\community_reports_extractor.py", line 80, in __call__
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\graphrag\language_model\providers\fnllm\models.py", line 81, in achat
    response = await self.model(prompt, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\openai\llm\openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\openai\services\openai_tools_parsing.py", line 130, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\base_llm.py", line 148, in __call__
    await self._events.on_error(
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\graphrag\language_model\providers\fnllm\events.py", line 26, in on_error
    self._on_error(error, traceback, arguments)
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\graphrag\language_model\providers\fnllm\utils.py", line 45, in on_error
    callbacks.error("Error Invoking LLM", error, stack, details)
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\graphrag\callbacks\workflow_callbacks_manager.py", line 64, in error
    callback.error(message, cause, stack, details)
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\graphrag\callbacks\file_workflow_callbacks.py", line 37, in error
    json.dumps(
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\__init__.py", line 238, in dumps
    **kw).encode(obj)
          ^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 202, in encode
    chunks = list(chunks)
             ^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 432, in _iterencode
    yield from _iterencode_dict(o, _current_indent_level)
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 406, in _iterencode_dict
    yield from chunks
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 406, in _iterencode_dict
    yield from chunks
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 406, in _iterencode_dict
    yield from chunks
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 439, in _iterencode
    o = _default(o)
        ^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 180, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
TypeError: Object of type ModelMetaclass is not JSON serializable
16:52:46,391 graphrag.callbacks.file_workflow_callbacks INFO Community Report Extraction Error details=None
16:52:46,391 graphrag.index.operations.summarize_communities.strategies WARNING No report found for community: 39.0
16:52:49,58 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:52:51,944 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:52:54,559 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:52:59,653 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:53:02,66 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:53:03,674 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:53:04,864 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:53:07,583 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:53:07,588 graphrag.index.operations.summarize_communities.community_reports_extractor ERROR error generating community report
Traceback (most recent call last):
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\services\json.py", line 126, in _parse_json_string
    return json.loads(value) if value else None
           ^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\__init__.py", line 346, in loads
    return _default_decoder.decode(s)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\services\json.py", line 96, in invoke_json
    return await self.try_receive_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\services\json.py", line 114, in try_receive_json
    raw_json = self._parse_json_string(json_string)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\services\json.py", line 129, in _parse_json_string
    raise FailedToGenerateValidJsonError(msg) from err
fnllm.base.services.errors.FailedToGenerateValidJsonError: JSON response is not a valid JSON, response=```json
{
    "title": "Shannon and Information Theory Community",
    "summary": "The community centers around Claude E. Shannon, a foundational figure in information theory, and his extensive contributions to the field. Key entities include Boltzmann, Hartley, Fano, and others who have influenced or been influenced by Shannon's work. The relationships between these entities highlight the interconnectedness of their contributions, particularly in areas such as entropy, channel capacity, and coding techniques. Shannon's work during World War II in cryptography also played a pivotal role in shaping his later theoretical advancements.",
    "rating": 9.5,
    "rating_explanation": "The impact severity rating is very high due to the foundational and transformative nature of Shannon's contributions to information theory and its widespread applications.",
    "findings": [
        {
            "summary": "Claude Shannon's foundational role in information theory",
            "explanation": "Claude E. Shannon is widely recognized as a pioneer in information theory, with his 1948 paper introducing key concepts such as entropy, mutual information, and channel capacity. His work laid the groundwork for data compression algorithms and established the theoretical limits of communication systems. Shannon's contributions remain central to the field, influencing numerous subsequent developments [Data: Entities (61), Relationships (44, 1819, 1820, 1821)]."
        },
        {
            "summary": "Influence of Boltzmann on Shannon's work",
            "explanation": "Ludwig Boltzmann's work on entropy significantly influenced Shannon's development of information theory. Boltzmann's equation \( S = k \ln W \) established a fundamental relationship between thermodynamic entropy and the number of microscopic states, which inspired Shannon's exploration of entropy in communication systems [Data: Entities (136), Relationships (144)]."
        },
        {
            "summary": "Hartley's logarithmic measure of information",
            "explanation": "Hartley introduced the logarithmic measure of information in the 1930s, which played a crucial role in shaping Shannon's understanding of entropy and mutual information. This foundational concept provided a mathematical basis for quantifying information, which Shannon later expanded upon in his work [Data: Entities (137), Relationships (145)]."
        },
        {
            "summary": "Shannon's wartime cryptography work",
            "explanation": "During World War II, Shannon's work in cryptography was pivotal in shaping his later contributions to information theory. His experiences and insights gained during this period directly inspired his foundational work in the field, highlighting the dual influence of his wartime efforts on his theoretical advancements [Data: Entities (290), Relationships (306)]."
        },
        {
            "summary": "Fano's contributions to coding techniques",
            "explanation": "Fano is a significant figure in information theory, primarily associated with Fano's inequality and the Shannon-Fano coding method. His work on these coding techniques, influenced by Shannon's simple coding construction, has had a lasting impact on the field, particularly in the areas of data compression and error correction [Data: Entities (142), Relationships (268, 1764)]."
        },
        {
            "summary": "Chung's extension of the AEP theorem",
            "explanation": "Chung extended the Asymptotic Equipartition Property (AEP) theorem, which was first discussed by Shannon. This extension to countable alphabets further advanced the understanding of entropy and its applications in information theory [Data: Entities (164), Relationships (164)]."
        },
        {
            "summary": "Feinstein's rigorous proof of channel capacity",
            "explanation": "Feinstein provided the first rigorous proof of the channel capacity theorem, which Shannon initially introduced. This proof solidified the theoretical foundations of the theorem, ensuring its applicability in practical communication systems [Data: Entities (391), Relationships (433)]."
        },
        {
            "summary": "Schalkwijk's coding schemes for two-way channels",
            "explanation": "Schalkwijk proposed coding schemes for two-way channels that exceeded Shannon's inner bounds. These advancements demonstrated the potential for improving communication efficiency and reliability, building upon Shannon's foundational work [Data: Entities (809), Relationships (968)]."
        }
    ]
}
```.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\services\json.py", line 77, in invoke
    return await this.invoke_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\services\json.py", line 100, in invoke_json
    raise FailedToGenerateValidJsonError from error
fnllm.base.services.errors.FailedToGenerateValidJsonError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\graphrag\index\operations\summarize_communities\community_reports_extractor.py", line 80, in __call__
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\graphrag\language_model\providers\fnllm\models.py", line 81, in achat
    response = await self.model(prompt, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\openai\llm\openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\openai\services\openai_tools_parsing.py", line 130, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\base_llm.py", line 148, in __call__
    await self._events.on_error(
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\graphrag\language_model\providers\fnllm\events.py", line 26, in on_error
    self._on_error(error, traceback, arguments)
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\graphrag\language_model\providers\fnllm\utils.py", line 45, in on_error
    callbacks.error("Error Invoking LLM", error, stack, details)
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\graphrag\callbacks\workflow_callbacks_manager.py", line 64, in error
    callback.error(message, cause, stack, details)
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\graphrag\callbacks\file_workflow_callbacks.py", line 37, in error
    json.dumps(
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\__init__.py", line 238, in dumps
    **kw).encode(obj)
          ^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 202, in encode
    chunks = list(chunks)
             ^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 432, in _iterencode
    yield from _iterencode_dict(o, _current_indent_level)
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 406, in _iterencode_dict
    yield from chunks
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 406, in _iterencode_dict
    yield from chunks
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 406, in _iterencode_dict
    yield from chunks
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 439, in _iterencode
    o = _default(o)
        ^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 180, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
TypeError: Object of type ModelMetaclass is not JSON serializable
16:53:07,594 graphrag.callbacks.file_workflow_callbacks INFO Community Report Extraction Error details=None
16:53:07,594 graphrag.index.operations.summarize_communities.strategies WARNING No report found for community: 37.0
16:53:09,172 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:53:11,286 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:53:17,604 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:53:18,731 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:53:18,845 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:53:21,660 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:53:25,942 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:53:27,111 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:53:30,252 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:53:30,832 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:53:36,264 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:53:36,269 graphrag.index.operations.summarize_communities.community_reports_extractor ERROR error generating community report
Traceback (most recent call last):
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\services\json.py", line 126, in _parse_json_string
    return json.loads(value) if value else None
           ^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\__init__.py", line 346, in loads
    return _default_decoder.decode(s)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\services\json.py", line 96, in invoke_json
    return await self.try_receive_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\services\json.py", line 114, in try_receive_json
    raw_json = self._parse_json_string(json_string)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\services\json.py", line 129, in _parse_json_string
    raise FailedToGenerateValidJsonError(msg) from err
fnllm.base.services.errors.FailedToGenerateValidJsonError: JSON response is not a valid JSON, response=```json
{
    "title": "Information Theory and Data Compression Community",
    "summary": "This community revolves around key figures and concepts in information theory and data compression, including Rissanen, Pasco, and Langdon, who have made significant contributions to arithmetic coding and the Minimum Description Length (MDL) principle. The Shannon-Fano-Elias method and arithmetic coding are central to this community, with relationships highlighting collaborative advancements in finite precision algorithms and efficient data encoding methods.",
    "rating": 8.5,
    "rating_explanation": "The impact severity rating is high due to the foundational contributions of the community's key entities to information theory and data compression, which have broad applications in computer science and mathematics.",
    "findings": [
        {
            "summary": "Rissanen's pivotal role in the community",
            "explanation": "Rissanen is a central figure in this community, known for developing the Minimum Description Length (MDL) principle and making significant contributions to arithmetic coding. His work has had a profound impact on both theoretical and applied aspects of mathematics and computer science, particularly in the fields of model selection and statistical inference. Rissanen's collaborations with Pasco and Langdon have further advanced the understanding and application of arithmetic coding. [Data: Entities (265, 681), Relationships (283, 285, 798)]"
        },
        {
            "summary": "Pasco's contributions to arithmetic coding",
            "explanation": "Pasco is recognized for proposing arithmetic coding, a technique used in finite precision algorithms, in collaboration with Rissanen. This work has been instrumental in the development of efficient data encoding methods, highlighting Pasco's role in advancing the understanding and application of arithmetic coding. Pasco's contributions are significant in the context of finite precision algorithms, which are crucial for efficient computational methods. [Data: Entities (264), Relationships (283)]"
        },
        {
            "summary": "Langdon's role in generalizing arithmetic coding",
            "explanation": "Langdon, in collaboration with Rissanen, played a key role in generalizing arithmetic coding, marking a pivotal development in the field. His contributions have enhanced the applicability and efficiency of arithmetic coding, making it a fundamental procedure in information theory. Langdon's work, along with Rissanen's, has solidified the importance of arithmetic coding in data compression. [Data: Entities (606), Relationships (715)]"
        },
        {
            "summary": "Shannon-Fano-Elias method and its extensions",
            "explanation": "The Shannon-Fano-Elias method is a key concept in this community, extended by Cover to sequences using enumeration methods. This method is closely related to arithmetic coding, with both being methods for encoding sequences of random variables. The Shannon-Fano-Elias method has been further developed through contributions from Rissanen, who applied finite precision algorithms to enhance its efficiency. [Data: Entities (271), Relationships (282, 285, 678)]"
        },
        {
            "summary": "Arithmetic coding as a fundamental procedure",
            "explanation": "Arithmetic coding is a pivotal procedure in information theory, representing a sequence of random variables as a subinterval within the range [0,1]. Initially proposed by Rissanen and Pasco, the technique was later generalized by Langdon and Rissanen, further enhancing its applicability and efficiency in data compression. Arithmetic coding plays a fundamental role in Shannon-Fano coding and has been extensively analyzed by researchers such as Jelinek. [Data: Entities (269), Relationships (678, 715)]"
        },
        {
            "summary": "Minimum Description Length (MDL) principle",
            "explanation": "The Minimum Description Length (MDL) principle, developed by Rissanen, is closely related to Kolmogorov's sufficient statistics and provides a framework for model selection and statistical inference. This principle aims to find the simplest model that explains the data, making it a significant contribution to both theoretical and applied aspects of mathematics and computer science. The MDL principle has had a profound impact on the field of information theory. [Data: Entities (681), Relationships (798)]"
        },
        {
            "summary": "Collaborative advancements in finite precision algorithms",
            "explanation": "Collaborative efforts between Pasco and Rissanen have led to significant advancements in finite precision algorithms, which are crucial for efficient data encoding methods. These algorithms have been applied to the Shannon-Fano-Elias method and arithmetic coding, enhancing their efficiency and applicability. The contributions of Pasco and Rissanen in this area have been instrumental in advancing the field of data compression. [Data: Entities (264, 265), Relationships (283, 285)]"
        }
    ]
}
```.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\services\json.py", line 77, in invoke
    return await this.invoke_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\services\json.py", line 100, in invoke_json
    raise FailedToGenerateValidJsonError from error
fnllm.base.services.errors.FailedToGenerateValidJsonError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\graphrag\index\operations\summarize_communities\community_reports_extractor.py", line 80, in __call__
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\graphrag\language_model\providers\fnllm\models.py", line 81, in achat
    response = await self.model(prompt, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\openai\llm\openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\openai\services\openai_tools_parsing.py", line 130, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\base_llm.py", line 148, in __call__
    await self._events.on_error(
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\graphrag\language_model\providers\fnllm\events.py", line 26, in on_error
    self._on_error(error, traceback, arguments)
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\graphrag\language_model\providers\fnllm\utils.py", line 45, in on_error
    callbacks.error("Error Invoking LLM", error, stack, details)
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\graphrag\callbacks\workflow_callbacks_manager.py", line 64, in error
    callback.error(message, cause, stack, details)
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\graphrag\callbacks\file_workflow_callbacks.py", line 37, in error
    json.dumps(
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\__init__.py", line 238, in dumps
    **kw).encode(obj)
          ^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 202, in encode
    chunks = list(chunks)
             ^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 432, in _iterencode
    yield from _iterencode_dict(o, _current_indent_level)
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 406, in _iterencode_dict
    yield from chunks
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 406, in _iterencode_dict
    yield from chunks
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 406, in _iterencode_dict
    yield from chunks
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 439, in _iterencode
    o = _default(o)
        ^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 180, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
TypeError: Object of type ModelMetaclass is not JSON serializable
16:53:36,275 graphrag.callbacks.file_workflow_callbacks INFO Community Report Extraction Error details=None
16:53:36,275 graphrag.index.operations.summarize_communities.strategies WARNING No report found for community: 45.0
16:53:37,360 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:53:37,365 graphrag.index.operations.summarize_communities.community_reports_extractor ERROR error generating community report
Traceback (most recent call last):
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\services\json.py", line 126, in _parse_json_string
    return json.loads(value) if value else None
           ^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\__init__.py", line 346, in loads
    return _default_decoder.decode(s)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\services\json.py", line 96, in invoke_json
    return await self.try_receive_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\services\json.py", line 114, in try_receive_json
    raw_json = self._parse_json_string(json_string)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\services\json.py", line 129, in _parse_json_string
    raise FailedToGenerateValidJsonError(msg) from err
fnllm.base.services.errors.FailedToGenerateValidJsonError: JSON response is not a valid JSON, response=```json
{
    "title": "Speaker and Listeners Community",
    "summary": "The community centers around a Speaker who communicates in Spanish and Dutch to two different listeners. Listener 2 understands only Dutch, and the Dutch language is associated with the concept of the Dutch book in probability theory. The relationships between these entities highlight the linguistic and conceptual connections within the community.",
    "rating": 3.5,
    "rating_explanation": "The impact severity rating is low to moderate due to the limited scope of the community's activities and interactions.",
    "findings": [
        {
            "summary": "Speaker's role in the community",
            "explanation": "The Speaker is a central entity in this community, delivering information in both Spanish and Dutch to two different listeners. This multilingual capability suggests the Speaker's importance in facilitating communication within the community. The Speaker's role is crucial in bridging the linguistic gap between the listeners. [Data: Entities (752), Relationships (889)]"
        },
        {
            "summary": "Listener 2's linguistic limitation",
            "explanation": "Listener 2 is a key entity in the community who understands only Dutch. This limitation shapes the dynamics of the community, as the Speaker must communicate with Listener 2 in Dutch. The relationship between Listener 2 and the Dutch language is essential in understanding the community's communication structure. [Data: Entities (754), Relationships (892)]"
        },
        {
            "summary": "Dutch language's conceptual association",
            "explanation": "The Dutch language is not only a medium of communication within the community but also associated with the concept of the Dutch book in probability theory. This association adds a layer of complexity to the community, linking linguistic elements with theoretical concepts. [Data: Entities (755), Relationships (1762)]"
        },
        {
            "summary": "Dutch Book's minimal role",
            "explanation": "The Dutch Book is an entity in the community with a minimal degree of connection. Its association with the Dutch language suggests a potential conceptual link, but its role in the community's activities appears to be limited. [Data: Entities (1647), Relationships (1762)]"
        }
    ]
}
```.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\services\json.py", line 77, in invoke
    return await this.invoke_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\services\json.py", line 100, in invoke_json
    raise FailedToGenerateValidJsonError from error
fnllm.base.services.errors.FailedToGenerateValidJsonError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\graphrag\index\operations\summarize_communities\community_reports_extractor.py", line 80, in __call__
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\graphrag\language_model\providers\fnllm\models.py", line 81, in achat
    response = await self.model(prompt, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\openai\llm\openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\openai\services\openai_tools_parsing.py", line 130, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\base_llm.py", line 148, in __call__
    await self._events.on_error(
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\graphrag\language_model\providers\fnllm\events.py", line 26, in on_error
    self._on_error(error, traceback, arguments)
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\graphrag\language_model\providers\fnllm\utils.py", line 45, in on_error
    callbacks.error("Error Invoking LLM", error, stack, details)
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\graphrag\callbacks\workflow_callbacks_manager.py", line 64, in error
    callback.error(message, cause, stack, details)
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\graphrag\callbacks\file_workflow_callbacks.py", line 37, in error
    json.dumps(
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\__init__.py", line 238, in dumps
    **kw).encode(obj)
          ^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 202, in encode
    chunks = list(chunks)
             ^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 432, in _iterencode
    yield from _iterencode_dict(o, _current_indent_level)
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 406, in _iterencode_dict
    yield from chunks
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 406, in _iterencode_dict
    yield from chunks
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 406, in _iterencode_dict
    yield from chunks
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 439, in _iterencode
    o = _default(o)
        ^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 180, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
TypeError: Object of type ModelMetaclass is not JSON serializable
16:53:37,371 graphrag.callbacks.file_workflow_callbacks INFO Community Report Extraction Error details=None
16:53:37,371 graphrag.index.operations.summarize_communities.strategies WARNING No report found for community: 54.0
16:53:38,58 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:53:45,428 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:53:49,651 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:53:50,585 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:53:52,716 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:53:58,275 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:53:58,426 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:54:00,561 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:54:01,311 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:54:02,581 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:54:05,853 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:54:09,555 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:54:16,341 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:54:16,345 graphrag.index.operations.summarize_communities.community_reports_extractor ERROR error generating community report
Traceback (most recent call last):
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\services\json.py", line 126, in _parse_json_string
    return json.loads(value) if value else None
           ^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\__init__.py", line 346, in loads
    return _default_decoder.decode(s)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\services\json.py", line 96, in invoke_json
    return await self.try_receive_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\services\json.py", line 114, in try_receive_json
    raw_json = self._parse_json_string(json_string)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\services\json.py", line 129, in _parse_json_string
    raise FailedToGenerateValidJsonError(msg) from err
fnllm.base.services.errors.FailedToGenerateValidJsonError: JSON response is not a valid JSON, response=```json
{
    "title": "Broadcast Channel and Information Theory Community",
    "summary": "The community centers around the concept of the broadcast channel, a fundamental model in communication and information theory. Key entities include researchers like Gallager and Bergmans, who have made significant contributions to understanding the capacity region of degraded broadcast channels. The community also includes practical examples like television stations and classroom lecturers, which illustrate real-world applications of broadcast channels.",
    "rating": 7.5,
    "rating_explanation": "The impact severity rating is high due to the foundational importance of broadcast channels in communication systems and the significant contributions of key researchers in the field.",
    "findings": [
        {
            "summary": "Broadcast Channel as a Fundamental Concept",
            "explanation": "The broadcast channel is a core model in communication and information theory, representing one-to-many communication scenarios. It is characterized by a single transmitter sending information to multiple receivers, who may experience varying noise levels and have different capacities for processing the information. The study of broadcast channels focuses on determining the capacity region, which defines the achievable rates for reliable communication. This concept is crucial for optimizing communication efficiency and understanding the limitations of such channels. [Data: Entities (700)]"
        },
        {
            "summary": "Gallager's Contributions to Information Theory",
            "explanation": "R. G. Gallager is a prominent researcher who has made significant contributions to information theory, particularly in understanding the capacity of Gaussian channels and degraded broadcast channels. He provided a simpler proof of the channel capacity theorem using random coding exponents and contributed to the development of universal codes. Gallager's work has had a lasting impact on the theoretical foundations of communication systems. [Data: Entities (392), Relationships (438, 708)]"
        },
        {
            "summary": "Bergmans and the Capacity Region",
            "explanation": "Bergmans, along with Gallager, obtained the capacity region for degraded broadcast channels. This development is critical in the field of information theory, as it helps define the limits of reliable communication in one-to-many scenarios. Their work has advanced the understanding of how information can be efficiently transmitted to multiple receivers with varying capacities. [Data: Entities (815), Relationships (979)]"
        },
        {
            "summary": "Practical Examples of Broadcast Channels",
            "explanation": "Television stations and classroom lecturers serve as practical examples of broadcast channels. A television station transmits information to multiple receivers, such as in HDTV, while a classroom lecturer communicates information to students with varying levels of reception. These examples illustrate the real-world applications of the broadcast channel model. [Data: Entities (750, 751), Relationships (883, 884)]"
        },
        {
            "summary": "Random Coding Exponents and Channel Capacity",
            "explanation": "Random coding exponents are used in the proof of the channel capacity theorem, simplifying the demonstration of the theorem's validity. Gallager utilized these exponents to provide a more elegant proof, which has been influential in simplifying complex theoretical concepts in information theory. [Data: Entities (397), Relationships (438)]"
        },
        {
            "summary": "Ryabko's Contribution to Universal Codes",
            "explanation": "Ryabko contributed to the conclusion linking the average redundancy of universal codes to channel capacity. This work, alongside Gallager's contributions, has helped establish the relationship between universal codes and the efficiency of communication systems. [Data: Entities (604), Relationships (708)]"
        }
    ]
}
```.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\services\json.py", line 77, in invoke
    return await this.invoke_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\services\json.py", line 100, in invoke_json
    raise FailedToGenerateValidJsonError from error
fnllm.base.services.errors.FailedToGenerateValidJsonError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\graphrag\index\operations\summarize_communities\community_reports_extractor.py", line 80, in __call__
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\graphrag\language_model\providers\fnllm\models.py", line 81, in achat
    response = await self.model(prompt, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\openai\llm\openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\openai\services\openai_tools_parsing.py", line 130, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\base_llm.py", line 148, in __call__
    await self._events.on_error(
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\graphrag\language_model\providers\fnllm\events.py", line 26, in on_error
    self._on_error(error, traceback, arguments)
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\graphrag\language_model\providers\fnllm\utils.py", line 45, in on_error
    callbacks.error("Error Invoking LLM", error, stack, details)
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\graphrag\callbacks\workflow_callbacks_manager.py", line 64, in error
    callback.error(message, cause, stack, details)
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\graphrag\callbacks\file_workflow_callbacks.py", line 37, in error
    json.dumps(
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\__init__.py", line 238, in dumps
    **kw).encode(obj)
          ^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 202, in encode
    chunks = list(chunks)
             ^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 432, in _iterencode
    yield from _iterencode_dict(o, _current_indent_level)
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 406, in _iterencode_dict
    yield from chunks
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 406, in _iterencode_dict
    yield from chunks
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 406, in _iterencode_dict
    yield from chunks
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 439, in _iterencode
    o = _default(o)
        ^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 180, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
TypeError: Object of type ModelMetaclass is not JSON serializable
16:54:16,352 graphrag.callbacks.file_workflow_callbacks INFO Community Report Extraction Error details=None
16:54:16,352 graphrag.index.operations.summarize_communities.strategies WARNING No report found for community: 52.0
16:54:16,867 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:54:19,532 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:54:21,279 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:54:25,217 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:54:25,469 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:54:28,840 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:54:30,534 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:54:37,500 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:54:41,824 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:54:42,971 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:54:43,583 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:54:44,414 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:54:45,354 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:54:46,146 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:54:47,48 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:54:50,134 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:55:00,715 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:55:02,810 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:55:03,422 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:55:06,76 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:55:06,129 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:55:06,162 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:55:08,644 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:55:14,135 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:55:14,454 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:55:19,804 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:55:24,382 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:55:27,686 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:55:29,178 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:55:29,306 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:55:29,671 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:55:30,871 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:55:30,875 graphrag.index.operations.summarize_communities.community_reports_extractor ERROR error generating community report
Traceback (most recent call last):
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\services\json.py", line 126, in _parse_json_string
    return json.loads(value) if value else None
           ^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\__init__.py", line 346, in loads
    return _default_decoder.decode(s)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\services\json.py", line 96, in invoke_json
    return await self.try_receive_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\services\json.py", line 114, in try_receive_json
    raw_json = self._parse_json_string(json_string)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\services\json.py", line 129, in _parse_json_string
    raise FailedToGenerateValidJsonError(msg) from err
fnllm.base.services.errors.FailedToGenerateValidJsonError: JSON response is not a valid JSON, response=```json
{
    "title": "Communication System and Discrete Memoryless Channel",
    "summary": "The community centers around the COMMUNICATION SYSTEM, which utilizes a DISCRETE MEMORYLESS CHANNEL for message transmission. Key components include the CODEBOOK, ENCODING FUNCTION, and DECODING FUNCTION, all of which are interconnected to ensure efficient and reliable communication.",
    "rating": 7.5,
    "rating_explanation": "The impact severity rating is high due to the critical role of the COMMUNICATION SYSTEM in information exchange and its reliance on advanced technical components.",
    "findings": [
        {
            "summary": "COMMUNICATION SYSTEM as the central entity",
            "explanation": "The COMMUNICATION SYSTEM is the core entity in this community, designed for efficient message transmission. It employs advanced techniques such as data compression and error correction, ensuring the integrity of transmitted information. The system operates through a DISCRETE MEMORYLESS CHANNEL, which is crucial for reliable communication. [Data: Entities (321), Relationships (344, 346, 347, 336)]"
        },
        {
            "summary": "Role of the DISCRETE MEMORYLESS CHANNEL",
            "explanation": "The DISCRETE MEMORYLESS CHANNEL is a fundamental model in information theory, used by the COMMUNICATION SYSTEM to transmit messages. Its key characteristic is that the output depends solely on the current input, ensuring no influence from past interactions. This makes the channel a reliable component for data transmission. [Data: Entities (327), Relationships (344, 348, 1705)]"
        },
        {
            "summary": "Importance of the CODEBOOK",
            "explanation": "The CODEBOOK is a critical component in the COMMUNICATION SYSTEM, containing a collection of codewords generated by the ENCODING FUNCTION. It serves as a shared resource between the sender and receiver, enabling accurate message encoding and decoding. The CODEBOOK ensures that messages are transmitted and interpreted correctly. [Data: Entities (328), Relationships (348, 349)]"
        },
        {
            "summary": "Functionality of the ENCODING FUNCTION",
            "explanation": "The ENCODING FUNCTION generates codewords from messages, which are then transmitted through the COMMUNICATION SYSTEM. This function is essential for converting information into a format suitable for transmission, ensuring that the data can be accurately decoded by the receiver. [Data: Entities (329), Relationships (346, 349)]"
        },
        {
            "summary": "Role of the DECODING FUNCTION",
            "explanation": "The DECODING FUNCTION is used by the receiver to interpret received codewords and retrieve the original messages. This function is crucial for ensuring that the transmitted information is accurately understood by the recipient, completing the communication process. [Data: Entities (330), Relationships (347)]"
        },
        {
            "summary": "CHANNEL as a mathematical construct",
            "explanation": "The CHANNEL is a mathematical model used to represent communication systems, involving inputs, outputs, and transfer probabilities. It is a foundational concept in understanding how data is transmitted and received within the COMMUNICATION SYSTEM. [Data: Entities (387), Relationships (1705, 1702)]"
        },
        {
            "summary": "CAPACITY THEOREM's relevance",
            "explanation": "The CAPACITY THEOREM is related to the capacity of communication channels, providing insights into the maximum rate at which information can be transmitted reliably. This theorem is significant in optimizing the performance of the COMMUNICATION SYSTEM. [Data: Entities (1557), Relationships (1702)]"
        }
    ]
}
```.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\services\json.py", line 77, in invoke
    return await this.invoke_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\services\json.py", line 100, in invoke_json
    raise FailedToGenerateValidJsonError from error
fnllm.base.services.errors.FailedToGenerateValidJsonError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\graphrag\index\operations\summarize_communities\community_reports_extractor.py", line 80, in __call__
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\graphrag\language_model\providers\fnllm\models.py", line 81, in achat
    response = await self.model(prompt, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\openai\llm\openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\openai\services\openai_tools_parsing.py", line 130, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\base_llm.py", line 148, in __call__
    await self._events.on_error(
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\graphrag\language_model\providers\fnllm\events.py", line 26, in on_error
    self._on_error(error, traceback, arguments)
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\graphrag\language_model\providers\fnllm\utils.py", line 45, in on_error
    callbacks.error("Error Invoking LLM", error, stack, details)
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\graphrag\callbacks\workflow_callbacks_manager.py", line 64, in error
    callback.error(message, cause, stack, details)
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\graphrag\callbacks\file_workflow_callbacks.py", line 37, in error
    json.dumps(
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\__init__.py", line 238, in dumps
    **kw).encode(obj)
          ^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 202, in encode
    chunks = list(chunks)
             ^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 432, in _iterencode
    yield from _iterencode_dict(o, _current_indent_level)
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 406, in _iterencode_dict
    yield from chunks
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 406, in _iterencode_dict
    yield from chunks
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 406, in _iterencode_dict
    yield from chunks
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 439, in _iterencode
    o = _default(o)
        ^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 180, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
TypeError: Object of type ModelMetaclass is not JSON serializable
16:55:30,881 graphrag.callbacks.file_workflow_callbacks INFO Community Report Extraction Error details=None
16:55:30,881 graphrag.index.operations.summarize_communities.strategies WARNING No report found for community: 65.0
16:55:32,554 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:55:33,14 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:55:45,762 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:55:47,230 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:55:47,234 graphrag.index.operations.summarize_communities.community_reports_extractor ERROR error generating community report
Traceback (most recent call last):
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\services\json.py", line 126, in _parse_json_string
    return json.loads(value) if value else None
           ^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\__init__.py", line 346, in loads
    return _default_decoder.decode(s)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\services\json.py", line 96, in invoke_json
    return await self.try_receive_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\services\json.py", line 114, in try_receive_json
    raw_json = self._parse_json_string(json_string)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\services\json.py", line 129, in _parse_json_string
    raise FailedToGenerateValidJsonError(msg) from err
fnllm.base.services.errors.FailedToGenerateValidJsonError: JSON response is not a valid JSON, response=```json
{
    "title": "Computer and Random Input Concepts",
    "summary": "The community centers around the concept of random input producing meaningful output, with the computer as the central entity. The computer is linked to the monkey, typewriter, and universal machine, all of which illustrate this concept. Shakespeare's works are used as an example of meaningful output.",
    "rating": 4.5,
    "rating_explanation": "The impact severity rating is moderate due to the theoretical and illustrative nature of the concepts involved.",
    "findings": [
        {
            "summary": "Computer as the central entity",
            "explanation": "The computer is the central entity in this community, serving as the primary device that amplifies intelligence and produces meaningful output from random input. Its relationships with the monkey, universal machine, and typewriter highlight its role in illustrating the concept of random input producing meaningful output. [Data: Entities (634), Relationships (745, 747)]"
        },
        {
            "summary": "Monkey's role in illustrating random input",
            "explanation": "The monkey is a hypothetical entity used to illustrate the concept of random input producing meaningful output. Its relationships with the computer and typewriter emphasize its role in demonstrating this concept. The monkey's theoretical nature suggests that it is primarily used for illustrative purposes rather than practical applications. [Data: Entities (635), Relationships (745, 751)]"
        },
        {
            "summary": "Universal Machine as a theoretical model",
            "explanation": "The universal machine is a theoretical model of a computer that can simulate any other computer. Its relationship with the computer underscores its importance in understanding the capabilities and limitations of computing devices. The universal machine's theoretical nature suggests that it is primarily used for academic and illustrative purposes. [Data: Entities (638), Relationships (747)]"
        },
        {
            "summary": "Typewriter's role in illustrating random input",
            "explanation": "The typewriter is a device used to illustrate the concept of random input producing meaningful output. Its relationships with the monkey and Shakespeare highlight its role in demonstrating this concept. The typewriter's use in this context suggests that it is primarily used for illustrative purposes rather than practical applications. [Data: Entities (637), Relationships (751, 752)]"
        },
        {
            "summary": "Shakespeare's works as meaningful output",
            "explanation": "Shakespeare's works are used as an example of meaningful output in the context of random input. The relationship between Shakespeare and the typewriter emphasizes the role of his works in illustrating the concept of producing meaningful output from random input. Shakespeare's inclusion in this community highlights the importance of meaningful output in understanding the concept of random input. [Data: Entities (636), Relationships (752)]"
        }
    ]
}
```.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\services\json.py", line 77, in invoke
    return await this.invoke_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\services\json.py", line 100, in invoke_json
    raise FailedToGenerateValidJsonError from error
fnllm.base.services.errors.FailedToGenerateValidJsonError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\graphrag\index\operations\summarize_communities\community_reports_extractor.py", line 80, in __call__
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\graphrag\language_model\providers\fnllm\models.py", line 81, in achat
    response = await self.model(prompt, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\openai\llm\openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\openai\services\openai_tools_parsing.py", line 130, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\base_llm.py", line 148, in __call__
    await self._events.on_error(
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\graphrag\language_model\providers\fnllm\events.py", line 26, in on_error
    self._on_error(error, traceback, arguments)
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\graphrag\language_model\providers\fnllm\utils.py", line 45, in on_error
    callbacks.error("Error Invoking LLM", error, stack, details)
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\graphrag\callbacks\workflow_callbacks_manager.py", line 64, in error
    callback.error(message, cause, stack, details)
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\graphrag\callbacks\file_workflow_callbacks.py", line 37, in error
    json.dumps(
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\__init__.py", line 238, in dumps
    **kw).encode(obj)
          ^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 202, in encode
    chunks = list(chunks)
             ^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 432, in _iterencode
    yield from _iterencode_dict(o, _current_indent_level)
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 406, in _iterencode_dict
    yield from chunks
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 406, in _iterencode_dict
    yield from chunks
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 406, in _iterencode_dict
    yield from chunks
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 439, in _iterencode
    o = _default(o)
        ^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 180, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
TypeError: Object of type ModelMetaclass is not JSON serializable
16:55:47,239 graphrag.callbacks.file_workflow_callbacks INFO Community Report Extraction Error details=None
16:55:47,240 graphrag.index.operations.summarize_communities.strategies WARNING No report found for community: 78.0
16:55:47,905 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:55:49,253 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:55:49,747 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:55:53,589 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:55:53,593 graphrag.index.operations.summarize_communities.community_reports_extractor ERROR error generating community report
Traceback (most recent call last):
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\services\json.py", line 126, in _parse_json_string
    return json.loads(value) if value else None
           ^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\__init__.py", line 346, in loads
    return _default_decoder.decode(s)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\services\json.py", line 96, in invoke_json
    return await self.try_receive_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\services\json.py", line 114, in try_receive_json
    raw_json = self._parse_json_string(json_string)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\services\json.py", line 129, in _parse_json_string
    raise FailedToGenerateValidJsonError(msg) from err
fnllm.base.services.errors.FailedToGenerateValidJsonError: JSON response is not a valid JSON, response=```json
{
    "title": "Kelly, Breiman, and Sharpe: Pioneers in Financial Mathematics",
    "summary": "This community centers around key figures in financial mathematics and investment theory, including Kelly, Breiman, and Sharpe. These individuals have made foundational contributions to log-optimal portfolios, mean-variance analysis, and information theory. Their interconnected work has shaped modern portfolio optimization and investment strategies, with collaborations and theoretical advancements linking their contributions.",
    "rating": 8.5,
    "rating_explanation": "The impact severity rating is high due to the foundational and enduring influence of their work on financial mathematics and investment theory.",
    "findings": [
        {
            "summary": "Kelly's foundational contributions to log-optimal portfolios",
            "explanation": "Kelly introduced the concept of log-optimal portfolios, which is a cornerstone of portfolio optimization and investment strategies. Her work also extended to gambling theory, where she discovered the relationship W=I, linking wealth growth to information. This dual contribution has had a lasting impact on both financial mathematics and gambling systems. [Data: Entities (315), Relationships (328, 1088)]"
        },
        {
            "summary": "Breiman's role in extending log-optimal portfolios and information theory",
            "explanation": "Breiman extended the concept of log-optimal portfolios and rigorously verified the asymptotic optimality of stochastic market processes. Additionally, he contributed to the proof of the Shannon-McMillan-Breiman theorem, a fundamental result in information theory. His work bridges theoretical insights with practical applications in mathematical finance. [Data: Entities (163), Relationships (167)]"
        },
        {
            "summary": "Sharpe's development of the Sharpe-Markowitz theory",
            "explanation": "Sharpe is renowned for developing the Sharpe-Markowitz theory, a foundational concept in mean-variance analysis and portfolio optimization. His work has profoundly influenced the study and practice of financial economics, particularly in stock market investment. Sharpe's contributions are essential to understanding modern investment strategies. [Data: Entities (894), Relationships (1085)]"
        },
        {
            "summary": "Collaboration between Latan and Tuttle on log-optimal portfolios",
            "explanation": "Latan and Tuttle collaborated on the development of the concept of log-optimal portfolios, emphasizing strategies that maximize logarithmic utility or growth over time. Their joint work has established them as key figures in the study of optimal investment strategies, bridging finance and information theory. [Data: Entities (317, 318), Relationships (329)]"
        },
        {
            "summary": "Samuelson's critical insights into log-optimal investment",
            "explanation": "Samuelson provided critical insights into the theory of log-optimal investment, building on Kelly's foundational work. His contributions have further enriched the theoretical framework of portfolio optimization, highlighting the interdisciplinary nature of financial mathematics. [Data: Entities (895), Relationships (1088)]"
        }
    ]
}
```.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\services\json.py", line 77, in invoke
    return await this.invoke_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\services\json.py", line 100, in invoke_json
    raise FailedToGenerateValidJsonError from error
fnllm.base.services.errors.FailedToGenerateValidJsonError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\graphrag\index\operations\summarize_communities\community_reports_extractor.py", line 80, in __call__
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\graphrag\language_model\providers\fnllm\models.py", line 81, in achat
    response = await self.model(prompt, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\openai\llm\openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\openai\services\openai_tools_parsing.py", line 130, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\base_llm.py", line 148, in __call__
    await self._events.on_error(
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\graphrag\language_model\providers\fnllm\events.py", line 26, in on_error
    self._on_error(error, traceback, arguments)
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\graphrag\language_model\providers\fnllm\utils.py", line 45, in on_error
    callbacks.error("Error Invoking LLM", error, stack, details)
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\graphrag\callbacks\workflow_callbacks_manager.py", line 64, in error
    callback.error(message, cause, stack, details)
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\graphrag\callbacks\file_workflow_callbacks.py", line 37, in error
    json.dumps(
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\__init__.py", line 238, in dumps
    **kw).encode(obj)
          ^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 202, in encode
    chunks = list(chunks)
             ^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 432, in _iterencode
    yield from _iterencode_dict(o, _current_indent_level)
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 406, in _iterencode_dict
    yield from chunks
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 406, in _iterencode_dict
    yield from chunks
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 406, in _iterencode_dict
    yield from chunks
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 439, in _iterencode
    o = _default(o)
        ^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 180, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
TypeError: Object of type ModelMetaclass is not JSON serializable
16:55:53,599 graphrag.callbacks.file_workflow_callbacks INFO Community Report Extraction Error details=None
16:55:53,599 graphrag.index.operations.summarize_communities.strategies WARNING No report found for community: 74.0
16:55:57,582 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:55:59,198 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:56:01,243 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:56:02,401 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:56:09,380 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:56:09,384 graphrag.index.operations.summarize_communities.community_reports_extractor ERROR error generating community report
Traceback (most recent call last):
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\services\json.py", line 126, in _parse_json_string
    return json.loads(value) if value else None
           ^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\__init__.py", line 346, in loads
    return _default_decoder.decode(s)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\services\json.py", line 96, in invoke_json
    return await self.try_receive_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\services\json.py", line 114, in try_receive_json
    raw_json = self._parse_json_string(json_string)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\services\json.py", line 129, in _parse_json_string
    raise FailedToGenerateValidJsonError(msg) from err
fnllm.base.services.errors.FailedToGenerateValidJsonError: JSON response is not a valid JSON, response=```json
{
    "title": "Investors and Logarithmic Optimal Portfolio",
    "summary": "The community centers around investors who utilize the logarithmic optimal portfolio strategy in the stock market. Key entities include the logarithmic optimal portfolio, log optimal investment strategy, and stock vector sequence, all interconnected through their roles in investment analysis and strategy comparison.",
    "rating": 6.5,
    "rating_explanation": "The impact severity rating is moderately high due to the financial implications and strategic importance of the logarithmic optimal portfolio in investment decisions.",
    "findings": [
        {
            "summary": "Investors as central entities",
            "explanation": "Investors are the primary entities in this community, engaging in the stock market to achieve financial gains using various strategies, including the logarithmic optimal portfolio. Their role is crucial in driving the dynamics of the community, as they are directly involved in investment activities and strategy implementation. [Data: Entities (850), Relationships (1025, 1780)]"
        },
        {
            "summary": "Logarithmic optimal portfolio as a key strategy",
            "explanation": "The logarithmic optimal portfolio is a significant strategy used by investors to maximize their returns in the stock market. This strategy is central to the community's focus on investment optimization and is linked to other entities such as the stock vector sequence and log optimal investment strategy. [Data: Entities (849), Relationships (1026, 1027)]"
        },
        {
            "summary": "Log optimal investment strategy and Kuhn-Tucker conditions",
            "explanation": "The log optimal investment strategy is validated using the Kuhn-Tucker conditions to ensure optimal portfolio allocation. This relationship highlights the mathematical rigor behind the strategy and its importance in achieving optimal investment outcomes. [Data: Entities (863), Relationships (1045)]"
        },
        {
            "summary": "Stock vector sequence in portfolio analysis",
            "explanation": "The stock vector sequence is used to analyze the performance of the logarithmic optimal portfolio. This entity plays a critical role in understanding the effectiveness of the portfolio strategy over time, providing valuable insights for investors. [Data: Entities (851), Relationships (1027)]"
        },
        {
            "summary": "Relative returns for strategy comparison",
            "explanation": "Relative returns are used to compare the logarithmic optimal portfolio with alternative strategies, such as the causal investment portfolio. This comparison is essential for evaluating the effectiveness of different investment approaches and making informed financial decisions. [Data: Entities (852, 853), Relationships (1029)]"
        }
    ]
}
```.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\services\json.py", line 77, in invoke
    return await this.invoke_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\services\json.py", line 100, in invoke_json
    raise FailedToGenerateValidJsonError from error
fnllm.base.services.errors.FailedToGenerateValidJsonError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\graphrag\index\operations\summarize_communities\community_reports_extractor.py", line 80, in __call__
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\graphrag\language_model\providers\fnllm\models.py", line 81, in achat
    response = await self.model(prompt, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\openai\llm\openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\openai\services\openai_tools_parsing.py", line 130, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\base_llm.py", line 148, in __call__
    await self._events.on_error(
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\graphrag\language_model\providers\fnllm\events.py", line 26, in on_error
    self._on_error(error, traceback, arguments)
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\graphrag\language_model\providers\fnllm\utils.py", line 45, in on_error
    callbacks.error("Error Invoking LLM", error, stack, details)
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\graphrag\callbacks\workflow_callbacks_manager.py", line 64, in error
    callback.error(message, cause, stack, details)
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\graphrag\callbacks\file_workflow_callbacks.py", line 37, in error
    json.dumps(
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\__init__.py", line 238, in dumps
    **kw).encode(obj)
          ^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 202, in encode
    chunks = list(chunks)
             ^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 432, in _iterencode
    yield from _iterencode_dict(o, _current_indent_level)
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 406, in _iterencode_dict
    yield from chunks
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 406, in _iterencode_dict
    yield from chunks
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 406, in _iterencode_dict
    yield from chunks
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 439, in _iterencode
    o = _default(o)
        ^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 180, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
TypeError: Object of type ModelMetaclass is not JSON serializable
16:56:09,391 graphrag.callbacks.file_workflow_callbacks INFO Community Report Extraction Error details=None
16:56:09,391 graphrag.index.operations.summarize_communities.strategies WARNING No report found for community: 80.0
16:56:11,686 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:56:12,30 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:56:14,635 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:56:22,877 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:56:23,405 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:56:23,443 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:56:24,922 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:56:28,280 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:56:30,514 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:56:34,701 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:56:34,777 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:56:38,915 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:56:44,68 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:56:44,669 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:56:50,666 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:56:52,409 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:56:53,658 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:56:58,563 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:56:59,188 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:57:01,389 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:57:02,948 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:57:05,378 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:57:09,616 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:57:12,4 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:57:12,217 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:57:20,606 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:57:23,182 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:57:23,687 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:57:25,489 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:57:29,492 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:57:30,764 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:57:31,409 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:57:34,651 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:57:35,87 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:57:43,448 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:57:44,891 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:57:46,62 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:57:46,306 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:57:49,952 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:57:57,13 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:57:57,497 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:57:58,965 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:58:00,18 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:58:00,440 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:58:04,355 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:58:07,783 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:58:09,929 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:58:13,382 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:58:14,854 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:58:21,493 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:58:22,969 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:58:22,972 graphrag.index.operations.summarize_communities.community_reports_extractor ERROR error generating community report
Traceback (most recent call last):
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\services\json.py", line 126, in _parse_json_string
    return json.loads(value) if value else None
           ^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\__init__.py", line 346, in loads
    return _default_decoder.decode(s)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\services\json.py", line 96, in invoke_json
    return await self.try_receive_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\services\json.py", line 114, in try_receive_json
    raw_json = self._parse_json_string(json_string)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\services\json.py", line 129, in _parse_json_string
    raise FailedToGenerateValidJsonError(msg) from err
fnllm.base.services.errors.FailedToGenerateValidJsonError: JSON response is not a valid JSON, response=```json
{
    "title": "Mathematical and Information Theory Community",
    "summary": "This community revolves around key entities in mathematical and information theory, including D, C, R(D), and V. These entities are interconnected through relationships that highlight their roles in mathematical proofs, coding applications, and rate-distortion theory. The community also includes foundational theoretical problems like the Slepian-Wolf problem and multi-terminal networks, which are crucial in distributed source coding and communication systems.",
    "rating": 7.5,
    "rating_explanation": "The impact severity rating is high due to the community's foundational role in theoretical and applied information theory, which underpins critical technologies like data compression and communication systems.",
    "findings": [
        {
            "summary": "D's dual role in mathematics and coding",
            "explanation": "D is a versatile entity that plays a significant role in both mathematical proofs and coding applications. It operates within a specific value range and represents destination strings in code definitions, highlighting its importance in both theoretical and practical contexts. [Data: Entities (213), Relationships (220)]"
        },
        {
            "summary": "C's central role in code definitions",
            "explanation": "C is a key entity in the community, serving as the basis for code definitions and extensions. Its relationship with D underscores its importance in defining destination strings, while its extension C* further maps finite-length strings, demonstrating its foundational role in coding theory. [Data: Entities (214), Relationships (220, 218)]"
        },
        {
            "summary": "R(D) and its significance in rate-distortion theory",
            "explanation": "R(D) is the rate-distortion function of source V, a critical concept in rate-distortion theory. It quantifies the minimum rate required to achieve a specific distortion, making it essential for understanding data compression and communication systems. [Data: Entities (502), Relationships (569, 568)]"
        },
        {
            "summary": "V's involvement in mathematical and financial contexts",
            "explanation": "V is a multifaceted entity involved in both mathematical proofs and financial operations. Its role in the cumulative sum of assets during company mergers, alongside its mathematical functions, highlights its versatility across different domains. [Data: Entities (248), Relationships (568)]"
        },
        {
            "summary": "The Slepian-Wolf problem's foundational role",
            "explanation": "The Slepian-Wolf problem is a cornerstone of information theory, addressing distributed source coding for correlated sources. Its relationship with multi-terminal networks underscores its importance in applications like sensor networks and distributed data compression. [Data: Entities (780), Relationships (936)]"
        },
        {
            "summary": "Multi-terminal networks and their general framework",
            "explanation": "Multi-terminal networks involve multiple transmitters and receivers, with information transfer rates and channel transfer functions. Their relationship with the Slepian-Wolf problem highlights their broader context in communication systems. [Data: Entities (788), Relationships (936)]"
        },
        {
            "summary": "R's role in rate distortion theory",
            "explanation": "R represents the rate in rate distortion theory, a fundamental concept in data compression and communication systems. Its relationship with D underscores its importance in achieving specific distortions in information transmission. [Data: Entities (468), Relationships (933)]"
        }
    ]
}
```.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\services\json.py", line 77, in invoke
    return await this.invoke_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\services\json.py", line 100, in invoke_json
    raise FailedToGenerateValidJsonError from error
fnllm.base.services.errors.FailedToGenerateValidJsonError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\graphrag\index\operations\summarize_communities\community_reports_extractor.py", line 80, in __call__
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\graphrag\language_model\providers\fnllm\models.py", line 81, in achat
    response = await self.model(prompt, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\openai\llm\openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\openai\services\openai_tools_parsing.py", line 130, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\base_llm.py", line 148, in __call__
    await self._events.on_error(
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\graphrag\language_model\providers\fnllm\events.py", line 26, in on_error
    self._on_error(error, traceback, arguments)
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\graphrag\language_model\providers\fnllm\utils.py", line 45, in on_error
    callbacks.error("Error Invoking LLM", error, stack, details)
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\graphrag\callbacks\workflow_callbacks_manager.py", line 64, in error
    callback.error(message, cause, stack, details)
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\graphrag\callbacks\file_workflow_callbacks.py", line 37, in error
    json.dumps(
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\__init__.py", line 238, in dumps
    **kw).encode(obj)
          ^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 202, in encode
    chunks = list(chunks)
             ^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 432, in _iterencode
    yield from _iterencode_dict(o, _current_indent_level)
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 406, in _iterencode_dict
    yield from chunks
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 406, in _iterencode_dict
    yield from chunks
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 406, in _iterencode_dict
    yield from chunks
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 439, in _iterencode
    o = _default(o)
        ^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 180, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
TypeError: Object of type ModelMetaclass is not JSON serializable
16:58:22,978 graphrag.callbacks.file_workflow_callbacks INFO Community Report Extraction Error details=None
16:58:22,979 graphrag.index.operations.summarize_communities.strategies WARNING No report found for community: 98.0
16:58:23,410 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:58:24,241 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:58:28,946 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:58:29,797 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:58:32,599 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:58:36,158 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:58:39,166 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:58:41,244 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:58:43,470 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:58:43,474 graphrag.index.operations.summarize_communities.community_reports_extractor ERROR error generating community report
Traceback (most recent call last):
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\services\json.py", line 126, in _parse_json_string
    return json.loads(value) if value else None
           ^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\__init__.py", line 346, in loads
    return _default_decoder.decode(s)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\services\json.py", line 96, in invoke_json
    return await self.try_receive_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\services\json.py", line 114, in try_receive_json
    raw_json = self._parse_json_string(json_string)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\services\json.py", line 129, in _parse_json_string
    raise FailedToGenerateValidJsonError(msg) from err
fnllm.base.services.errors.FailedToGenerateValidJsonError: JSON response is not a valid JSON, response=```json
{
    "title": "Network Information Theory and Related Concepts",
    "summary": "The community centers around Network Information Theory, a field that extends traditional information theory to scenarios with multiple transmitters and receivers. Key entities include Slepian-Wolf Source Coding, Distributed Source Coding, the Ford-Fulkerson Theorem, and Channel Coding, all of which are interconnected through their contributions to understanding and optimizing communication systems. The relationships between these entities highlight their foundational roles in advancing the field of network information theory.",
    "rating": 7.5,
    "rating_explanation": "The impact severity rating is high due to the foundational importance of these concepts in advancing communication systems and network optimization.",
    "findings": [
        {
            "summary": "Network Information Theory as the central field",
            "explanation": "Network Information Theory is the central entity in this community, extending traditional information theory to scenarios involving multiple transmitters and receivers. This field is crucial for understanding and optimizing communication systems, particularly in noisy and interference-prone environments. Its relationships with other key concepts like Slepian-Wolf Source Coding and Distributed Source Coding underscore its foundational role in the community. [Data: Entities (70), Relationships (57, 818, 819)]"
        },
        {
            "summary": "Slepian-Wolf Source Coding's role in distributed communication",
            "explanation": "Slepian-Wolf Source Coding is a method of distributed source coding where two sources are encoded separately but decoded together at a common node. This concept is essential for understanding how multiple correlated sources can be efficiently encoded and decoded without direct communication, making it a key component of Network Information Theory. Its relationship with Gaussian channels further highlights its importance in the study of network communication. [Data: Entities (694), Relationships (814)]"
        },
        {
            "summary": "Distributed Source Coding's efficiency in encoding correlated sources",
            "explanation": "Distributed Source Coding (DSC) is a technique that allows for the independent encoding of multiple correlated sources while enabling joint decoding. This method is particularly valuable in scenarios where direct communication between sources is impractical or costly. DSC's relationship with Network Information Theory underscores its role in advancing the efficiency and reliability of communication systems. [Data: Entities (695), Relationships (818)]"
        },
        {
            "summary": "Ford-Fulkerson Theorem's application in network flow optimization",
            "explanation": "The Ford-Fulkerson Theorem is a fundamental mathematical theorem used to calculate the maximum flow of information or resources that can be transmitted through a network. This theorem is widely applied in optimization and network analysis, providing a theoretical foundation for solving complex flow-related challenges. Its relationships with Slepian-Wolf Source Coding and Network Information Theory highlight its importance in the broader context of network communication. [Data: Entities (693), Relationships (812, 1768, 1769)]"
        },
        {
            "summary": "Channel Coding's role in reliable communication",
            "explanation": "Channel Coding focuses on encoding information for transmission over noisy channels to ensure reliable communication. This concept is a fundamental aspect of Network Information Theory, as it directly addresses the challenges posed by noise and interference in communication systems. Its relationship with Network Information Theory underscores its critical role in advancing the reliability of modern communication networks. [Data: Entities (696), Relationships (819)]"
        },
        {
            "summary": "Contributions of L. R. Ford and D. R. Fulkerson",
            "explanation": "L. R. Ford and D. R. Fulkerson are key individuals associated with the Ford-Fulkerson Theorem, a foundational concept in network flow optimization. Their contributions to this theorem have had a significant impact on the field of network information theory, particularly in solving complex flow-related challenges. Their relationships with the Ford-Fulkerson Theorem highlight their importance in the community. [Data: Entities (1648, 1654), Relationships (1768, 1769)]"
        }
    ]
}
```.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\services\json.py", line 77, in invoke
    return await this.invoke_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\services\json.py", line 100, in invoke_json
    raise FailedToGenerateValidJsonError from error
fnllm.base.services.errors.FailedToGenerateValidJsonError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\graphrag\index\operations\summarize_communities\community_reports_extractor.py", line 80, in __call__
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\graphrag\language_model\providers\fnllm\models.py", line 81, in achat
    response = await self.model(prompt, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\openai\llm\openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\openai\services\openai_tools_parsing.py", line 130, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\base_llm.py", line 148, in __call__
    await self._events.on_error(
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\graphrag\language_model\providers\fnllm\events.py", line 26, in on_error
    self._on_error(error, traceback, arguments)
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\graphrag\language_model\providers\fnllm\utils.py", line 45, in on_error
    callbacks.error("Error Invoking LLM", error, stack, details)
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\graphrag\callbacks\workflow_callbacks_manager.py", line 64, in error
    callback.error(message, cause, stack, details)
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\graphrag\callbacks\file_workflow_callbacks.py", line 37, in error
    json.dumps(
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\__init__.py", line 238, in dumps
    **kw).encode(obj)
          ^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 202, in encode
    chunks = list(chunks)
             ^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 432, in _iterencode
    yield from _iterencode_dict(o, _current_indent_level)
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 406, in _iterencode_dict
    yield from chunks
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 406, in _iterencode_dict
    yield from chunks
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 406, in _iterencode_dict
    yield from chunks
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 439, in _iterencode
    o = _default(o)
        ^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 180, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
TypeError: Object of type ModelMetaclass is not JSON serializable
16:58:43,479 graphrag.callbacks.file_workflow_callbacks INFO Community Report Extraction Error details=None
16:58:43,480 graphrag.index.operations.summarize_communities.strategies WARNING No report found for community: 103.0
16:58:47,675 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:58:48,79 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:58:49,734 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:58:51,556 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:58:58,471 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:58:59,284 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:59:01,713 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:59:02,884 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:59:06,830 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:59:09,393 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:59:11,19 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:59:11,303 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:59:14,774 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:59:17,312 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:59:20,812 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:59:20,836 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:59:26,160 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:59:26,166 graphrag.index.operations.summarize_communities.community_reports_extractor ERROR error generating community report
Traceback (most recent call last):
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\services\json.py", line 126, in _parse_json_string
    return json.loads(value) if value else None
           ^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\__init__.py", line 346, in loads
    return _default_decoder.decode(s)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\services\json.py", line 96, in invoke_json
    return await self.try_receive_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\services\json.py", line 114, in try_receive_json
    raw_json = self._parse_json_string(json_string)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\services\json.py", line 129, in _parse_json_string
    raise FailedToGenerateValidJsonError(msg) from err
fnllm.base.services.errors.FailedToGenerateValidJsonError: JSON response is not a valid JSON, response=```json
{
    "title": "AEP and Information Theory Community",
    "summary": "The community centers around the Asymptotic Equipartition Property (AEP), which serves as the foundation for key theorems in information theory, including the Data Compression Theorem and the Data Transmission Theorem. These entities are interconnected through mathematical concepts such as joint typicality and distortion typical sets, forming a cohesive framework for understanding data compression and transmission.",
    "rating": 8.5,
    "rating_explanation": "The impact severity rating is high due to the foundational role of AEP and its derived theorems in advancing information theory and practical data communication systems.",
    "findings": [
        {
            "summary": "AEP as the foundational concept",
            "explanation": "The Asymptotic Equipartition Property (AEP) is the cornerstone of this community, providing the basis for both the Data Compression Theorem and the Data Transmission Theorem. AEP's role in defining typical sequences is critical for understanding efficient data compression and reliable data transmission. Its high degree of connectivity within the community underscores its importance [Data: Entities (156), Relationships (401, 403)]."
        },
        {
            "summary": "Data Compression Theorem's role",
            "explanation": "The Data Compression Theorem, derived from AEP, highlights the efficiency of compressing data by focusing on a small subset of source sequences that contain most of the probability. This theorem is fundamental to reducing data size while minimizing error, making it a key component of modern data storage and transmission systems [Data: Entities (376), Relationships (401, 403)]."
        },
        {
            "summary": "Data Transmission Theorem's significance",
            "explanation": "The Data Transmission Theorem, based on joint AEP, ensures reliable communication by leveraging the concept of joint typicality between input and output sequences. This theorem is essential for designing robust communication systems that minimize errors during data transmission [Data: Entities (377), Relationships (404, 403)]."
        },
        {
            "summary": "Role of joint typicality",
            "explanation": "Joint typicality is a critical concept in the Data Transmission Theorem, ensuring that input and output sequences are jointly typical for reliable communication. This concept bridges the gap between theoretical principles and practical applications in information theory [Data: Relationships (404)]."
        },
        {
            "summary": "Distortion typical set and its relevance",
            "explanation": "The distortion typical set, represented by $A_{d,\\varepsilon}^{(n)}$, is a collection of sequences that are typical under a given distortion measure and probability distribution. This set is crucial for understanding the expected distortion in data compression and transmission systems [Data: Entities (479), Relationships (545, 546)]."
        },
        {
            "summary": "Expected distortion in data systems",
            "explanation": "The expected distortion, $E d(X,\\hat{X})$, is a key metric used to define the distortion typical set and evaluate the performance of data compression and transmission systems. It provides a quantitative measure of the quality of data reconstruction [Data: Entities (486), Relationships (546)]."
        },
        {
            "summary": "Event space for joint probability distribution",
            "explanation": "The event space $\\boldsymbol{\\chi}\\times\\boldsymbol{\\hat{\\chi}}$ is defined for the joint probability distribution and distortion measure, providing a mathematical framework for analyzing data compression and transmission. This space is essential for understanding the theoretical underpinnings of the community [Data: Entities (478), Relationships (545)]."
        }
    ]
}
```.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\services\json.py", line 77, in invoke
    return await this.invoke_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\services\json.py", line 100, in invoke_json
    raise FailedToGenerateValidJsonError from error
fnllm.base.services.errors.FailedToGenerateValidJsonError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\graphrag\index\operations\summarize_communities\community_reports_extractor.py", line 80, in __call__
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\graphrag\language_model\providers\fnllm\models.py", line 81, in achat
    response = await self.model(prompt, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\openai\llm\openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\openai\services\openai_tools_parsing.py", line 130, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\base_llm.py", line 148, in __call__
    await self._events.on_error(
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\graphrag\language_model\providers\fnllm\events.py", line 26, in on_error
    self._on_error(error, traceback, arguments)
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\graphrag\language_model\providers\fnllm\utils.py", line 45, in on_error
    callbacks.error("Error Invoking LLM", error, stack, details)
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\graphrag\callbacks\workflow_callbacks_manager.py", line 64, in error
    callback.error(message, cause, stack, details)
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\graphrag\callbacks\file_workflow_callbacks.py", line 37, in error
    json.dumps(
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\__init__.py", line 238, in dumps
    **kw).encode(obj)
          ^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 202, in encode
    chunks = list(chunks)
             ^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 432, in _iterencode
    yield from _iterencode_dict(o, _current_indent_level)
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 406, in _iterencode_dict
    yield from chunks
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 406, in _iterencode_dict
    yield from chunks
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 406, in _iterencode_dict
    yield from chunks
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 439, in _iterencode
    o = _default(o)
        ^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 180, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
TypeError: Object of type ModelMetaclass is not JSON serializable
16:59:26,171 graphrag.callbacks.file_workflow_callbacks INFO Community Report Extraction Error details=None
16:59:26,171 graphrag.index.operations.summarize_communities.strategies WARNING No report found for community: 111.0
16:59:27,984 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:59:28,979 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:59:29,738 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:59:30,950 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:59:38,331 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:59:38,494 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:59:42,608 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:59:46,495 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
16:59:50,9 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
17:00:15,685 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
17:00:15,690 graphrag.index.operations.summarize_communities.community_reports_extractor ERROR error generating community report
Traceback (most recent call last):
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\services\json.py", line 126, in _parse_json_string
    return json.loads(value) if value else None
           ^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\__init__.py", line 346, in loads
    return _default_decoder.decode(s)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\services\json.py", line 96, in invoke_json
    return await self.try_receive_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\services\json.py", line 114, in try_receive_json
    raw_json = self._parse_json_string(json_string)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\services\json.py", line 129, in _parse_json_string
    raise FailedToGenerateValidJsonError(msg) from err
fnllm.base.services.errors.FailedToGenerateValidJsonError: JSON response is not a valid JSON, response=```json
{
    "title": "CSISZ\xc1R and Information Theory Researchers",
    "summary": "The community centers around CSISZ\xc1R, a prominent researcher in network information theory, and their collaborations with other key figures such as K\xd6RMER, AMARI, and KONER. These researchers have collectively advanced foundational techniques like the Method of Types and iterative algorithms for computing channel capacity, significantly impacting the field of information theory.",
    "rating": 8.5,
    "rating_explanation": "The impact severity rating is high due to the foundational contributions of these researchers to information theory, which have wide-ranging theoretical and practical applications.",
    "findings": [
        {
            "summary": "CSISZ\xc1R's foundational contributions to information theory",
            "explanation": "CSISZ\xc1R has made significant contributions to network information theory, including the development of the Method of Types and an iterative algorithm for calculating the rate-distortion function. These advancements have established many important theorems and are widely referenced in the field. [Data: Entities (140), Relationships (576, 949)]"
        },
        {
            "summary": "Collaboration between CSISZ\xc1R and K\xd6RMER",
            "explanation": "CSISZ\xc1R and K\xd6RMER collaborated to develop the Method of Types, a fundamental technique in information theory and statistics. This method is crucial for analyzing sequences of random variables and deriving strong error bounds for channel coding theorems. [Data: Entities (836, 140), Relationships (576)]"
        },
        {
            "summary": "AMARI's discussions on relative entropy",
            "explanation": "AMARI provided detailed discussions on relative entropy, exploring its various names and implications. This work complements CSISZ\xc1R's contributions and has furthered the understanding of relative entropy in information theory. [Data: Entities (141), Relationships (148)]"
        },
        {
            "summary": "KONER's role in developing the Method of Types",
            "explanation": "KONER, alongside CSISZ\xc1R, developed the Method of Types, which has led to many important theorems in information theory. This technique is a cornerstone in the analysis of information-theoretic problems. [Data: Entities (555), Relationships (646)]"
        },
        {
            "summary": "ARIMOTO and BLAHUT's iterative algorithms",
            "explanation": "ARIMOTO and BLAHUT independently developed iterative algorithms for computing channel capacity, a fundamental concept in information theory. These algorithms have become foundational tools in the field. [Data: Entities (395, 396), Relationships (441, 442, 443)]"
        },
        {
            "summary": "KEMPERMAN's contributions to relative entropy",
            "explanation": "KEMPERMAN contributed to the lower bound of relative entropy, further advancing the theoretical understanding of this concept in information theory. [Data: Entities (556), Relationships (648)]"
        },
        {
            "summary": "K\xd6RNER's proposal of a non-ordinary multiple-access channel",
            "explanation": "K\xd6RNER, along with CSISZ\xc1R, independently proposed a non-ordinary multiple-access channel, contributing to the diversity of research in information theory. [Data: Entities (797), Relationships (949)]"
        }
    ]
}
```.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\services\json.py", line 77, in invoke
    return await this.invoke_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\services\json.py", line 100, in invoke_json
    raise FailedToGenerateValidJsonError from error
fnllm.base.services.errors.FailedToGenerateValidJsonError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\graphrag\index\operations\summarize_communities\community_reports_extractor.py", line 80, in __call__
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\graphrag\language_model\providers\fnllm\models.py", line 81, in achat
    response = await self.model(prompt, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\openai\llm\openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\openai\services\openai_tools_parsing.py", line 130, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\base_llm.py", line 148, in __call__
    await self._events.on_error(
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\graphrag\language_model\providers\fnllm\events.py", line 26, in on_error
    self._on_error(error, traceback, arguments)
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\graphrag\language_model\providers\fnllm\utils.py", line 45, in on_error
    callbacks.error("Error Invoking LLM", error, stack, details)
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\graphrag\callbacks\workflow_callbacks_manager.py", line 64, in error
    callback.error(message, cause, stack, details)
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\graphrag\callbacks\file_workflow_callbacks.py", line 37, in error
    json.dumps(
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\__init__.py", line 238, in dumps
    **kw).encode(obj)
          ^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 202, in encode
    chunks = list(chunks)
             ^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 432, in _iterencode
    yield from _iterencode_dict(o, _current_indent_level)
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 406, in _iterencode_dict
    yield from chunks
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 406, in _iterencode_dict
    yield from chunks
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 406, in _iterencode_dict
    yield from chunks
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 439, in _iterencode
    o = _default(o)
        ^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 180, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
TypeError: Object of type ModelMetaclass is not JSON serializable
17:00:15,695 graphrag.callbacks.file_workflow_callbacks INFO Community Report Extraction Error details=None
17:00:15,695 graphrag.index.operations.summarize_communities.strategies WARNING No report found for community: 115.0
17:00:43,475 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
17:00:44,532 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
17:00:45,32 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
17:00:49,165 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
17:00:49,630 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
17:00:50,603 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
17:00:51,876 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
17:00:51,960 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
17:00:52,298 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
17:00:52,577 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
17:01:10,825 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
17:01:17,452 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
17:01:18,698 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
17:01:21,384 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
17:01:24,769 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
17:01:24,953 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
17:01:25,614 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
17:01:26,856 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
17:01:30,725 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
17:01:32,872 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
17:01:33,919 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
17:01:49,359 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
17:01:52,209 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
17:01:54,994 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
17:01:55,715 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
17:01:57,779 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
17:01:58,531 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
17:01:59,688 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
17:02:03,315 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
17:02:05,52 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
17:02:12,359 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
17:02:22,329 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
17:02:24,852 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
17:02:25,295 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
17:02:27,564 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
17:02:28,35 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
17:02:28,39 graphrag.index.operations.summarize_communities.community_reports_extractor ERROR error generating community report
Traceback (most recent call last):
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\services\json.py", line 126, in _parse_json_string
    return json.loads(value) if value else None
           ^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\__init__.py", line 346, in loads
    return _default_decoder.decode(s)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\services\json.py", line 96, in invoke_json
    return await self.try_receive_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\services\json.py", line 114, in try_receive_json
    raw_json = self._parse_json_string(json_string)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\services\json.py", line 129, in _parse_json_string
    raise FailedToGenerateValidJsonError(msg) from err
fnllm.base.services.errors.FailedToGenerateValidJsonError: JSON response is not a valid JSON, response=```json
{
    "title": "Turbo Codes and Information Theory Community",
    "summary": "The community centers around Turbo Codes, a pivotal development in information theory, and their relationships with key concepts such as Iterative Decoding, Rate Distortion Function, and LDPC Codes. These entities are interconnected through their contributions to coding theory, error correction, and data transmission efficiency, making them foundational to modern communication technologies.",
    "rating": 8.5,
    "rating_explanation": "The impact severity rating is high due to the widespread application of Turbo Codes and related concepts in critical communication systems.",
    "findings": [
        {
            "summary": "Turbo Codes as a cornerstone of modern communication",
            "explanation": "Turbo Codes are a class of error-correcting codes that have revolutionized information theory by achieving near-Shannon-limit performance. Their iterative decoding techniques make them computationally practical and highly effective in noisy communication channels. Turbo Codes are widely used in wireless and satellite communications, enhancing the reliability of data transmission. [Data: Entities (65), Relationships (48, 393, 394)]"
        },
        {
            "summary": "Iterative Decoding's role in Turbo Codes",
            "explanation": "Iterative Decoding is a fundamental process in Turbo Codes, where multiple decoders exchange and refine their estimates of bit values until consensus is reached. This method significantly improves decoding accuracy and is a key factor in the success of Turbo Codes. [Data: Entities (369), Relationships (393)]"
        },
        {
            "summary": "Rate Distortion Function's theoretical significance",
            "explanation": "The Rate Distortion Function is a critical concept in information theory, quantifying the trade-offs between data compression and fidelity. It provides a theoretical framework for optimizing information transmission under constraints, making it essential for understanding communication systems. [Data: Entities (21), Relationships (527, 528, 564)]"
        },
        {
            "summary": "LDPC Codes and their relationship to Turbo Codes",
            "explanation": "LDPC Codes, introduced by Robert Gallager, are another class of error-correcting codes widely used in communication systems. They share similarities with Turbo Codes, particularly in their use of iterative message-passing algorithms. Both codes are foundational to modern communication technologies. [Data: Entities (366), Relationships (389, 390, 391, 395)]"
        },
        {
            "summary": "Berrou's contribution to Turbo Codes",
            "explanation": "Berrou proposed the concept of Turbo Codes in 1993, combining two interleaved convolutional codes with a parallel cooperative decoder. This innovation has had a profound impact on the field of coding theory and communication systems. [Data: Entities (362), Relationships (388)]"
        },
        {
            "summary": "Convex and concave functions in information theory",
            "explanation": "Convex and concave functions, such as X\xb2, E^X, and LOG X, play a significant role in information theory, particularly in the context of Jensen's Inequality. These functions are essential for understanding the behavior of random variables and their expectations. [Data: Entities (103, 104, 106, 107), Relationships (100, 101, 102, 103, 106, 107)]"
        },
        {
            "summary": "Joint Source Channel Coding Theorem",
            "explanation": "The Joint Source Channel Coding Theorem provides a theoretical framework for efficiently encoding information by jointly considering source and channel characteristics. This theorem is a significant result in information theory, offering insights into optimizing communication systems. [Data: Entities (1709), Relationships (1784, 1785)]"
        }
    ]
}
```.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\services\json.py", line 77, in invoke
    return await this.invoke_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\services\json.py", line 100, in invoke_json
    raise FailedToGenerateValidJsonError from error
fnllm.base.services.errors.FailedToGenerateValidJsonError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\graphrag\index\operations\summarize_communities\community_reports_extractor.py", line 80, in __call__
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\graphrag\language_model\providers\fnllm\models.py", line 81, in achat
    response = await self.model(prompt, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\openai\llm\openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\openai\services\openai_tools_parsing.py", line 130, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\base_llm.py", line 148, in __call__
    await self._events.on_error(
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\graphrag\language_model\providers\fnllm\events.py", line 26, in on_error
    self._on_error(error, traceback, arguments)
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\graphrag\language_model\providers\fnllm\utils.py", line 45, in on_error
    callbacks.error("Error Invoking LLM", error, stack, details)
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\graphrag\callbacks\workflow_callbacks_manager.py", line 64, in error
    callback.error(message, cause, stack, details)
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\graphrag\callbacks\file_workflow_callbacks.py", line 37, in error
    json.dumps(
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\__init__.py", line 238, in dumps
    **kw).encode(obj)
          ^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 202, in encode
    chunks = list(chunks)
             ^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 432, in _iterencode
    yield from _iterencode_dict(o, _current_indent_level)
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 406, in _iterencode_dict
    yield from chunks
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 406, in _iterencode_dict
    yield from chunks
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 406, in _iterencode_dict
    yield from chunks
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 439, in _iterencode
    o = _default(o)
        ^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 180, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
TypeError: Object of type ModelMetaclass is not JSON serializable
17:02:28,46 graphrag.callbacks.file_workflow_callbacks INFO Community Report Extraction Error details=None
17:02:28,47 graphrag.index.operations.summarize_communities.strategies WARNING No report found for community: 7.0
17:02:30,517 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
17:02:30,648 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
17:02:39,122 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
17:02:40,49 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
17:02:47,176 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
17:02:54,208 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
17:02:55,693 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
17:02:55,787 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
17:02:58,590 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
17:03:01,867 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
17:03:05,139 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
17:03:05,144 graphrag.index.operations.summarize_communities.community_reports_extractor ERROR error generating community report
Traceback (most recent call last):
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\services\json.py", line 126, in _parse_json_string
    return json.loads(value) if value else None
           ^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\__init__.py", line 346, in loads
    return _default_decoder.decode(s)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\services\json.py", line 96, in invoke_json
    return await self.try_receive_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\services\json.py", line 114, in try_receive_json
    raw_json = self._parse_json_string(json_string)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\services\json.py", line 129, in _parse_json_string
    raise FailedToGenerateValidJsonError(msg) from err
fnllm.base.services.errors.FailedToGenerateValidJsonError: JSON response is not a valid JSON, response=```json
{
    "title": "Bernoulli Distribution and Related Probability Concepts",
    "summary": "The community centers around the Bernoulli Distribution, a fundamental probability model for binary outcomes, and its related entities such as the Bernoulli Process, Large Deviation Theory, and Bayesian Posterior Probability. These entities are interconnected through various relationships that highlight their roles in probability theory and statistical modeling. The Bernoulli Process, for instance, is linked to concepts like entropy rate and waiting time, while Large Deviation Theory applies to analyzing deviations in the Bernoulli Distribution. Bayesian Posterior Probability is calculated for the Bernoulli Distribution, demonstrating its utility in Bayesian statistics. This network of entities and relationships underscores the foundational importance of these concepts in probability and statistics.",
    "rating": 8.5,
    "rating_explanation": "The impact severity rating is high due to the foundational role of these concepts in probability theory and their widespread applications in statistical modeling.",
    "findings": [
        {
            "summary": "Bernoulli Distribution as a foundational concept",
            "explanation": "The Bernoulli Distribution is a cornerstone of probability theory, modeling binary outcomes with probabilities of success and failure. Its simplicity and versatility make it a building block for more complex distributions and statistical models. The distribution is referenced in various contexts, including optimal code matching and large deviation theory, highlighting its broad applicability [Data: Entities (499), Relationships (592, 676)]."
        },
        {
            "summary": "Bernoulli Process and its historical significance",
            "explanation": "The Bernoulli Process, a sequence of independent binary trials, has historical significance in probability theory, notably used by Laplace to model the probability of the sun rising. It is linked to concepts like entropy rate, waiting time, and modulo 2 addition, which are crucial for understanding stochastic processes. The process's binary nature makes it a foundational concept in probability and statistics [Data: Entities (201), Relationships (205, 206, 207, 766)]."
        },
        {
            "summary": "Large Deviation Theory's role in analyzing rare events",
            "explanation": "Large Deviation Theory focuses on the exponential decay of probabilities of rare or extreme events, providing a framework for understanding significant deviations from expected values. It is applied to the Bernoulli Distribution, demonstrating its utility in analyzing deviations in binary outcomes. The theory is foundational to understanding the behavior of systems in the presence of rare events [Data: Entities (523), Relationships (592, 593)]."
        },
        {
            "summary": "Bayesian Posterior Probability in statistical inference",
            "explanation": "Bayesian Posterior Probability is a key concept in Bayesian statistics, representing the updated probability of an event after considering new evidence. It is calculated for the Bernoulli Distribution, illustrating its application in statistical inference. The concept is also linked to the Bayesian Probability of Error, highlighting its role in decision theory [Data: Entities (575), Relationships (676, 1689)]."
        },
        {
            "summary": "Uniform Distribution as a non-informative prior",
            "explanation": "The Uniform Distribution, characterized by equal likelihood of outcomes within a specified interval, is widely used in Bayesian statistics as a non-informative prior. It is also employed in modeling noise in communication channels, ensuring no specific outcome is favored. The distribution's simplicity and versatility make it a key example in illustrating concepts like differential entropy [Data: Entities (129), Relationships (447)]."
        },
        {
            "summary": "Random variables and their relationships",
            "explanation": "Random variables X and Y are central to understanding relationships in probability theory, such as conditional entropy and the Fano Inequality. The quantized version of X, X^, is used to derive the relationship between differential and discrete entropy. These relationships are crucial for analyzing and modeling probabilistic systems [Data: Entities (126, 124, 402), Relationships (125, 446)]."
        },
        {
            "summary": "Computer and Universal Machine in theoretical modeling",
            "explanation": "The Computer and Universal Machine are theoretical models that illustrate the concept of amplifying intelligence and simulating any computational process. The Universal Machine's ability to simulate other computers underscores its foundational role in theoretical computer science. These concepts are linked to the Bernoulli Process and other stochastic models [Data: Entities (634, 638), Relationships (747)]."
        },
        {
            "summary": "Monkey and Typewriter as illustrative concepts",
            "explanation": "The Monkey and Typewriter are used to illustrate the concept of random input producing meaningful output, such as Shakespeare's works. These hypothetical entities highlight the probabilistic nature of generating meaningful sequences from randomness. The concepts are linked to the Computer and Typewriter, emphasizing their role in understanding randomness and information theory [Data: Entities (635, 637), Relationships (745, 751, 752)]."
        }
    ]
}
```.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\services\json.py", line 77, in invoke
    return await this.invoke_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\services\json.py", line 100, in invoke_json
    raise FailedToGenerateValidJsonError from error
fnllm.base.services.errors.FailedToGenerateValidJsonError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\graphrag\index\operations\summarize_communities\community_reports_extractor.py", line 80, in __call__
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\graphrag\language_model\providers\fnllm\models.py", line 81, in achat
    response = await self.model(prompt, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\openai\llm\openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\openai\services\openai_tools_parsing.py", line 130, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\base_llm.py", line 148, in __call__
    await self._events.on_error(
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\graphrag\language_model\providers\fnllm\events.py", line 26, in on_error
    self._on_error(error, traceback, arguments)
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\graphrag\language_model\providers\fnllm\utils.py", line 45, in on_error
    callbacks.error("Error Invoking LLM", error, stack, details)
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\graphrag\callbacks\workflow_callbacks_manager.py", line 64, in error
    callback.error(message, cause, stack, details)
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\graphrag\callbacks\file_workflow_callbacks.py", line 37, in error
    json.dumps(
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\__init__.py", line 238, in dumps
    **kw).encode(obj)
          ^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 202, in encode
    chunks = list(chunks)
             ^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 432, in _iterencode
    yield from _iterencode_dict(o, _current_indent_level)
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 406, in _iterencode_dict
    yield from chunks
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 406, in _iterencode_dict
    yield from chunks
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 406, in _iterencode_dict
    yield from chunks
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 439, in _iterencode
    o = _default(o)
        ^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 180, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
TypeError: Object of type ModelMetaclass is not JSON serializable
17:03:05,150 graphrag.callbacks.file_workflow_callbacks INFO Community Report Extraction Error details=None
17:03:05,150 graphrag.index.operations.summarize_communities.strategies WARNING No report found for community: 11.0
17:03:11,358 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
17:03:19,390 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
17:03:20,710 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
17:03:22,680 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
17:03:25,177 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
17:03:25,182 graphrag.index.operations.summarize_communities.community_reports_extractor ERROR error generating community report
Traceback (most recent call last):
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\services\json.py", line 126, in _parse_json_string
    return json.loads(value) if value else None
           ^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\__init__.py", line 346, in loads
    return _default_decoder.decode(s)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\services\json.py", line 96, in invoke_json
    return await self.try_receive_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\services\json.py", line 114, in try_receive_json
    raw_json = self._parse_json_string(json_string)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\services\json.py", line 129, in _parse_json_string
    raise FailedToGenerateValidJsonError(msg) from err
fnllm.base.services.errors.FailedToGenerateValidJsonError: JSON response is not a valid JSON, response=```json
{
    "title": "TDMA, FDMA, and CDMA Communication Technologies",
    "summary": "The community revolves around key communication technologies: TDMA, FDMA, and CDMA. These technologies are interconnected through their shared purpose of enabling efficient data transmission among multiple users. TDMA and FDMA are foundational techniques that manage user access through time and frequency division, respectively, while CDMA employs code division for simultaneous communication. The relationships between these technologies highlight their complementary roles in communication systems, with TDMA also linked to historical communication concepts like telephone and timesharing.",
    "rating": 7.5,
    "rating_explanation": "The impact severity rating is high due to the foundational role these technologies play in modern communication systems.",
    "findings": [
        {
            "summary": "TDMA as a central communication technology",
            "explanation": "TDMA (Time-Division Multiple Access) is a central entity in this community, serving as a foundational communication technology. It operates by dividing time into discrete slots, allowing multiple users to share the same frequency channel efficiently. TDMA is particularly suited for fixed groups of users, optimizing bandwidth usage and minimizing interference. Its relationships with FDMA, CDMA, telephone, and timesharing underscore its significance in communication systems. [Data: Entities (733), Relationships (857, 855, 1845, 1846)]"
        },
        {
            "summary": "FDMA's role in frequency division",
            "explanation": "FDMA (Frequency-Division Multiple Access) is another key technology in this community, managing user access by dividing the available bandwidth into distinct frequency bands. Each user is assigned a unique frequency band, enabling simultaneous communication without interference. FDMA shares similarities with TDMA in its application to fixed groups of users and its limitations in user management. Its relationship with CDMA highlights the complementary nature of these technologies. [Data: Entities (734), Relationships (857, 856)]"
        },
        {
            "summary": "CDMA's unique approach to simultaneous communication",
            "explanation": "CDMA (Code-Division Multiple Access) distinguishes itself by enabling multiple users to transmit data simultaneously over a shared channel using unique codes. This approach allows for efficient bandwidth usage and seamless integration of new users. CDMA's relationships with TDMA and FDMA emphasize its role as a complementary technology in communication systems. [Data: Entities (732), Relationships (855, 856)]"
        },
        {
            "summary": "TDMA's application in telephone systems",
            "explanation": "TDMA is directly linked to telephone communication systems, highlighting its practical application in voice transmission. This relationship underscores the technology's versatility and its role in modern communication infrastructure. [Data: Relationships (1845)]"
        },
        {
            "summary": "Historical context of telegraph and telephone",
            "explanation": "The relationship between telegraph and telephone provides historical context for the evolution of communication technologies. Both technologies played pivotal roles in the development of modern communication systems, with telephone continuing to be relevant today. [Data: Entities (1957, 1958), Relationships (1847)]"
        },
        {
            "summary": "Timesharing's connection to TDMA",
            "explanation": "Timesharing, a mathematical concept in information theory, is related to TDMA in its approach to resource allocation. This connection highlights the theoretical underpinnings of TDMA and its application in managing communication resources. [Data: Entities (1960), Relationships (1846)]"
        }
    ]
}
```.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\services\json.py", line 77, in invoke
    return await this.invoke_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\services\json.py", line 100, in invoke_json
    raise FailedToGenerateValidJsonError from error
fnllm.base.services.errors.FailedToGenerateValidJsonError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\graphrag\index\operations\summarize_communities\community_reports_extractor.py", line 80, in __call__
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\graphrag\language_model\providers\fnllm\models.py", line 81, in achat
    response = await self.model(prompt, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\openai\llm\openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\openai\services\openai_tools_parsing.py", line 130, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\base_llm.py", line 148, in __call__
    await self._events.on_error(
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\graphrag\language_model\providers\fnllm\events.py", line 26, in on_error
    self._on_error(error, traceback, arguments)
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\graphrag\language_model\providers\fnllm\utils.py", line 45, in on_error
    callbacks.error("Error Invoking LLM", error, stack, details)
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\graphrag\callbacks\workflow_callbacks_manager.py", line 64, in error
    callback.error(message, cause, stack, details)
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\graphrag\callbacks\file_workflow_callbacks.py", line 37, in error
    json.dumps(
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\__init__.py", line 238, in dumps
    **kw).encode(obj)
          ^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 202, in encode
    chunks = list(chunks)
             ^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 432, in _iterencode
    yield from _iterencode_dict(o, _current_indent_level)
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 406, in _iterencode_dict
    yield from chunks
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 406, in _iterencode_dict
    yield from chunks
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 406, in _iterencode_dict
    yield from chunks
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 439, in _iterencode
    o = _default(o)
        ^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 180, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
TypeError: Object of type ModelMetaclass is not JSON serializable
17:03:25,188 graphrag.callbacks.file_workflow_callbacks INFO Community Report Extraction Error details=None
17:03:25,188 graphrag.index.operations.summarize_communities.strategies WARNING No report found for community: 18.0
17:03:25,204 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
17:03:25,208 graphrag.index.operations.summarize_communities.community_reports_extractor ERROR error generating community report
Traceback (most recent call last):
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\services\json.py", line 126, in _parse_json_string
    return json.loads(value) if value else None
           ^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\__init__.py", line 346, in loads
    return _default_decoder.decode(s)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\services\json.py", line 96, in invoke_json
    return await self.try_receive_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\services\json.py", line 114, in try_receive_json
    raw_json = self._parse_json_string(json_string)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\services\json.py", line 129, in _parse_json_string
    raise FailedToGenerateValidJsonError(msg) from err
fnllm.base.services.errors.FailedToGenerateValidJsonError: JSON response is not a valid JSON, response=```json
{
    "title": "Information Theory Communication Models",
    "summary": "This community revolves around advanced communication models and concepts in information theory, including the Gaussian Two-Way Channel, Slepian-Wolf Encoding, and the Joint Source-Channel Coding Theorem. These entities are interconnected through foundational principles such as the Asymptotic Equipartition Property (AEP) and Joint Typicality, which underpin their theoretical frameworks and practical applications.",
    "rating": 7.5,
    "rating_explanation": "The impact severity rating is high due to the foundational importance of these concepts in advancing communication theory and their potential applications in modern communication systems.",
    "findings": [
        {
            "summary": "Gaussian Two-Way Channel as a sophisticated communication model",
            "explanation": "The Gaussian Two-Way Channel is a specialized communication model that facilitates bidirectional feedback and collaboration between two senders and two receivers. This model builds upon the Gaussian Interference Channel but introduces additional connections that enhance coordination and information exchange. Its sophisticated framework is crucial for studying communication systems with interactive feedback mechanisms. [Data: Entities (708), Relationships (829)]"
        },
        {
            "summary": "Slepian-Wolf Encoding's role in distributed source coding",
            "explanation": "Slepian-Wolf Encoding is a method of distributed source coding that efficiently compresses correlated sources by encoding them separately but decoding them jointly. This approach is foundational in information theory, enabling optimal compression rates based on conditional entropy. Its principles are closely related to the Gaussian Multiple Access Channel, highlighting its significance in modern communication systems. [Data: Entities (739), Relationships (878, 863)]"
        },
        {
            "summary": "Joint Source-Channel Coding Theorem's reliance on AEP",
            "explanation": "The Joint Source-Channel Coding Theorem demonstrates that error probability can approach zero if the source entropy is less than the channel capacity. This theorem relies on the Asymptotic Equipartition Property (AEP) to prove the existence of a typical set, which is crucial for understanding the behavior of random processes in communication systems. [Data: Entities (374), Relationships (398)]"
        },
        {
            "summary": "Typical Set and its foundational role in information theory",
            "explanation": "The Typical Set is a fundamental concept in information theory, representing sequences that are most likely to occur in a random process. It is derived from the Asymptotic Equipartition Property (AEP) and plays a critical role in the proof of the Joint Source-Channel Coding Theorem. The Typical Set is essential for understanding the statistical behavior of sequences in large-scale random processes. [Data: Entities (155), Relationships (156)]"
        },
        {
            "summary": "Joint Typicality's importance in communication systems",
            "explanation": "Joint Typicality is a key concept in information theory, describing sequences that are typical with respect to a joint probability distribution. It is crucial for analyzing communication channels and is utilized in advanced encoding techniques such as Slepian-Wolf Encoding. Joint Typicality ensures that input and output sequences are aligned for reliable communication. [Data: Entities (379), Relationships (404)]"
        }
    ]
}
```.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\services\json.py", line 77, in invoke
    return await this.invoke_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\services\json.py", line 100, in invoke_json
    raise FailedToGenerateValidJsonError from error
fnllm.base.services.errors.FailedToGenerateValidJsonError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\graphrag\index\operations\summarize_communities\community_reports_extractor.py", line 80, in __call__
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\graphrag\language_model\providers\fnllm\models.py", line 81, in achat
    response = await self.model(prompt, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\openai\llm\openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\openai\services\openai_tools_parsing.py", line 130, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\base_llm.py", line 148, in __call__
    await self._events.on_error(
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\graphrag\language_model\providers\fnllm\events.py", line 26, in on_error
    self._on_error(error, traceback, arguments)
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\graphrag\language_model\providers\fnllm\utils.py", line 45, in on_error
    callbacks.error("Error Invoking LLM", error, stack, details)
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\graphrag\callbacks\workflow_callbacks_manager.py", line 64, in error
    callback.error(message, cause, stack, details)
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\graphrag\callbacks\file_workflow_callbacks.py", line 37, in error
    json.dumps(
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\__init__.py", line 238, in dumps
    **kw).encode(obj)
          ^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 202, in encode
    chunks = list(chunks)
             ^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 432, in _iterencode
    yield from _iterencode_dict(o, _current_indent_level)
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 406, in _iterencode_dict
    yield from chunks
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 406, in _iterencode_dict
    yield from chunks
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 406, in _iterencode_dict
    yield from chunks
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 439, in _iterencode
    o = _default(o)
        ^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 180, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
TypeError: Object of type ModelMetaclass is not JSON serializable
17:03:25,214 graphrag.callbacks.file_workflow_callbacks INFO Community Report Extraction Error details=None
17:03:25,215 graphrag.index.operations.summarize_communities.strategies WARNING No report found for community: 19.0
17:03:42,580 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
17:03:42,585 graphrag.index.operations.summarize_communities.community_reports_extractor ERROR error generating community report
Traceback (most recent call last):
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\services\json.py", line 126, in _parse_json_string
    return json.loads(value) if value else None
           ^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\__init__.py", line 346, in loads
    return _default_decoder.decode(s)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\services\json.py", line 96, in invoke_json
    return await self.try_receive_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\services\json.py", line 114, in try_receive_json
    raw_json = self._parse_json_string(json_string)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\services\json.py", line 129, in _parse_json_string
    raise FailedToGenerateValidJsonError(msg) from err
fnllm.base.services.errors.FailedToGenerateValidJsonError: JSON response is not a valid JSON, response=```json
{
    "title": "Statistical Estimation and Cramr-Rao Inequality",
    "summary": "This community revolves around the concepts of statistical estimation and the Cramr-Rao Inequality, with key entities such as Fisher Information, Unbiased Estimator, and Parameter . The relationships between these entities highlight the foundational principles of statistical theory, particularly in the context of parameter estimation and the efficiency of estimators.",
    "rating": 7.5,
    "rating_explanation": "The impact severity rating is high due to the foundational importance of these concepts in statistical theory and their widespread application in various fields.",
    "findings": [
        {
            "summary": "Cramr-Rao Inequality as a cornerstone of statistical estimation",
            "explanation": "The Cramr-Rao Inequality is a fundamental theorem in statistics that establishes a lower bound for the variance of unbiased estimators of a parameter. This inequality is crucial for evaluating the efficiency of estimators and understanding the limitations of parameter estimation. It is derived from Fisher Information, which quantifies the amount of information an observable random variable carries about an unknown parameter. The relationship between the Cramr-Rao Inequality and Fisher Information underscores the theoretical foundation of statistical inference. [Data: Entities (25, 554), Relationships (19, 637, 636)]"
        },
        {
            "summary": "Fisher Information's role in parameter estimation",
            "explanation": "Fisher Information is a key concept in statistical estimation, providing a measure of how well an unknown parameter can be estimated from observed data. It evaluates the sensitivity of the likelihood function to changes in the parameter, indicating the precision with which the parameter can be inferred. Fisher Information is directly related to the Cramr-Rao Inequality, as it is used to define the lower bound for the variance of unbiased estimators. This relationship highlights the importance of Fisher Information in understanding the efficiency of statistical estimators. [Data: Entities (24), Relationships (19, 637)]"
        },
        {
            "summary": "Unbiased Estimator and its significance in statistical estimation",
            "explanation": "An unbiased estimator is a statistical estimator whose expected value equals the true value of the parameter being estimated. This ensures that the estimation process does not systematically overestimate or underestimate the true parameter value. The Cramr-Rao Inequality specifically applies to unbiased estimators, providing a lower bound for their variance. This relationship emphasizes the importance of unbiasedness in achieving accurate and reliable parameter estimation. [Data: Entities (548), Relationships (636)]"
        },
        {
            "summary": "Parameter  as the target of statistical estimation",
            "explanation": "Parameter  represents the unknown value in a statistical model that is to be estimated using sample data. It is the central focus of statistical estimation, with various estimators and methods developed to infer its value. The relationship between Parameter  and statistical estimation highlights the goal of parameter estimation and the challenges associated with achieving accurate and precise estimates. [Data: Entities (547), Relationships (627)]"
        },
        {
            "summary": "Mean Squared Error as a measure of estimator quality",
            "explanation": "Mean Squared Error (MSE) is a measure of the quality of an estimator, representing the average squared difference between the estimated values and the actual value. It is used to evaluate the performance of estimators in statistical estimation, providing a quantitative measure of their accuracy and precision. The relationship between MSE and statistical estimation underscores the importance of evaluating estimator performance in practical applications. [Data: Entities (549), Relationships (629)]"
        },
        {
            "summary": "Consistent Estimator and its convergence properties",
            "explanation": "A consistent estimator is one that converges in probability to the true parameter value as the sample size increases. This property is desirable in statistical estimation, as it ensures that the estimator becomes more accurate with larger sample sizes. The relationship between consistent estimators and statistical estimation highlights the importance of asymptotic properties in achieving reliable parameter estimation. [Data: Entities (551), Relationships (632)]"
        },
        {
            "summary": "Score Function's role in the proof of the Cramr-Rao Inequality",
            "explanation": "The Score Function is the derivative of the log-likelihood function with respect to the parameter and is a key component in the proof of the Cramr-Rao Inequality. It plays a crucial role in understanding the sensitivity of the likelihood function to changes in the parameter, which is essential for deriving the lower bound on the variance of unbiased estimators. The relationship between the Score Function and the Cramr-Rao Inequality highlights the mathematical foundations of statistical estimation. [Data: Entities (553), Relationships (634)]"
        },
        {
            "summary": "Fisher's contributions to statistical theory",
            "explanation": "Fisher is a prominent figure in the field of statistics, known for defining the concept of sufficient statistics and Fisher Information. These contributions have had a significant impact on statistical theory, particularly in the context of parameter estimation and the efficiency of estimators. Fisher's work is closely related to the Cramr-Rao Inequality, as Fisher Information is used to define the lower bound for the variance of unbiased estimators. [Data: Entities (143), Relationships (19, 149)]"
        },
        {
            "summary": "Lehmann and Scheff's development of minimal sufficient statistics",
            "explanation": "Lehmann and Scheff introduced the concept of minimal sufficient statistics, which are statistics that contain all the information needed to make inferences about a parameter. This concept builds on Fisher's work on sufficient statistics and has further advanced the field of statistical estimation. The relationship between Lehmann, Scheff, and Fisher highlights the evolution of statistical theory and the ongoing development of methods for efficient parameter estimation. [Data: Entities (144, 145), Relationships (149, 150)]"
        }
    ]
}
```.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\services\json.py", line 77, in invoke
    return await this.invoke_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\services\json.py", line 100, in invoke_json
    raise FailedToGenerateValidJsonError from error
fnllm.base.services.errors.FailedToGenerateValidJsonError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\graphrag\index\operations\summarize_communities\community_reports_extractor.py", line 80, in __call__
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\graphrag\language_model\providers\fnllm\models.py", line 81, in achat
    response = await self.model(prompt, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\openai\llm\openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\openai\services\openai_tools_parsing.py", line 130, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\base_llm.py", line 148, in __call__
    await self._events.on_error(
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\graphrag\language_model\providers\fnllm\events.py", line 26, in on_error
    self._on_error(error, traceback, arguments)
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\graphrag\language_model\providers\fnllm\utils.py", line 45, in on_error
    callbacks.error("Error Invoking LLM", error, stack, details)
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\graphrag\callbacks\workflow_callbacks_manager.py", line 64, in error
    callback.error(message, cause, stack, details)
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\graphrag\callbacks\file_workflow_callbacks.py", line 37, in error
    json.dumps(
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\__init__.py", line 238, in dumps
    **kw).encode(obj)
          ^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 202, in encode
    chunks = list(chunks)
             ^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 432, in _iterencode
    yield from _iterencode_dict(o, _current_indent_level)
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 406, in _iterencode_dict
    yield from chunks
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 406, in _iterencode_dict
    yield from chunks
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 406, in _iterencode_dict
    yield from chunks
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 439, in _iterencode
    o = _default(o)
        ^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 180, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
TypeError: Object of type ModelMetaclass is not JSON serializable
17:03:42,591 graphrag.callbacks.file_workflow_callbacks INFO Community Report Extraction Error details=None
17:03:42,591 graphrag.index.operations.summarize_communities.strategies WARNING No report found for community: 14.0
17:03:44,244 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
17:03:44,398 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
17:03:49,181 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
17:03:49,186 graphrag.index.operations.summarize_communities.community_reports_extractor ERROR error generating community report
Traceback (most recent call last):
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\services\json.py", line 126, in _parse_json_string
    return json.loads(value) if value else None
           ^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\__init__.py", line 346, in loads
    return _default_decoder.decode(s)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\services\json.py", line 96, in invoke_json
    return await self.try_receive_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\services\json.py", line 114, in try_receive_json
    raw_json = self._parse_json_string(json_string)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\services\json.py", line 129, in _parse_json_string
    raise FailedToGenerateValidJsonError(msg) from err
fnllm.base.services.errors.FailedToGenerateValidJsonError: JSON response is not a valid JSON, response=```json
{
    "title": "Information Theory and Its Key Contributors",
    "summary": "The community revolves around Information Theory, a multidisciplinary field that quantifies, stores, and communicates information. Key entities include Claude Shannon, whose work laid the foundation for the field, and other notable researchers like Berger, Davisson, and Van der Meulen. The community is interconnected through various subfields such as probability theory, cryptography, and quantum mechanics, with significant contributions to data compression, secure communication, and quantum information.",
    "rating": 8.5,
    "rating_explanation": "The impact severity rating is high due to the foundational role of Information Theory in modern technology and its widespread applications in telecommunications, data science, and cryptography.",
    "findings": [
        {
            "summary": "Claude Shannon's foundational role in Information Theory",
            "explanation": "Claude Shannon is a central figure in Information Theory, having laid the groundwork for understanding data compression and transmission. His work during World War II also significantly advanced cryptography, bridging it with Information Theory. Shannon's contributions continue to shape the field, influencing both theoretical and practical applications [Data: Entities (66, 291); Relationships (308)]."
        },
        {
            "summary": "Interconnection between Information Theory and Probability Theory",
            "explanation": "Probability Theory provides the mathematical foundation for key concepts in Information Theory, such as entropy and mutual information. This relationship is crucial for understanding the quantification of uncertainty and the analysis of random phenomena, which are central to Information Theory [Data: Entities (68); Relationships (52)]."
        },
        {
            "summary": "Berger's contributions to network information theory",
            "explanation": "Berger has made significant contributions to network information theory, particularly in the areas of Slepian-Wolf coding and rate-distortion coding. His work on strong typical sequences has advanced the understanding of the rate distortion theorem, extending its applicability to more general sources [Data: Entities (490); Relationships (554, 995)]."
        },
        {
            "summary": "Davisson's work on source coding with unknown distributions",
            "explanation": "Davisson is recognized for his foundational work in source coding, particularly in scenarios with unknown distributions. He proved the existence of asymptotically optimal universal source codes for certain classes of sources, addressing complex challenges within Information Theory [Data: Entities (603); Relationships (1730)]."
        },
        {
            "summary": "Van der Meulen's influence on network communication",
            "explanation": "Van der Meulen has made significant contributions to network information theory, particularly through his work on broadcast and relay channels. His concepts of achievable regions for general broadcast channels and the relay channel have been influential in understanding the capacity and performance limits of communication systems [Data: Entities (818); Relationships (984)]."
        },
        {
            "summary": "Cryptography's relationship with Information Theory",
            "explanation": "Cryptography and Information Theory are closely related fields, with Claude Shannon's work during World War II significantly influencing both. Cryptography focuses on secure communication, while Information Theory provides the theoretical foundation for data transmission and compression. This relationship is crucial for understanding secure communication systems [Data: Entities (291); Relationships (308)]."
        },
        {
            "summary": "Quantum mechanics and von Neumann entropy",
            "explanation": "Quantum mechanics plays a significant role in Information Theory through the concept of von Neumann entropy, which quantifies quantum information. This extends classical entropy concepts to quantum systems, providing a framework for understanding quantum information processing [Data: Entities (93); Relationships (76, 84)]."
        }
    ]
}
```.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\services\json.py", line 77, in invoke
    return await this.invoke_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\services\json.py", line 100, in invoke_json
    raise FailedToGenerateValidJsonError from error
fnllm.base.services.errors.FailedToGenerateValidJsonError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\graphrag\index\operations\summarize_communities\community_reports_extractor.py", line 80, in __call__
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\graphrag\language_model\providers\fnllm\models.py", line 81, in achat
    response = await self.model(prompt, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\openai\llm\openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\openai\services\openai_tools_parsing.py", line 130, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\base_llm.py", line 148, in __call__
    await self._events.on_error(
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\graphrag\language_model\providers\fnllm\events.py", line 26, in on_error
    self._on_error(error, traceback, arguments)
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\graphrag\language_model\providers\fnllm\utils.py", line 45, in on_error
    callbacks.error("Error Invoking LLM", error, stack, details)
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\graphrag\callbacks\workflow_callbacks_manager.py", line 64, in error
    callback.error(message, cause, stack, details)
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\graphrag\callbacks\file_workflow_callbacks.py", line 37, in error
    json.dumps(
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\__init__.py", line 238, in dumps
    **kw).encode(obj)
          ^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 202, in encode
    chunks = list(chunks)
             ^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 432, in _iterencode
    yield from _iterencode_dict(o, _current_indent_level)
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 406, in _iterencode_dict
    yield from chunks
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 406, in _iterencode_dict
    yield from chunks
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 406, in _iterencode_dict
    yield from chunks
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 439, in _iterencode
    o = _default(o)
        ^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 180, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
TypeError: Object of type ModelMetaclass is not JSON serializable
17:03:49,192 graphrag.callbacks.file_workflow_callbacks INFO Community Report Extraction Error details=None
17:03:49,192 graphrag.index.operations.summarize_communities.strategies WARNING No report found for community: 17.0
17:03:50,822 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
17:03:50,826 graphrag.index.operations.summarize_communities.community_reports_extractor ERROR error generating community report
Traceback (most recent call last):
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\services\json.py", line 126, in _parse_json_string
    return json.loads(value) if value else None
           ^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\__init__.py", line 346, in loads
    return _default_decoder.decode(s)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\services\json.py", line 96, in invoke_json
    return await self.try_receive_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\services\json.py", line 114, in try_receive_json
    raw_json = self._parse_json_string(json_string)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\services\json.py", line 129, in _parse_json_string
    raise FailedToGenerateValidJsonError(msg) from err
fnllm.base.services.errors.FailedToGenerateValidJsonError: JSON response is not a valid JSON, response=```json
{
    "title": "Gaussian Channel and Network Information Theory",
    "summary": "The community revolves around the Gaussian Channel, a fundamental model in information theory, and its extensions such as the Parallel Gaussian Channel and Gaussian Colored Noise Channel. These entities are interconnected through concepts like power constraints, noise variance, and coding theorems, forming the backbone of network information theory. Key researchers like Slepian, Landau, and Pollak have contributed significantly to this field, advancing our understanding of communication systems under noisy conditions.",
    "rating": 8.5,
    "rating_explanation": "The impact severity rating is high due to the foundational role of the Gaussian Channel in modern communication systems and its widespread applications in real-world scenarios.",
    "findings": [
        {
            "summary": "Gaussian Channel as the central model",
            "explanation": "The Gaussian Channel is the cornerstone of this community, serving as a fundamental model for analyzing communication systems under noisy conditions. It is characterized by additive Gaussian noise and is widely used to study information transmission capacity, error probabilities, and the impact of noise on signal integrity. The Gaussian Channel's significance is further highlighted by its extensions, such as the Parallel Gaussian Channel and Gaussian Colored Noise Channel, which model more complex communication scenarios. [Data: Entities (11), Relationships (8, 500, 11, 477, 10, 12, 457, 458, 459, 821, +more)]"
        },
        {
            "summary": "Power constraints and noise variance",
            "explanation": "Power constraints and noise variance are critical parameters in the operation of the Gaussian Channel. The power constraint, denoted by \( P \), limits the maximum allowable power of the transmitted signal, ensuring the system operates within predefined energy limits. Noise variance, denoted by \( N \), quantifies the variance of the noise present in the channel, which is essential for calculating channel capacity. These parameters are crucial for optimizing the performance and efficiency of communication systems modeled by the Gaussian Channel. [Data: Entities (421, 422), Relationships (460, 462)]"
        },
        {
            "summary": "Extensions of the Gaussian Channel",
            "explanation": "The Gaussian Channel has several extensions that model more complex communication scenarios. The Parallel Gaussian Channel involves multiple Gaussian channels operating in parallel, focusing on power allocation and capacity analysis. The Gaussian Colored Noise Channel represents scenarios with correlated Gaussian noise, making it a more realistic model for certain communication systems. These extensions are essential for understanding and improving the transmission of signals in multi-channel and time-dependent environments. [Data: Entities (447, 19), Relationships (500, 11, 10, 12, 490, +more)]"
        },
        {
            "summary": "Key researchers and their contributions",
            "explanation": "Researchers like Slepian, Landau, and Pollak have made significant contributions to the field of information theory, particularly in the treatment of the Gaussian Channel. Slepian is known for his work on bandwidth-limited signals and the Slepian-Wolf theorem, which has had a profound impact on distributed source coding. Landau and Pollak collaborated on research related to the Gaussian channel and the theory of bandwidth-limited signals, advancing the understanding of signal constraints in communication systems. [Data: Entities (432, 433, 434), Relationships (482, 520, 484, 977, +more)]"
        },
        {
            "summary": "Coding theorems and decoding methods",
            "explanation": "The Gaussian Channel Coding Theorem establishes the capacity of a Gaussian channel under a power constraint, providing a theoretical foundation for reliable communication. Joint Typicality Decoding is a method used to minimize error probability in the Gaussian channel, ensuring reliable communication by identifying codewords that are jointly typical with the received sequence. These theorems and methods are integral to the proof of fundamental results in information theory, such as Shannon's Channel Capacity Theorem. [Data: Entities (428, 334), Relationships (477, 471, 468, 121, +more)]"
        }
    ]
}
```.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\services\json.py", line 77, in invoke
    return await this.invoke_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\services\json.py", line 100, in invoke_json
    raise FailedToGenerateValidJsonError from error
fnllm.base.services.errors.FailedToGenerateValidJsonError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\graphrag\index\operations\summarize_communities\community_reports_extractor.py", line 80, in __call__
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\graphrag\language_model\providers\fnllm\models.py", line 81, in achat
    response = await self.model(prompt, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\openai\llm\openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\openai\services\openai_tools_parsing.py", line 130, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\fnllm\base\base_llm.py", line 148, in __call__
    await self._events.on_error(
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\graphrag\language_model\providers\fnllm\events.py", line 26, in on_error
    self._on_error(error, traceback, arguments)
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\graphrag\language_model\providers\fnllm\utils.py", line 45, in on_error
    callbacks.error("Error Invoking LLM", error, stack, details)
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\graphrag\callbacks\workflow_callbacks_manager.py", line 64, in error
    callback.error(message, cause, stack, details)
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\site-packages\graphrag\callbacks\file_workflow_callbacks.py", line 37, in error
    json.dumps(
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\__init__.py", line 238, in dumps
    **kw).encode(obj)
          ^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 202, in encode
    chunks = list(chunks)
             ^^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 432, in _iterencode
    yield from _iterencode_dict(o, _current_indent_level)
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 406, in _iterencode_dict
    yield from chunks
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 406, in _iterencode_dict
    yield from chunks
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 406, in _iterencode_dict
    yield from chunks
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 439, in _iterencode
    o = _default(o)
        ^^^^^^^^^^^
  File "F:\Anaconda\envs\inf_model_GraphRag\Lib\json\encoder.py", line 180, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
TypeError: Object of type ModelMetaclass is not JSON serializable
17:03:50,843 graphrag.callbacks.file_workflow_callbacks INFO Community Report Extraction Error details=None
17:03:50,843 graphrag.index.operations.summarize_communities.strategies WARNING No report found for community: 16.0
17:04:10,265 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/chat/completions "HTTP/1.1 200 OK"
17:04:10,365 graphrag.utils.storage INFO reading table from storage: documents.parquet
17:04:10,376 graphrag.utils.storage INFO reading table from storage: relationships.parquet
17:04:10,384 graphrag.utils.storage INFO reading table from storage: text_units.parquet
17:04:10,397 graphrag.utils.storage INFO reading table from storage: entities.parquet
17:04:10,406 graphrag.utils.storage INFO reading table from storage: community_reports.parquet
17:04:10,422 graphrag.index.workflows.generate_text_embeddings INFO Creating embeddings
17:04:10,423 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding entity.description: default-entity-description
17:04:10,811 graphrag.index.operations.embed_text.strategies.openai INFO embedding 500 inputs via 500 snippets using 32 batches. max_batch_size=16, max_tokens=8191
17:04:12,599 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:04:12,605 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:04:13,131 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:04:13,166 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:04:13,247 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:04:13,679 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:04:13,709 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:04:13,781 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:04:13,799 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:04:13,876 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:04:14,681 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:04:14,777 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:04:14,875 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:04:15,37 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:04:15,73 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:04:15,296 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:04:15,552 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:04:15,808 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:04:16,297 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:04:16,347 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:04:16,491 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:04:16,494 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:04:16,838 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:04:17,146 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:04:17,667 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:04:17,989 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:04:18,28 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:04:18,541 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:04:21,131 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:04:21,697 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:04:21,903 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:04:22,121 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:04:22,525 graphrag.index.operations.embed_text.strategies.openai INFO embedding 500 inputs via 500 snippets using 32 batches. max_batch_size=16, max_tokens=8191
17:04:23,979 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:04:24,7 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:04:24,76 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:04:24,201 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:04:24,804 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:04:24,964 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:04:25,99 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:04:25,601 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:04:25,874 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:04:26,287 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:04:26,304 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:04:26,413 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:04:27,138 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:04:27,166 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:04:27,349 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:04:27,547 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:04:27,806 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:04:28,644 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:04:28,827 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:04:28,842 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:04:28,884 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:04:28,931 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:04:29,465 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:04:29,609 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:04:29,726 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:04:29,807 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:04:30,322 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:04:30,405 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:04:30,661 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:04:30,745 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:04:30,985 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:04:31,579 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:04:31,691 graphrag.index.operations.embed_text.strategies.openai INFO embedding 500 inputs via 500 snippets using 32 batches. max_batch_size=16, max_tokens=8191
17:04:32,638 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:04:32,971 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:04:33,6 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:04:33,73 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:04:33,483 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:04:33,586 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:04:33,868 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:04:34,22 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:04:34,553 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:04:34,676 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:04:35,44 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:04:35,506 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:04:35,562 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:04:35,741 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:04:35,974 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:04:36,73 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:04:36,594 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:04:36,757 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:04:37,71 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:04:37,97 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:04:37,683 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:04:38,136 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:04:38,342 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:04:38,867 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:04:39,384 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:04:39,979 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:04:40,850 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:04:40,980 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:04:41,113 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:04:41,660 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:04:42,248 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:04:42,420 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:04:42,580 graphrag.index.operations.embed_text.strategies.openai INFO embedding 500 inputs via 500 snippets using 32 batches. max_batch_size=16, max_tokens=8191
17:04:43,775 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:04:43,853 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:04:43,897 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:04:44,64 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:04:44,288 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:04:44,289 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:04:44,499 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:04:44,503 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:04:44,635 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:04:44,699 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:04:44,764 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:04:45,146 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:04:45,310 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:04:45,432 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:04:45,502 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:04:45,536 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:04:45,564 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:04:46,20 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:04:46,101 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:04:46,207 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:04:46,312 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:04:46,507 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:04:46,640 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:04:46,794 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:04:47,15 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:04:47,174 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:04:47,291 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:04:47,631 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:04:48,385 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:04:49,143 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:04:49,899 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:04:50,392 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:04:50,526 graphrag.index.operations.embed_text.strategies.openai INFO embedding 38 inputs via 38 snippets using 3 batches. max_batch_size=16, max_tokens=8191
17:04:51,180 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:04:51,956 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:04:52,867 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:04:52,909 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding community.full_content: default-community-full_content
17:04:52,982 graphrag.index.operations.embed_text.strategies.openai INFO embedding 133 inputs via 133 snippets using 10 batches. max_batch_size=16, max_tokens=8191
17:04:54,577 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:04:54,609 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:04:54,645 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:04:54,750 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:04:55,91 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:04:55,110 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:04:55,173 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:04:55,476 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:04:55,565 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:04:55,812 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:04:55,928 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding text_unit.text: default-text_unit-text
17:04:56,431 graphrag.index.operations.embed_text.strategies.openai INFO embedding 500 inputs via 500 snippets using 84 batches. max_batch_size=16, max_tokens=8191
17:04:57,769 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:04:57,789 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:04:57,904 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:04:58,646 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:04:58,648 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:04:58,653 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:04:58,680 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:04:58,726 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:04:58,749 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:04:58,844 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:04:58,848 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:04:58,897 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:04:59,123 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:04:59,728 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:04:59,864 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:04:59,922 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:05:00,35 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:05:00,115 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:05:00,374 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:05:00,433 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:05:00,600 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:05:00,713 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:05:00,737 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:05:00,797 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:05:00,918 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:05:01,126 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:05:01,427 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:05:01,620 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:05:01,626 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:05:01,669 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:05:01,866 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:05:01,979 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:05:02,47 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:05:02,117 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:05:02,191 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:05:02,259 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:05:02,365 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:05:02,616 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:05:02,806 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:05:02,925 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:05:03,231 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:05:03,399 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:05:03,407 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:05:03,529 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:05:03,552 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:05:03,626 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:05:03,628 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:05:03,820 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:05:03,823 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:05:04,17 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:05:04,226 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:05:04,405 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:05:04,453 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:05:04,466 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:05:04,485 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:05:04,726 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:05:04,779 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:05:04,885 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:05:04,932 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:05:05,117 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:05:05,254 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:05:05,311 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:05:05,478 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:05:05,540 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:05:05,703 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:05:05,900 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:05:06,64 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:05:06,96 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:05:06,99 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:05:06,267 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:05:06,287 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:05:06,399 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:05:06,550 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:05:06,596 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:05:06,766 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:05:06,989 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:05:07,163 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:05:07,243 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:05:07,453 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:05:07,478 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:05:07,577 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:05:07,610 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:05:07,728 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:05:07,791 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:05:07,900 graphrag.index.operations.embed_text.strategies.openai INFO embedding 27 inputs via 27 snippets using 5 batches. max_batch_size=16, max_tokens=8191
17:05:08,762 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:05:08,775 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:05:08,906 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:05:08,936 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:05:09,327 httpx INFO HTTP Request: POST https://api.ppinfra.com/v3/openai/embeddings "HTTP/1.1 200 OK"
17:05:09,452 graphrag.cli.index INFO All workflows completed successfully.
