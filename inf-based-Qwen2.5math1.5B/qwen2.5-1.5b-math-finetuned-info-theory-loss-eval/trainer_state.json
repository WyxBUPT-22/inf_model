{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 2.999170124481328,
  "eval_steps": 500,
  "global_step": 2709,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.05532503457814661,
      "grad_norm": 0.33513134717941284,
      "learning_rate": 4.9e-05,
      "loss": 1.0751,
      "step": 50
    },
    {
      "epoch": 0.11065006915629322,
      "grad_norm": 0.35505783557891846,
      "learning_rate": 9.900000000000001e-05,
      "loss": 0.9836,
      "step": 100
    },
    {
      "epoch": 0.16597510373443983,
      "grad_norm": 0.3664849102497101,
      "learning_rate": 9.99129922858415e-05,
      "loss": 0.8547,
      "step": 150
    },
    {
      "epoch": 0.22130013831258644,
      "grad_norm": 0.29010656476020813,
      "learning_rate": 9.964514770852713e-05,
      "loss": 0.8291,
      "step": 200
    },
    {
      "epoch": 0.2766251728907331,
      "grad_norm": 0.33670490980148315,
      "learning_rate": 9.919740062608017e-05,
      "loss": 0.8264,
      "step": 250
    },
    {
      "epoch": 0.33195020746887965,
      "grad_norm": 0.3219771385192871,
      "learning_rate": 9.857137357011778e-05,
      "loss": 0.7603,
      "step": 300
    },
    {
      "epoch": 0.3872752420470263,
      "grad_norm": 0.29868942499160767,
      "learning_rate": 9.776933511754727e-05,
      "loss": 0.7403,
      "step": 350
    },
    {
      "epoch": 0.4426002766251729,
      "grad_norm": 0.3338351249694824,
      "learning_rate": 9.679419166976914e-05,
      "loss": 0.7535,
      "step": 400
    },
    {
      "epoch": 0.4979253112033195,
      "grad_norm": 0.33899545669555664,
      "learning_rate": 9.56494769205524e-05,
      "loss": 0.7215,
      "step": 450
    },
    {
      "epoch": 0.5532503457814661,
      "grad_norm": 0.3223101794719696,
      "learning_rate": 9.43393390507476e-05,
      "loss": 0.7252,
      "step": 500
    },
    {
      "epoch": 0.6085753803596127,
      "grad_norm": 0.36725491285324097,
      "learning_rate": 9.286852569624112e-05,
      "loss": 0.7421,
      "step": 550
    },
    {
      "epoch": 0.6639004149377593,
      "grad_norm": 0.3434903919696808,
      "learning_rate": 9.124236674362354e-05,
      "loss": 0.7204,
      "step": 600
    },
    {
      "epoch": 0.719225449515906,
      "grad_norm": 0.3031025230884552,
      "learning_rate": 8.946675501591631e-05,
      "loss": 0.6879,
      "step": 650
    },
    {
      "epoch": 0.7745504840940526,
      "grad_norm": 0.3249165117740631,
      "learning_rate": 8.754812491834734e-05,
      "loss": 0.7064,
      "step": 700
    },
    {
      "epoch": 0.8298755186721992,
      "grad_norm": 0.31545570492744446,
      "learning_rate": 8.549342912155833e-05,
      "loss": 0.7016,
      "step": 750
    },
    {
      "epoch": 0.8852005532503457,
      "grad_norm": 0.42413097620010376,
      "learning_rate": 8.33101133667383e-05,
      "loss": 0.7152,
      "step": 800
    },
    {
      "epoch": 0.9405255878284924,
      "grad_norm": 0.33768388628959656,
      "learning_rate": 8.100608948398381e-05,
      "loss": 0.6863,
      "step": 850
    },
    {
      "epoch": 0.995850622406639,
      "grad_norm": 0.38233640789985657,
      "learning_rate": 7.858970672166096e-05,
      "loss": 0.6819,
      "step": 900
    },
    {
      "epoch": 1.0520055325034579,
      "grad_norm": 0.3266735374927521,
      "learning_rate": 7.606972149066525e-05,
      "loss": 0.7036,
      "step": 950
    },
    {
      "epoch": 1.1073305670816045,
      "grad_norm": 0.35853663086891174,
      "learning_rate": 7.345526563321845e-05,
      "loss": 0.6658,
      "step": 1000
    },
    {
      "epoch": 1.1626556016597511,
      "grad_norm": 0.35843396186828613,
      "learning_rate": 7.07558133311898e-05,
      "loss": 0.6675,
      "step": 1050
    },
    {
      "epoch": 1.2179806362378978,
      "grad_norm": 0.3271652162075043,
      "learning_rate": 6.798114677385731e-05,
      "loss": 0.6794,
      "step": 1100
    },
    {
      "epoch": 1.2733056708160442,
      "grad_norm": 0.31670546531677246,
      "learning_rate": 6.51413207095219e-05,
      "loss": 0.6677,
      "step": 1150
    },
    {
      "epoch": 1.3286307053941908,
      "grad_norm": 0.4281041622161865,
      "learning_rate": 6.224662600943078e-05,
      "loss": 0.6893,
      "step": 1200
    },
    {
      "epoch": 1.3839557399723375,
      "grad_norm": 0.36026543378829956,
      "learning_rate": 5.930755237604583e-05,
      "loss": 0.6389,
      "step": 1250
    },
    {
      "epoch": 1.439280774550484,
      "grad_norm": 0.3591061234474182,
      "learning_rate": 5.633475033079402e-05,
      "loss": 0.6624,
      "step": 1300
    },
    {
      "epoch": 1.4946058091286307,
      "grad_norm": 0.3390439748764038,
      "learning_rate": 5.333899261904707e-05,
      "loss": 0.6669,
      "step": 1350
    },
    {
      "epoch": 1.5499308437067774,
      "grad_norm": 0.34216490387916565,
      "learning_rate": 5.033113517218978e-05,
      "loss": 0.6453,
      "step": 1400
    },
    {
      "epoch": 1.605255878284924,
      "grad_norm": 0.32038506865501404,
      "learning_rate": 4.732207776824176e-05,
      "loss": 0.6701,
      "step": 1450
    },
    {
      "epoch": 1.6605809128630704,
      "grad_norm": 0.39471733570098877,
      "learning_rate": 4.432272453358883e-05,
      "loss": 0.6644,
      "step": 1500
    },
    {
      "epoch": 1.7159059474412173,
      "grad_norm": 0.3847580850124359,
      "learning_rate": 4.1343944428957226e-05,
      "loss": 0.6375,
      "step": 1550
    },
    {
      "epoch": 1.7712309820193637,
      "grad_norm": 0.3839907944202423,
      "learning_rate": 3.83965318628198e-05,
      "loss": 0.6536,
      "step": 1600
    },
    {
      "epoch": 1.8265560165975103,
      "grad_norm": 0.3849332332611084,
      "learning_rate": 3.54911675749625e-05,
      "loss": 0.6311,
      "step": 1650
    },
    {
      "epoch": 1.881881051175657,
      "grad_norm": 0.33530667424201965,
      "learning_rate": 3.263837993195956e-05,
      "loss": 0.6554,
      "step": 1700
    },
    {
      "epoch": 1.9372060857538036,
      "grad_norm": 0.4154650568962097,
      "learning_rate": 2.9848506774814112e-05,
      "loss": 0.6343,
      "step": 1750
    },
    {
      "epoch": 1.9925311203319502,
      "grad_norm": 0.3495122790336609,
      "learning_rate": 2.7131657957019168e-05,
      "loss": 0.6657,
      "step": 1800
    },
    {
      "epoch": 2.048686030428769,
      "grad_norm": 0.35049790143966675,
      "learning_rate": 2.449767870879252e-05,
      "loss": 0.656,
      "step": 1850
    },
    {
      "epoch": 2.1040110650069157,
      "grad_norm": 0.31245189905166626,
      "learning_rate": 2.1956113960245135e-05,
      "loss": 0.6326,
      "step": 1900
    },
    {
      "epoch": 2.159336099585062,
      "grad_norm": 0.4082978069782257,
      "learning_rate": 1.9516173752767204e-05,
      "loss": 0.6284,
      "step": 1950
    },
    {
      "epoch": 2.214661134163209,
      "grad_norm": 0.35086938738822937,
      "learning_rate": 1.7186699863973687e-05,
      "loss": 0.6391,
      "step": 2000
    },
    {
      "epoch": 2.2699861687413554,
      "grad_norm": 0.3813265264034271,
      "learning_rate": 1.4976133767152039e-05,
      "loss": 0.6343,
      "step": 2050
    },
    {
      "epoch": 2.3253112033195023,
      "grad_norm": 0.3547051250934601,
      "learning_rate": 1.2892486041320296e-05,
      "loss": 0.6485,
      "step": 2100
    },
    {
      "epoch": 2.3806362378976487,
      "grad_norm": 0.387321799993515,
      "learning_rate": 1.09433073427458e-05,
      "loss": 0.6159,
      "step": 2150
    },
    {
      "epoch": 2.4359612724757955,
      "grad_norm": 0.4332582354545593,
      "learning_rate": 9.135661043117698e-06,
      "loss": 0.6243,
      "step": 2200
    },
    {
      "epoch": 2.491286307053942,
      "grad_norm": 0.3902113139629364,
      "learning_rate": 7.476097633525342e-06,
      "loss": 0.6287,
      "step": 2250
    },
    {
      "epoch": 2.5466113416320884,
      "grad_norm": 0.39473956823349,
      "learning_rate": 5.9706309869974885e-06,
      "loss": 0.632,
      "step": 2300
    },
    {
      "epoch": 2.601936376210235,
      "grad_norm": 0.3914884924888611,
      "learning_rate": 4.624716565620673e-06,
      "loss": 0.6215,
      "step": 2350
    },
    {
      "epoch": 2.6572614107883816,
      "grad_norm": 0.3731709122657776,
      "learning_rate": 3.443231651209433e-06,
      "loss": 0.6303,
      "step": 2400
    },
    {
      "epoch": 2.7125864453665285,
      "grad_norm": 0.37027403712272644,
      "learning_rate": 2.430457671167863e-06,
      "loss": 0.6378,
      "step": 2450
    },
    {
      "epoch": 2.767911479944675,
      "grad_norm": 0.44030073285102844,
      "learning_rate": 1.5900646835892985e-06,
      "loss": 0.6071,
      "step": 2500
    },
    {
      "epoch": 2.8232365145228213,
      "grad_norm": 0.37534618377685547,
      "learning_rate": 9.250980778166996e-07,
      "loss": 0.6454,
      "step": 2550
    },
    {
      "epoch": 2.878561549100968,
      "grad_norm": 0.4055282473564148,
      "learning_rate": 4.379675386577409e-07,
      "loss": 0.6304,
      "step": 2600
    },
    {
      "epoch": 2.933886583679115,
      "grad_norm": 0.4265859127044678,
      "learning_rate": 1.3043831424575104e-07,
      "loss": 0.6394,
      "step": 2650
    },
    {
      "epoch": 2.9892116182572614,
      "grad_norm": 0.3727755546569824,
      "learning_rate": 3.624819189745887e-09,
      "loss": 0.6492,
      "step": 2700
    },
    {
      "epoch": 2.999170124481328,
      "step": 2709,
      "total_flos": 1.819645724446556e+17,
      "train_loss": 0.6890713409023912,
      "train_runtime": 2814.0464,
      "train_samples_per_second": 7.707,
      "train_steps_per_second": 0.963
    }
  ],
  "logging_steps": 50,
  "max_steps": 2709,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1.819645724446556e+17,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
